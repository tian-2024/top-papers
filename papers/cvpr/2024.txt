1-Lipschitz Layers Compared: Memory Speed and Certifiable Robustness
2S-UDF: A Novel Two-stage UDF Learning Method for Robust Non-watertight Model Reconstruction from Multi-view Images
360+x: A Panoptic Multi-modal Scene Understanding Dataset
360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model
360Loc: A Dataset and Benchmark for Omnidirectional Visual Localization with Cross-device Queries
3D Building Reconstruction from Monocular Remote Sensing Images with Multi-level Supervisions
3D Face Reconstruction with the Geometric Guidance of Facial Part Segmentation
3D Face Tracking from 2D Video through Iterative Dense UV to Image Flow
3D Facial Expressions through Analysis-by-Neural-Synthesis
3D Feature Tracking via Event Camera
3D Geometry-Aware Deformable Gaussian Splatting for Dynamic View Synthesis
3D Human Pose Perception from Egocentric Stereo Videos
3D LiDAR Mapping in Dynamic Environments using a 4D Implicit Neural Representation
3D Multi-frame Fusion for Video Stabilization
3D Neural Edge Reconstruction
3D Paintbrush: Local Stylization of 3D Shapes with Cascaded Score Distillation
3D-Aware Face Editing via Warping-Guided Latent Direction Learning
3D-LFM: Lifting Foundation Model
3D-SceneDreamer: Text-Driven 3D-Consistent Scene Generation
3DFIRES: Few Image 3D REconstruction for Scenes with Hidden Surfaces
3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting
3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming of Photo-Realistic Free-Viewpoint Videos
3DInAction: Understanding Human Actions in 3D Point Clouds
3DSFLabelling: Boosting 3D Scene Flow Estimation by Pseudo Auto-labelling
3DToonify: Creating Your High-Fidelity 3D Stylized Avatar Easily from 2D Portrait Images
3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features
4D Gaussian Splatting for Real-Time Dynamic Scene Rendering
4D-DRESS: A 4D Dataset of Real-World Human Clothing With Semantic Annotations
4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling
4K4D: Real-Time 4D View Synthesis at 4K Resolution
6D-Diff: A Keypoint Diffusion Framework for 6D Object Pose Estimation
A Backpack Full of Skills: Egocentric Video Understanding with Diverse Task Perspectives
A Bayesian Approach to OOD Robustness in Image Classification
A Call to Reflect on Evaluation Practices for Age Estimation: Comparative Analysis of the State-of-the-Art and a Unified Benchmark
A Category Agnostic Model for Visual Rearrangment
A Closer Look at the Few-Shot Adaptation of Large Vision-Language Models
A Conditional Denoising Diffusion Probabilistic Model for Point Cloud Upsampling
A Dual-Augmentor Framework for Domain Generalization in 3D Human Pose Estimation
A Dynamic Kernel Prior Model for Unsupervised Blind Image Super-Resolution
A General and Efficient Training for Transformer via Token Expansion
A Generative Approach for Wikipedia-Scale Visual Entity Recognition
A Noisy Elephant in the Room: Is Your Out-of-Distribution Detector Robust to Label Noise?
A Pedestrian is Worth One Prompt: Towards Language Guidance Person Re-Identification
A Physics-informed Low-rank Deep Neural Network for Blind and Universal Lens Aberration Correction
A Picture is Worth More Than 77 Text Tokens: Evaluating CLIP-Style Models on Dense Captions
A Recipe for Scaling up Text-to-Video Generation with Text-free Videos
A Semi-supervised Nighttime Dehazing Baseline with Spatial-Frequency Aware and Realistic Brightness Constraint
A Simple Baseline for Efficient Hand Mesh Reconstruction
A Simple Recipe for Contrastively Pre-training Video-First Encoders Beyond 16 Frames
A Simple Recipe for Language-guided Domain Generalized Segmentation
A Simple and Effective Point-based Network for Event Camera 6-DOFs Pose Relocalization
A Stealthy Wrongdoer: Feature-Oriented Reconstruction Attack against Split Learning
A Study of Dropout-Induced Modality Bias on Robustness to Missing Video Frames for Audio-Visual Speech Recognition
A Subspace-Constrained Tyler's Estimator and its Applications to Structure from Motion
A Theory of Joint Light and Heat Transport for Lambertian Scenes
A Unified Approach for Text- and Image-guided 4D Scene Generation
A Unified Diffusion Framework for Scene-aware Human Motion Estimation from Sparse Signals
A Unified Framework for Human-centric Point Cloud Video Understanding
A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid Transformer and Contrastive Learning
A Unified and Interpretable Emotion Representation and Expression Generation
A Versatile Framework for Continual Test-Time Domain Adaptation: Balancing Discriminability and Generalizability
A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization Inversion for Zero-Shot Video Editing
A Vision Check-up for Language Models
A&B BNN: Add&Bit-Operation-Only Hardware-Friendly Binary Neural Network
A-Teacher: Asymmetric Network for 3D Semi-Supervised Object Detection
A2XP: Towards Private Domain Generalization
AAMDM: Accelerated Auto-regressive Motion Diffusion Model
ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models
ADA-Track: End-to-End Multi-Camera 3D Multi-Object Tracking with Alternating Detection and Association
ADFactory: An Effective Framework for Generalizing Optical Flow with NeRF
AEROBLADE: Training-Free Detection of Latent Diffusion Images Using Autoencoder Reconstruction Error
AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation
AHIVE: Anatomy-aware Hierarchical Vision Encoding for Interactive Radiology Report Retrieval
AIDE: An Automatic Data Engine for Object Detection in Autonomous Driving
ALGM: Adaptive Local-then-Global Token Merging for Efficient Semantic Segmentation with Plain Vision Transformers
AM-RADIO: Agglomerative Vision Foundation Model Reduce All Domains Into One
AMU-Tuning: Effective Logit Bias for CLIP-based Few-shot Learning
ANIM: Accurate Neural Implicit Model for Human Reconstruction from a single RGB-D Image
APISR: Anime Production Inspired Real-World Anime Super-Resolution
APSeg: Auto-Prompt Network for Cross-Domain Few-Shot Semantic Segmentation
ARTrackV2: Prompting Autoregressive Tracker Where to Look and How to Describe
ASAM: Boosting Segment Anything Model with Adversarial Tuning
ASH: Animatable Gaussian Splats for Efficient and Photoreal Human Rendering
AUEditNet: Dual-Branch Facial Action Unit Intensity Manipulation with Implicit Disentanglement
AV-RIR: Audio-Visual Room Impulse Response Estimation
AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation with Unified Audio-Visual Speech Representation
AVFF: Audio-Visual Feature Fusion for Video Deepfake Detection
AVID: Any-Length Video Inpainting with Diffusion Model
AZ-NAS: Assembling Zero-Cost Proxies for Network Architecture Search
Abductive Ego-View Accident Video Understanding for Safe Driving Perception
Absolute Pose from One or Two Scaled and Oriented Features
Accelerating Diffusion Sampling with Optimized Time Steps
Accelerating Neural Field Training via Soft Mining
Accept the Modality Gap: An Exploration in the Hyperbolic Space
Accurate Spatial Gene Expression Prediction by Integrating Multi-Resolution Features
Accurate Training Data for Occupancy Map Prediction in Automated Driving Using Evidence Theory
Action Detection via an Image Diffusion Process
Action Scene Graphs for Long-Form Understanding of Egocentric Videos
Action-slot: Visual Action-centric Representations for Multi-label Atomic Activity Recognition in Traffic Scenes
Active Domain Adaptation with False Negative Prediction for Object Detection
Active Generalized Category Discovery
Active Object Detection with Knowledge Aggregation and Distillation from Large Models
Active Open-Vocabulary Recognition: Let Intelligent Moving Mitigate CLIP Limitations
Active Prompt Learning in Vision Language Models
ActiveDC: Distribution Calibration for Active Finetuning
Activity-Biometrics: Person Identification from Daily Activities
AdaBM: On-the-Fly Adaptive Bit Mapping for Image Super-Resolution
AdaRevD: Adaptive Patch Exiting Reversible Decoder Pushes the Limit of Image Deblurring
AdaShift: Learning Discriminative Self-Gated Neural Feature Activation With an Adaptive Shift Factor
Adapt Before Comparison: A New Perspective on Cross-Domain Few-Shot Segmentation
Adapt or Perish: Adaptive Sparse Transformer with Attentive Feature Refinement for Image Restoration
Adapters Strike Back
Adapting Short-Term Transformers for Action Detection in Untrimmed Videos
Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images
Adapting to Length Shift: FlexiLength Network for Trajectory Prediction
Adaptive Bidirectional Displacement for Semi-Supervised Medical Image Segmentation
Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving
Adaptive Hyper-graph Aggregation for Modality-Agnostic Federated Learning
Adaptive Multi-Modal Cross-Entropy Loss for Stereo Matching
Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks
Adaptive Slot Attention: Object Discovery with Dynamic Slot Number
Adaptive Softassign via Hadamard-Equipped Sinkhorn
Adaptive VIO: Deep Visual-Inertial Odometry with Online Continual Learning
Addressing Background Context Bias in Few-Shot Segmentation through Iterative Modulation
Advancing Saliency Ranking with Human Fixations: Dataset Models and Benchmarks
Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving
Adversarial Distillation Based on Slack Matching and Attribution Region Alignment
Adversarial Score Distillation: When score distillation meets GAN
Adversarial Text to Continuous Image Generation
Adversarially Robust Few-shot Learning via Parameter Co-distillation of Similarity and Class Concept Learners
Aerial Lifting: Neural Urban Semantic and Building Instance Lifting from Aerial Imagery
Affine Equivariant Networks Based on Differential Invariants
AiOS: All-in-One-Stage Expressive Human Pose and Shape Estimation
AirPlanes: Accurate Plane Estimation via 3D-Consistent Embeddings
Alchemist: Parametric Control of Material Properties with Diffusion Models
Align Before Adapt: Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition
Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models
Align and Aggregate: Compositional Reasoning with Video Alignment and Answer Aggregation for Video Question-Answering
AlignMiF: Geometry-Aligned Multimodal Implicit Field for LiDAR-Camera Joint Synthesis
AlignSAM: Aligning Segment Anything Model to Open Context via Reinforcement Learning
Aligning Logits Generatively for Principled Black-Box Knowledge Distillation
Aligning and Prompting Everything All at Once for Universal Visual Perception
All Rivers Run to the Sea: Private Learning with Asymmetric Flows
All in One Framework for Multimodal Re-identification in the Wild
AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation
Alpha Invariance: On Inverse Scaling Between Distance and Volume Density in Neural Radiance Fields
Alpha-CLIP: A CLIP Model Focusing on Wherever You Want
Amodal Completion via Progressive Mixed Context Diffusion
Amodal Ground Truth and Completion in the Wild
An Aggregation-Free Federated Learning for Tackling Data Heterogeneity
An Asymmetric Augmented Self-Supervised Learning Method for Unsupervised Fine-Grained Image Hashing
An Edit Friendly DDPM Noise Space: Inversion and Manipulations
An Empirical Study of Scaling Law for Scene Text Recognition
An Empirical Study of the Generalization Ability of Lidar 3D Object Detectors to Unseen Domains
An Interactive Navigation Method with Effect-oriented Affordance
An N-Point Linear Solver for Line and Motion Estimation with Event Cameras
An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side Pre-trained Generator to Clients in Heterogeneous Federated Learning
Analyzing and Improving the Training Dynamics of Diffusion Models
Anatomically Constrained Implicit Face Models
Anchor-based Robust Finetuning of Vision-Language Models
Animatable Gaussians: Learning Pose-dependent Gaussian Maps for High-fidelity Human Avatar Modeling
Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation
Animating General Image with Large Visual Motion Model
Anomaly Heterogeneity Learning for Open-set Supervised Anomaly Detection
Anomaly Score: Evaluating Generative Models and Individual Generated Images based on Complexity and Vulnerability
Any-Shift Prompting for Generalization over Distributions
AnyDoor: Zero-shot Object-level Image Customization
AnyScene: Customized Image Synthesis with Composited Foreground
AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents
ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models
Arbitrary Motion Style Transfer with Multi-condition Motion Latent Diffusion Model
Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion Model and Implicit Neural Decoder
Are Conventional SNNs Really Efficient? A Perspective from Network Quantization
ArtAdapter: Text-to-Image Style Transfer using Multi-Level Style Encoder and Explicit Adaptation
Artist-Friendly Relightable and Animatable Neural Heads
As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D Diffusion Priors
AssistGUI: Task-Oriented PC Graphical User Interface Automation
Asymmetric Masked Distillation for Pre-Training Small Foundation Models
Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion
Atom-Level Optical Chemical Structure Recognition with Limited Supervision
Attack To Defend: Exploiting Adversarial Attacks for Detecting Poisoned Models
Attention Calibration for Disentangled Text-to-Image Personalization
Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models
Attention-Propagation Network for Egocentric Heatmap to 3D Pose Lifting
Attentive Illumination Decomposition Model for Multi-Illuminant White Balancing
AttriHuman-3D: Editable 3D Human Avatar Generation with Attribute Decomposition and Indexing
Attribute-Guided Pedestrian Retrieval: Bridging Person Re-ID with Internal Attribute Variability
Audio-Visual Segmentation via Unlabeled Frame Exploitation
Authentic Hand Avatar from a Phone Scan via Universal Hand Model
Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft
Auto-Train-Once: Controller Network Guided Automatic Network Pruning from Scratch
AutoAD III: The Prequel – Back to the Pixels
Automatic Controllable Colorization via Imagination
Autoregressive Queries for Adaptive Tracking with Spatio-Temporal Transformers
AvatarGPT: All-in-One Framework for Motion Understanding Planning Generation and Beyond
BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model
BANF: Band-Limited Neural Fields for Levels of Detail Reconstruction
BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation
BEM: Balanced and Entropy-based Mix for Long-Tailed Semi-Supervised Learning
BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection
BEVSpread: Spread Voxel Pooling for Bird’s-Eye-View Representation in Vision-based Roadside 3D Object Detection
BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models
BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics
BSNet: Box-Supervised Simulation-assisted Mean Teacher for 3D Instance Segmentation
BT-Adapter: Video Conversation is Feasible Without Video Instruction Tuning
Back to 3D: Few-Shot 3D Keypoint Detection with Back-Projected 2D Features
Backdoor Defense via Test-Time Detecting and Repairing
Backpropagation-free Network for 3D Test-time Adaptation
BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning
BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP
Balancing Act: Distribution-Guided Debiasing in Diffusion Models
Batch Normalization Alleviates the Spectral Bias in Coordinate Networks
Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields
Bayesian Differentiable Physics for Cloth Digitalization
Bayesian Diffusion Models for 3D Shape Reconstruction
Bayesian Exploration of Pre-trained Models for Low-shot Image Classification
Behind the Veil: Enhanced Indoor 3D Scene Reconstruction with Occluded Surfaces Completion
Benchmarking Audio Visual Segmentation for Long-Untrimmed Videos
Benchmarking Implicit Neural Representation and Geometric Rendering in Real-Time RGB-D SLAM
Benchmarking Segmentation Models with Mask-Preserved Attribute Editing
Benchmarking the Robustness of Temporal Action Detection Models Against Temporal Corruptions
BerfScene: Bev-conditioned Equivariant Radiance Fields for Infinite 3D Scene Generation
Beyond Average: Individualized Visual Scanpath Prediction
Beyond First-Order Tweedie: Solving Inverse Problems using Latent Diffusion
Beyond Image Super-Resolution for Image Recognition with Task-Driven Perceptual Loss
Beyond Seen Primitive Concepts and Attribute-Object Compositional Learning
Beyond Text: Frozen Large Language Models in Visual Signal Comprehension
Beyond Textual Constraints: Learning Novel Diffusion Conditions with Fewer Examples
Bi-Causal: Group Activity Recognition via Bidirectional Causality
Bi-SSC: Geometric-Semantic Bidirectional Fusion for Camera-based 3D Semantic Scene Completion
Bi-level Learning of Task-Specific Decoders for Joint Registration and One-Shot Medical Image Segmentation
BiPer: Binary Neural Networks using a Periodic Function
BiTT: Bi-directional Texture Reconstruction of Interacting Two Hands from a Single Image
Bidirectional Autoregessive Diffusion Model for Dance Generation
Bidirectional Multi-Scale Implicit Neural Representations for Image Deraining
BigGait: Learning Gait Representation You Want by Large Vision Models
Bilateral Adaptation for Human-Object Interaction Detection with Occlusion-Robustness
Bilateral Event Mining and Complementary for Event Stream Super-Resolution
Bilateral Propagation Network for Depth Completion
BilevelPruning: Unified Dynamic and Static Channel Pruning for Convolutional Neural Networks
Binarized Low-light Raw Video Enhancement
Binding Touch to Everything: Learning Unified Multimodal Tactile Representations
BioCLIP: A Vision Foundation Model for the Tree of Life
Blind Image Quality Assessment Based on Geometric Order Learning
BlockGCN: Redefine Topology Awareness for Skeleton-Based Action Recognition
Blur-aware Spatio-temporal Sparse Transformer for Video Deblurring
Blur2Blur: Blur Conversion for Unsupervised Image Deblurring on Unknown Domains
BoQ: A Place is Worth a Bag of Learnable Queries
BodyMAP - Jointly Predicting Body Mesh and 3D Applied Pressure Map for People in Bed
Boosting Adversarial Training via Fisher-Rao Norm-based Regularization
Boosting Adversarial Transferability by Block Shuffle and Rotation
Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters
Boosting Diffusion Models with Moving Average Sampling in Frequency Domain
Boosting Flow-based Generative Super-Resolution Models via Learned Prior
Boosting Image Quality Assessment through Efficient Transformer Adaptation with Local Feature Enhancement
Boosting Image Restoration via Priors from Pre-trained Models
Boosting Neural Representations for Videos with a Conditional Decoder
Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation
Boosting Order-Preserving and Transferability for Neural Architecture Search: a Joint Architecture Refined Search and Fine-tuning Approach
Boosting Self-Supervision for Single-View Scene Completion via Knowledge Distillation
Boosting Spike Camera Image Reconstruction from a Perspective of Dealing with Spike Fluctuations
Bootstrapping Autonomous Driving Radars with Self-Supervised Learning
Bootstrapping Chest CT Image Understanding by Distilling Knowledge from X-ray Expert Models
Bootstrapping SparseFormers from Vision Foundation Models
Brain Decodes Deep Nets
BrainWash: A Poisoning Attack to Forget in Continual Learning
Breathing Life Into Sketches Using Text-to-Video Priors
Bridging Remote Sensors with Multisensor Geospatial Foundation Models
Bridging the Gap Between End-to-End and Two-Step Text Spotting
Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection
Bridging the Synthetic-to-Authentic Gap: Distortion-Guided Unsupervised Domain Adaptation for Blind Image Quality Assessment
Bring Event into RGB and LiDAR: Hierarchical Visual-Motion Fusion for Scene Flow
Brush2Prompt: Contextual Prompt Generator for Object Inpainting
Building Bridges across Spatial and Temporal Resolutions: Reference-Based Super-Resolution via Change Priors and Conditional Diffusion Model
Building Optimal Neural Architectures using Interpretable Knowledge
Building Vision-Language Models on Solid Foundations with Masked Distillation
Building a Strong Pre-Training Baseline for Universal 3D Large-Scale Perception
Byzantine-robust Decentralized Federated Learning via Dual-domain Clustering and Trust Bootstrapping
Bézier Everywhere All at Once: Learning Drivable Lanes as Bézier Graphs
C2KD: Bridging the Modality Gap for Cross-Modal Knowledge Distillation
C3: High-Performance and Low-Complexity Neural Compression from a Single Image or Video
C3Net: Compound Conditioned ControlNet for Multimodal Content Generation
CA-Jaccard: Camera-aware Jaccard Distance for Person Re-identification
CAD-SIGNet: CAD Language Inference from Point Clouds using Layer-wise Sketch Instance Guided Attention
CAD: Photorealistic 3D Generation via Adversarial Distillation
CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD Programs
CAGE: Controllable Articulation GEneration
CAM Back Again: Large Kernel CNNs from a Weakly Supervised Object Localization Perspective
CAMEL: CAusal Motion Enhancement Tailored for Lifting Text-driven Video Editing
CAMixerSR: Only Details Need More "Attention"
CAPE: CAM as a Probabilistic Ensemble for Enhanced DNN Interpretation
CARZero: Cross-Attention Alignment for Radiology Zero-Shot Classification
CAT-DM: Controllable Accelerated Virtual Try-on with Diffusion Model
CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation
CAT: Exploiting Inter-Class Dynamics for Domain Adaptive Object Detection
CCEdit: Creative and Controllable Video Editing via Diffusion Models
CDFormer: When Degradation Prediction Embraces Diffusion Model for Blind Image Super-Resolution
CDMAD: Class-Distribution-Mismatch-Aware Debiasing for Class-Imbalanced Semi-Supervised Learning
CFAT: Unleashing Triangular Windows for Image Super-resolution
CFPL-FAS: Class Free Prompt Learning for Generalizable Face Anti-spoofing
CG-HOI: Contact-Guided 3D Human-Object Interaction Generation
CGI-DM: Digital Copyright Authentication for Diffusion Models via Contrasting Gradient Inversion
CHAIN: Enhancing Generalization in Data-Efficient GANs via lipsCHitz continuity constrAIned Normalization
CLIB-FIQA: Face Image Quality Assessment with Confidence Calibration
CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor
CLIP-BEVFormer: Enhancing Multi-View Image-Based BEV Detector with Ground Truth Flow
CLIP-Driven Open-Vocabulary 3D Scene Graph Generation via Cross-Modality Contrastive Learning
CLIP-KD: An Empirical Study of CLIP Model Distillation
CLIPtone: Unsupervised Learning for Text-based Image Tone Adjustment
CLOAF: CoLlisiOn-Aware Human Flow
CLOVA: A Closed-LOop Visual Assistant with Tool Usage and Update
CLiC: Concept Learning in Context
CMA: A Chromaticity Map Adapter for Robust Detection of Screen-Recapture Document Images
CN-RMA: Combined Network with Ray Marching Aggregation for 3D Indoor Object Detection from Multi-view Images
CNC-Net: Self-Supervised Learning for CNC Machining Operations
COCONut: Modernizing COCO Segmentation
COLMAP-Free 3D Gaussian Splatting
CONFORM: Contrast is All You Need for High-Fidelity Text-to-Image Diffusion Models
CORE-MPI: Consistency Object Removal with Embedding MultiPlane Image
CORES: Convolutional Response-based Score for Out-of-distribution Detection
COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy Prediction
CPGA: Coding Priors-Guided Aggregation Network for Compressed Video Quality Enhancement
CPLIP: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment
CPP-Net: Embracing Multi-Scale Feature Fusion into Deep Unfolding CP-PPA Network for Compressive Sensing
CPR-Coach: Recognizing Composite Error Actions based on Single-class Training
CPR: Retrieval Augmented Generation for Copyright Protection
CRKD: Enhanced Camera-Radar Object Detection with Cross-modality Knowledge Distillation
CSTA: CNN-based Spatiotemporal Attention for Video Summarization
CURSOR: Scalable Mixed-Order Hypergraph Matching with CUR Decomposition
CVT-xRF: Contrastive In-Voxel Transformer for 3D Consistent Radiance Fields from Sparse Inputs
C^2RV: Cross-Regional and Cross-View Learning for Sparse-View CBCT Reconstruction
CaDeT: a Causal Disentanglement Approach for Robust Trajectory Prediction in Autonomous Driving
CaKDP: Category-aware Knowledge Distillation and Pruning Framework for Lightweight 3D Object Detection
Cache Me if You Can: Accelerating Diffusion Models through Block Caching
Calibrating Multi-modal Representations: A Pursuit of Group Robustness without Annotations
Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications
Can Biases in ImageNet Models Explain Generalization?
Can I Trust Your Answer? Visually Grounded Video Question Answering
Can Language Beat Numerical Regression? Language-Based Multimodal Trajectory Prediction
Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?
Can’t Make an Omelette Without Breaking Some Eggs: Plausible Action Anticipation Using Large Video-Language Models
CapHuman: Capture Your Moments in Parallel Universes
CapsFusion: Rethinking Image-Text Data at Scale
Capturing Closely Interacted Two-Person Motions with Reaction Priors
Carve3D: Improving Multi-view Reconstruction Consistency for Diffusion Models with RL Finetuning
Category-Level Multi-Part Multi-Joint 3D Shape Assembly
Causal Mode Multiplexer: A Novel Framework for Unbiased Multispectral Pedestrian Detection
Causal-CoG: A Causal-Effect Look at Context Generation for Boosting Multi-modal Language Models
CausalPC: Improving the Robustness of Point Cloud Classification by Causal Effect Identification
ChAda-ViT : Channel Adaptive Attention for Joint Representation Learning of Heterogeneous Microscopy Images
Characteristics Matching Based Hash Codes Generation for Efficient Fine-grained Image Retrieval
Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding
ChatPose: Chatting about 3D Human Pose
ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles
Check Locate Rectify: A Training-Free Layout Calibration System for Text-to-Image Generation
Choose What You Need: Disentangled Representation Learning for Scene Text Recognition Removal and Editing
Cinematic Behavior Transfer via NeRF-based Differentiable Filming
Circuit Design and Efficient Simulation of Quantum Inner Product and Empirical Studies of Its Effect on Near-Term Hybrid Quantum-Classic Machine Learning
CityDreamer: Compositional Generative Model of Unbounded 3D Cities
Class Incremental Learning with Multi-Teacher Distillation
Class Tokens Infusion for Weakly Supervised Semantic Segmentation
Classes Are Not Equal: An Empirical Study on Image Recognition Fairness
Clockwork Diffusion: Efficient Generation With Model-Step Distillation
Close Imitation of Expert Retouching for Black-and-White Photography
Closely Interactive Human Reconstruction with Proxemics and Physics-Guided Adaption
Cloud-Device Collaborative Learning for Multimodal Large Language Models
Clustering Propagation for Universal Medical Image Segmentation
Clustering for Protein Representation Learning
Co-Speech Gesture Video Generation via Motion-Decoupled Diffusion Model
CoDe: An Explicit Content Decoupling Framework for Image Restoration
CoDeF: Content Deformation Fields for Temporally Consistent Video Processing
CoDi-2: In-Context Interleaved and Interactive Any-to-Any Generation
CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation
CoG-DQA: Chain-of-Guiding Learning with Large Language Models for Diagram Question Answering
CoGS: Controllable Gaussian Splatting
CoSeR: Bridging Image and Language for Cognitive Super-Resolution
Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis
Codebook Transfer with Part-of-Speech for Vector-Quantized Image Modeling
CodedEvents: Optimal Point-Spread-Function Engineering for 3D-Tracking with Event Cameras
CogAgent: A Visual Language Model for GUI Agents
Coherence As Texture – Passive Textureless 3D Reconstruction by Self-interference
Coherent Temporal Synthesis for Incremental Action Segmentation
Collaborating Foundation Models for Domain Generalized Semantic Segmentation
Collaborative Learning of Anomalies with Privacy (CLAP) for Unsupervised Video Anomaly Detection: A New Baseline
Collaborative Semantic Occupancy Prediction with Hybrid Feature Fusion in Connected Automated Vehicles
Color Shift Estimation-and-Correction for Image Enhancement
ColorPCR: Color Point Cloud Registration with Multi-Stage Geometric-Color Fusion
Combining Frame and GOP Embeddings for Neural Video Representation
CommonCanvas: Open Diffusion Models Trained on Creative-Commons Images
Commonsense Prototype for Outdoor Unsupervised 3D Object Detection
Communication-Efficient Collaborative Perception via Information Filling with Codebook
Communication-Efficient Federated Learning with Accelerated Client Gradient
Compact 3D Gaussian Representation for Radiance Field
Comparing the Decision-Making Mechanisms by Transformers and CNNs via Explanation Methods
Complementing Event Streams and RGB Frames for Hand Mesh Reconstruction
Composed Video Retrieval via Enriched Context and Discriminative Embeddings
Composing Object Relations and Attributes for Image-Text Matching
Compositional Chain-of-Thought Prompting for Large Multimodal Models
Compositional Video Understanding with Spatiotemporal Structure-based Transformers
Compressed 3D Gaussian Splatting for Accelerated Novel View Synthesis
ConCon-Chi: Concept-Context Chimera Benchmark for Personalized Vision-Language Tasks
ConTex-Human: Free-View Rendering of Human from a Single Image with Texture-Consistent Synthesis
Concept Weaver: Enabling Multi-Concept Fusion in Text-to-Image Models
Condition-Aware Neural Network for Controlled Image Generation
Confronting Ambiguity in 6D Object Pose Estimation via Score-Based Diffusion on SE(3)
ConsistDreamer: 3D-Consistent 2D Diffusion for High-Fidelity Scene Editing
ConsistNet: Enforcing 3D Consistency for Multi-view Images Diffusion
Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering
Consistent Prompting for Rehearsal-Free Continual Learning
Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior
Constrained Layout Generation with Factor Graphs
Construct to Associate: Cooperative Context Learning for Domain Adaptive Point Cloud Segmentation
Constructing and Exploring Intermediate Domains in Mixed Domain Semi-supervised Medical Image Segmentation
Content-Adaptive Non-Local Convolution for Remote Sensing Pansharpening
Content-Style Decoupling for Unsupervised Makeup Transfer without Generating Pseudo Ground Truth
Context-Aware Integration of Language and Visual References for Natural Language Tracking
Context-Guided Spatio-Temporal Video Grounding
Context-based and Diversity-driven Specificity in Compositional Zero-Shot Learning
ContextSeg: Sketch Semantic Segmentation by Querying the Context with Attention
Contextrast: Contextual Contrastive Learning for Semantic Segmentation
Contextual Augmented Global Contrast for Multimodal Intent Recognition
Continual Forgetting for Pre-trained Vision Models
Continual Learning for Motion Prediction Model via Meta-Representation Learning and Optimal Memory Buffer Retention Strategy
Continual Segmentation with Disentangled Objectness Learning and Class Recognition
Continual Self-supervised Learning: Towards Universal Multi-modal Medical Data Representation Learning
Continual-MAE: Adaptive Distribution Masked Autoencoders for Continual Test-Time Adaptation
Continuous Optical Zooming: A Benchmark for Arbitrary-Scale Image Super-Resolution in Real World
Continuous Pose for Monocular Cameras in Neural Implicit Representation
Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to Enhance Visio-Linguistic Compositional Understanding
Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing
Contrastive Learning for DeepFake Classification and Localization via Multi-Label Ranking
Contrastive Mean-Shift Learning for Generalized Category Discovery
Contrastive Pre-Training with Multi-View Fusion for No-Reference Point Cloud Quality Assessment
Control4D: Efficient 4D Portrait Editing with Text
ControlRoom3D: Room Generation using Semantic Proxy Rooms
ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis
Convolutional Prompting meets Language Models for Continual Learning
Cooperation Does Matter: Exploring Multi-Order Bilateral Relations for Audio-Visual Segmentation
CoralSCOP: Segment any COral Image on this Planet
CorrMatch: Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation
Correcting Diffusion Generation through Resampling
Correlation-Decoupled Knowledge Distillation for Multimodal Sentiment Analysis with Incomplete Modalities
Correlation-aware Coarse-to-fine MLPs for Deformable Medical Image Registration
Correspondence-Free Non-Rigid Point Set Registration Using Unsupervised Clustering Analysis
CosalPure: Learning Concept from Group Images for Robust Co-Saliency Detection
CosmicMan: A Text-to-Image Foundation Model for Humans
Countering Personalized Text-to-Image Generation with Influence Watermarks
Coupled Laplacian Eigenmaps for Locally-Aware 3D Rigid Point Cloud Matching
CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition
CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label Learning
Cross Initialization for Face Personalization of Text-to-Image Models
Cross-Dimension Affinity Distillation for 3D EM Neuron Segmentation
Cross-Domain Few-Shot Segmentation via Iterative Support-Query Correspondence Mining
Cross-spectral Gated-RGB Stereo Depth Estimation
Cross-view and Cross-pose Completion for 3D Human Understanding
CrossKD: Cross-Head Knowledge Distillation for Object Detection
CrossMAE: Cross-Modality Masked Autoencoders for Region-Aware Audio-Visual Pre-Training
CrowdDiff: Multi-hypothesis Crowd Density Estimation using Diffusion Models
CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive Self-Supervised Transformers
Curriculum Point Prompting for Weakly-Supervised Referring Image Segmentation
CurveCloudNet: Processing Point Clouds with 1D Structure
CustomListener: Text-guided Responsive Interaction for User-friendly Listening Head Generation
Customization Assistant for Text-to-Image Generation
Customize your NeRF: Adaptive Source Driven 3D Scene Editing via Local-Global Iterative Training
CyberDemo: Augmenting Simulated Human Demonstration for Real-World Dexterous Manipulation
CycleINR: Cycle Implicit Neural Representation for Arbitrary-Scale Volumetric Super-Resolution of Medical Data
Cyclic Learning for Binaural Audio Generation and Localization
D3T: Distinctive Dual-Domain Teacher Zigzagging Across RGB-Thermal Gap for Domain-Adaptive Object Detection
D3still: Decoupled Differential Distillation for Asymmetric Image Retrieval
DAP: A Dynamic Adversarial Patch for Evading Person Detectors
DART: Implicit Doppler Tomography for Radar Novel View Synthesis
DAVE - A Detect-and-Verify Paradigm for Low-Shot Counting
DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations
DETRs Beat YOLOs on Real-time Object Detection
DGC-GNN: Leveraging Geometry and Color Cues for Visual Descriptor-Free 2D-3D Matching
DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement
DIEM: Decomposition-Integration Enhancing Multimodal Insights
DIMAT: Decentralized Iterative Merging-And-Training for Deep Learning Models
DIOD: Self-Distillation Meets Object Discovery
DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data
DITTO: Dual and Integrated Latent Topologies for Implicit 3D Reconstruction
DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision
DMR: Decomposed Multi-Modality Representations for Frames and Events Fusion in Visual Reinforcement Learning
DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization
DPHMs: Diffusion Parametric Head Models for Depth-based Tracking
DPMesh: Exploiting Diffusion Prior for Occluded Human Mesh Recovery
DREAM: Diffusion Rectification and Estimation-Adaptive Models
DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback
DS-NeRV: Implicit Neural Video Representation with Decomposed Static and Dynamic Codes
DSGG: Dense Relation Transformer for an End-to-end Scene Graph Generation
DSL-FIQA: Assessing Facial Image Quality via Dual-Set Degradation Learning and Landmark-Guided Transformer
DUDF: Differentiable Unsigned Distance Fields with Hyperbolic Scaling
DUSt3R: Geometric 3D Vision Made Easy
DVMNet: Computing Relative Pose for Unseen Objects Beyond Hypotheses
DYSON: Dynamic Feature Space Self-Organization for Online Task-Free Class Incremental Learning
D^4: Dataset Distillation via Disentangled Diffusion Model
DaReNeRF: Direction-aware Representation for Dynamic Scenes
DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance
Dancing with Still Images: Video Distillation via Static-Dynamic Disentanglement
Data Poisoning based Backdoor Attacks to Contrastive Learning
Data Valuation and Detections in Federated Learning
Data-Efficient Multimodal Fusion on a Single GPU
Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images
Data-Free Quantization via Pseudo-label Filtering
Day-Night Cross-domain Vehicle Re-identification
De-Diffusion Makes Text a Strong Cross-Modal Interface
De-confounded Data-free Knowledge Distillation for Handling Distribution Shifts
DeCoTR: Enhancing Depth Completion with 2D and 3D Attentions
DeIL: Direct-and-Inverse CLIP for Open-World Few-Shot Learning
DeMatch: Deep Decomposition of Motion Field for Two-View Correspondence Learning
DePT: Decoupled Prompt Tuning
Decentralized Directed Collaboration for Personalized Federated Learning
Deciphering ‘What’ and ‘Where’ Visual Pathways from Spectral Clustering of Layer-Distributed Neural Representations
Decompose-and-Compose: A Compositional Approach to Mitigating Spurious Correlation
Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Pre-training Framework
DeconfuseTrack: Dealing with Confusion for Multi-Object Tracking
Decoupled Pseudo-labeling for Semi-Supervised Monocular 3D Object Detection
Decoupling Static and Hierarchical Motion Perception for Referring Video Segmentation
Deep Equilibrium Diffusion Restoration with Parallel Sampling
Deep Generative Model based Rate-Distortion for Image Downscaling Assessment
Deep Imbalanced Regression via Hierarchical Classification Adjustment
Deep Single Image Camera Calibration by Heatmap Regression to Recover Fisheye Images Under Manhattan World Assumption
Deep Video Inverse Tone Mapping Based on Temporal Clues
Deep-TROJ: An Inference Stage Trojan Insertion Algorithm through Efficient Weight Replacement Attack
DeepCache: Accelerating Diffusion Models for Free
Defense Against Adversarial Attacks on No-Reference Image Quality Models with Gradient Norm Regularization
Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay
Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction
Deformable One-shot Face Stylization via DINO Semantic Guidance
Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories
DeiT-LT: Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets
Delving into the Trajectory Long-tail Distribution for Muti-object Tracking
DemoCaricature: Democratising Caricature Generation with a Rough Sketch
DemoFusion: Democratising High-Resolution Image Generation With No $$$
Denoising Point Clouds in Latent Space via Graph Convolution and Invertible Neural Network
Dense Optical Tracking: Connecting the Dots
Dense Vision Transformer Compression with Few Samples
Density-Adaptive Model Based on Motif Matrix for Multi-Agent Trajectory Prediction
Density-Guided Semi-Supervised 3D Semantic Segmentation with Dual-Space Hardness Sampling
Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain Adaptive Segmentation of 3D Point Clouds
Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data
Depth Information Assisted Collaborative Mutual Promotion Network for Single Image Dehazing
Depth Prompting for Sensor-Agnostic Depth Estimation
Depth-Aware Concealed Crop Detection in Dense Agricultural Scenes
Depth-aware Test-Time Training for Zero-shot Video Object Segmentation
Describing Differences in Image Sets with Natural Language
Descriptor and Word Soups: Overcoming the Parameter Efficiency Accuracy Tradeoff for Out-of-Distribution Few-shot Learning
Desigen: A Pipeline for Controllable Design Template Generation
Design2Cloth: 3D Cloth Generation from 2D Masks
DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection
DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception
Detector-Free Structure from Motion
Detours for Navigating Instructional Videos
Device-Wise Federated Network Pruning
Dexterous Grasp Transformer
DiG-IN: Diffusion Guidance for Investigating Networks - Uncovering Classifier Differences Neuron Visualisations and Visual Counterfactual Explanations
DiLiGenRT: A Photometric Stereo Dataset with Quantified Roughness and Translucency
DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning
DiSR-NeRF: Diffusion-Guided View-Consistent Super-Resolution NeRF
DiVAS: Video and Audio Synchronization with Dynamic Frame Rates
DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields
DiaLoc: An Iterative Approach to Embodied Dialog Localization
DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with Iterative Diffusion-Based Refinement
Diff-BGM: A Diffusion Model for Video Background Music Generation
Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks
DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection
DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model
DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly
DiffAvatar: Simulation-Ready Garment Optimization with Differentiable Simulation
DiffCast: A Unified Framework via Residual Diffusion for Precipitation Nowcasting
DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing
DiffForensics: Leveraging Diffusion Prior to Image Forgery Detection and Localization
DiffHuman: Probabilistic Photorealistic 3D Reconstruction of Humans
DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation
DiffLoc: Diffusion Model for Outdoor LiDAR Localization
DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with Non-linear Prediction
DiffMorpher: Unleashing the Capability of Diffusion Models for Image Morphing
DiffPerformer: Iterative Learning of Consistent Latent Guidance for Diffusion-based Human Video Generation
DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis
DiffSCI: Zero-Shot Snapshot Compressive Imaging via Iterative Spectral Diffusion Model
DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation
DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction
Diffeomorphic Template Registration for Atmospheric Turbulence Mitigation
Differentiable Display Photometric Stereo
Differentiable Information Bottleneck for Deterministic Multi-view Clustering
Differentiable Micro-Mesh Construction
Differentiable Neural Surface Refinement for Modeling Transparent Objects
Differentiable Point-based Inverse Rendering
DiffuScene: Denoising Diffusion Models for Generative Indoor Scene Synthesis
Diffuse Attend and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion
DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models
Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with Distilled Semantic Features
Diffusion Handles Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D
Diffusion Model Alignment Using Direct Preference Optimization
Diffusion Models Without Attention
Diffusion Reflectance Map: Single-Image Stochastic Inverse Rendering of Illumination and Reflectance
Diffusion Time-step Curriculum for One Image to 3D Generation
Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation
Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous and Instruction-guided Driving
Diffusion-FOF: Single-View Clothed Human Reconstruction via Diffusion-Based Fourier Occupancy Field
Diffusion-based Blind Text Image Super-Resolution
Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation
DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars
DiffusionGAN3D: Boosting Text-guided 3D Generation and Domain Adaptation by Combining 3D GANs and Diffusion Priors
DiffusionLight: Light Probes for Free by Painting a Chrome Ball
DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data
DiffusionPoser: Real-time Human Motion Reconstruction From Arbitrary Sparse Sensors Using Autoregressive Diffusion
DiffusionRegPose: Enhancing Multi-Person Pose Estimation using a Diffusion-Based End-to-End Regression Approach
DiffusionTrack: Point Set Diffusion Model for Visual Object Tracking
Digital Life Project: Autonomous 3D Characters with Social Intelligence
Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion
DisCo: Disentangled Control for Realistic Human Dance Generation
Discontinuity-preserving Normal Integration with Auxiliary Edges
Discover and Mitigate Multiple Biased Subgroups in Image Classifiers
Discovering Syntactic Interaction Clues for Human-Object Interaction Detection
Discovering and Mitigating Visual Biases through Keyword Explanation
Discriminability-Driven Channel Selection for Out-of-Distribution Detection
Discriminative Pattern Calibration Mechanism for Source-Free Domain Adaptation
Discriminative Probing and Tuning for Text-to-Image Generation
Discriminative Sample-Guided and Parameter-Efficient Feature Space Adaptation for Cross-Domain Few-Shot Learning
Disentangled Pre-training for Human-Object Interaction Detection
Disentangled Prompt Representation for Domain Generalization
Dispel Darkness for Better Fusion: A Controllable Visual Enhancer based on Cross-modal Conditional Adversarial Learning
Dispersed Structured Light for Hyperspectral 3D Imaging
Distilled Datamodel with Reverse Gradient Matching
Distilling CLIP with Dual Guidance for Learning Discriminative Human Body Shape Representation
Distilling ODE Solvers of Diffusion Models into Smaller Steps
Distilling Semantic Priors from SAM to Efficient Image Restoration Models
Distilling Vision-Language Models on Millions of Videos
Distraction is All You Need: Memory-Efficient Image Immunization against Diffusion-Based Image Editing
DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models
Distribution-aware Knowledge Prototyping for Non-exemplar Lifelong Person Re-identification
Distributionally Generative Augmentation for Fair Facial Attribute Classification
DiverGen: Improving Instance Segmentation by Learning Wider Data Distribution with More Diverse Generative Data
Diversified and Personalized Multi-rater Medical Image Segmentation
Diversity-aware Channel Pruning for StyleGAN Compression
Do Vision and Language Encoders Represent the World Similarly?
Do You Remember? Dense Video Captioning with Cross-Modal Memory Retrieval
DocRes: A Generalist Model Toward Unifying Document Image Restoration Tasks
Domain Gap Embeddings for Generative Dataset Augmentation
Domain Prompt Learning with Quaternion Networks
Domain Separation Graph Neural Networks for Saliency Object Ranking
Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation
Domain-Rectifying Adapter for Cross-Domain Few-Shot Segmentation
Domain-Specific Block Selection and Paired-View Pseudo-Labeling for Online Test-Time Adaptation
Don't Look into the Dark: Latent Codes for Pluralistic Image Inpainting
Don’t Drop Your Samples! Coherence-Aware Training Benefits Conditional Diffusion
Doodle Your 3D: From Abstract Freehand Sketches to Precise 3D Shapes
Doubly Abductive Counterfactual Inference for Text-based Image Editing
Dr. Bokeh: DiffeRentiable Occlusion-aware Bokeh Rendering
Dr.Hair: Reconstructing Scalp-Connected Hair Strands without Pre-Training via Differentiable Rendering of Line Segments
Dr2Net: Dynamic Reversible Dual-Residual Networks for Memory-Efficient Finetuning
Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation
DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing
Draw Step by Step: Reconstructing CAD Construction Sequences from Point Clouds via Multimodal Diffusion.
DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models
DreamComposer: Controllable 3D Object Generation via Multi-View Conditions
DreamControl: Control-Based Text-to-3D Generation with 3D Self-Prior
DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization
DreamPropeller: Supercharge Text-to-3D Generation with Parallel Sampling
DreamSalon: A Staged Diffusion Framework for Preserving Identity-Context in Editable Face Generation
DreamVideo: Composing Your Dream Videos with Customized Subject and Motion
DriveTrack: A Benchmark for Long-Range Point Tracking in Real-World Videos
DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving
Driving Everywhere with Large Language Model Policy Adaptation
Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving
Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance
DrivingGaussian: Composite Gaussian Splatting for Surrounding Dynamic Autonomous Driving Scenes
DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation
Dual DETRs for Multi-Label Temporal Action Detection
Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models
Dual Pose-invariant Embeddings: Learning Category and Object-specific Discriminative Representations for Recognition and Retrieval
Dual Prior Unfolding for Snapshot Compressive Imaging
Dual Prototype Attention for Unsupervised Video Object Segmentation
Dual-Consistency Model Inversion for Non-Exemplar Class Incremental Learning
Dual-Enhanced Coreset Selection with Class-wise Collaboration for Online Blurry Class Incremental Learning
Dual-Scale Transformer for Large-Scale Single-Pixel Imaging
Dual-View Visual Contextualization for Web Navigation
DualAD: Disentangling the Dynamic and Static World for End-to-End Driving
DyBluRF: Dynamic Neural Radiance Fields from Blurry Monocular Video
DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and View-Change Human-Centric Video Editing
Dynamic Adapter Meets Prompt Tuning: Parameter-Efficient Transfer Learning for Point Cloud Analysis
Dynamic Cues-Assisted Transformer for Robust Point Cloud Registration
Dynamic Graph Representation with Knowledge-aware Attention for Histopathology Whole Slide Image Analysis
Dynamic Inertial Poser (DynaIP): Part-Based Motion Dynamics Learning for Enhanced Human Pose Estimation with Sparse Inertial Sensors
Dynamic LiDAR Re-simulation using Compositional Neural Fields
Dynamic Policy-Driven Adaptive Multi-Instance Learning for Whole Slide Image Classification
Dynamic Prompt Optimizing for Text-to-Image Generation
Dynamic Support Information Mining for Category-Agnostic Pose Estimation
Dysen-VDM: Empowering Dynamics-aware Text-to-Video Diffusion with LLMs
E-GPS: Explainable Geometry Problem Solving via Top-Down Solver and Bottom-Up Generator
EAGLE: Eigen Aggregation Learning for Object-Centric Unsupervised Semantic Segmentation
EASE-DETR: Easing the Competition among Object Queries
ECLIPSE: A Resource-Efficient Text-to-Image Prior for Image Generations
ECLIPSE: Efficient Continual Learning in Panoptic Segmentation with Visual Prompt Tuning
ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation
EFHQ: Multi-purpose ExtremePose-Face-HQ dataset
EFormer: Enhanced Transformer towards Semantic-Contour Features of Foreground for Portraits Matting
EGTR: Extracting Graph from Transformer for Scene Graph Generation
EMAGE: Towards Unified Holistic Co-Speech Gesture Generation via Expressive Masked Audio Gesture Modeling
EMCAD: Efficient Multi-scale Convolutional Attention Decoding for Medical Image Segmentation
EMOPortraits: Emotion-enhanced Multimodal One-shot Head Avatars
ERMVP: Communication-Efficient and Collaboration-Robust Multi-Vehicle Perception in Challenging Environments
ESCAPE: Encoding Super-keypoints for Category-Agnostic Pose Estimation
ESR-NeRF: Emissive Source Reconstruction Using LDR Multi-view Images
ES³: Evolving Self-Supervised Learning of Robust Audio-Visual Speech Representations
EVCap: Retrieval-Augmented Image Captioning with External Visual-Name Memory for Open-World Comprehension
EVS-assisted Joint Deblurring Rolling-Shutter Correction and Video Frame Interpolation through Sensor Inverse Modeling
Each Test Image Deserves A Specific Prompt: Continual Test-Time Adaptation for 2D Medical Image Segmentation
EarthLoc: Astronaut Photography Localization by Indexing Earth from Space
EasyDrag: Efficient Point-based Manipulation on Diffusion Models
Eclipse: Disambiguating Illumination and Materials using Unintended Shadows
Edge-Aware 3D Instance Segmentation Network with Intelligent Semantic Prior
Edit One for All: Interactive Batch Image Editing
EditGuard: Versatile Image Watermarking for Tamper Localization and Copyright Protection
Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents
Effective Video Mirror Detection with Inconsistent Motion Cues
Efficient 3D Implicit Head Avatar with Mesh-anchored Hash Table Blendshapes
Efficient Dataset Distillation via Minimax Diffusion
Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator for Vision Applications
Efficient Detection of Long Consistent Cycles and its Application to Distributed Synchronization
Efficient Hyperparameter Optimization with Adaptive Fidelity Identification
Efficient LoFTR: Semi-Dense Local Feature Matching with Sparse-Like Speed
Efficient Meshflow and Optical Flow Estimation from Event Cameras
Efficient Model Stealing Defense with Noise Transition Matrix
Efficient Multi-scale Network with Learnable Discrete Wavelet Transform for Blind Motion Deblurring
Efficient Multitask Dense Predictor via Binarization
Efficient Privacy-Preserving Visual Localization Using 3D Ray Clouds
Efficient Scene Recovery Using Luminous Flux Prior
Efficient Solution of Point-Line Absolute Pose
Efficient Stitchable Task Adaptation
Efficient Test-Time Adaptation of Vision-Language Models
Efficient Vision-Language Pre-training by Cluster Masking
Efficient and Effective Weakly-Supervised Action Segmentation via Action-Transition-Aware Boundary Alignment
EfficientDreamer: High-Fidelity and Robust 3D Creation via Orthogonal-view Diffusion Priors
EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything
Efficiently Assemble Normalization Layers and Regularization for Federated Domain Generalization
Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives
EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World
EgoGen: An Egocentric Synthetic Data Generator
EgoThink: Evaluating First-Person Perspective Thinking Capability of Vision-Language Models
Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based Motion Refinement
ElasticDiffusion: Training-free Arbitrary Size Image Generation through Global-Local Content Separation
Elite360D: Towards Efficient 360 Depth Estimation via Semantic- and Distance-Aware Bi-Projection Fusion
Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld
EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI
Embracing Unimodal Aleatoric Uncertainty for Robust Multimodal Fusion
Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models
EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models
EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning
Emotional Speech-driven 3D Body Animation via Disentangled Latent Diffusion
Empowering Resampling Operation for Ultra-High-Definition Image Enhancement with Model-Aware Guidance
Emu Edit: Precise Image Editing via Recognition and Generation Tasks
En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data
End-to-End Spatio-Temporal Action Localisation with Video Transformers
End-to-End Temporal Action Detection with 1B Parameters Across 1000 Frames
Endow SAM with Keen Eyes: Temporal-spatial Prompt Learning for Video Camouflaged Object Detection
Enhance Image Classification via Inter-Class Image Mixup with Diffusion Model
Enhanced Motion-Text Alignment for Image-to-Video Transfer Learning
Enhancing 3D Fidelity of Text-to-3D using Cross-View Correspondences
Enhancing 3D Object Detection with 2D Detection-Guided Query Anchors
Enhancing Intrinsic Features for Debiasing via Investigating Class-Discerning Common Attributes in Bias-Contrastive Pair
Enhancing Multimodal Cooperation via Sample-level Modality Valuation
Enhancing Post-training Quantization Calibration through Contrastive Learning
Enhancing Quality of Compressed Images by Mitigating Enhancement Bias Towards Compression Domain
Enhancing Video Super-Resolution via Implicit Resampling-based Alignment
Enhancing Vision-Language Pre-training with Rich Supervisions
Enhancing Visual Continual Learning with Language-Guided Supervision
Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models
Enhancing the Power of OOD Detection via Sample-Aware Model Selection
Ensemble Diversity Facilitates Adversarial Transferability
Entangled View-Epipolar Information Aggregation for Generalizable Neural Radiance Fields
Entity-NeRF: Detecting and Removing Moving Entities in Urban Scenes
EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion
Epistemic Uncertainty Quantification For Pre-Trained Neural Networks
Equivariant Multi-Modality Image Fusion
Equivariant Plug-and-Play Image Reconstruction
Error Detection in Egocentric Procedural Task Videos
EscherNet: A Generative Model for Scalable View Synthesis
Estimating Extreme 3D Image Rotations using Cascaded Attention
Estimating Noisy Class Posterior with Part-level Labels for Noisy Label Learning
EvDiG: Event-guided Direct and Global Components Separation
EvalCrafter: Benchmarking and Evaluating Large Video Generation Models
Evaluating Transferability in Retrieval Tasks: An Approach Using MMD and Kernel Methods
Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline
Event-assisted Low-Light Video Object Segmentation
Event-based Structure-from-Orbit
Event-based Visible and Infrared Fusion via Multi-task Collaboration
EventDance: Unsupervised Source-free Cross-modal Adaptation for Event-based Object Recognition
EventEgo3D: 3D Human Motion Capture from Egocentric Event Streams
EventPS: Real-Time Photometric Stereo Using an Event Camera
Evidential Active Recognition: Intelligent and Prudent Open-World Embodied Perception
ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action Recognition and More
ExMap: Leveraging Explainability Heatmaps for Unsupervised Group Robustness to Spurious Correlations
Exact Fusion via Feature Distribution Matching for Few-shot Image Generation
Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental Learning
Explaining CLIP's Performance Disparities on Data from Blind/Low Vision Users
Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by Tracing their Contributions
Exploiting Diffusion Prior for Generalizable Dense Prediction
Exploiting Inter-sample and Inter-feature Relations in Dataset Distillation
Exploiting Style Latent Flows for Generalizing Deepfake Video Detection
Exploring Efficient Asymmetric Blind-Spots for Self-Supervised Denoising in Real-World Scenarios
Exploring Orthogonality in Open World Object Detection
Exploring Pose-Aware Human-Object Interaction via Hybrid Learning
Exploring Region-Word Alignment in Built-in Detector for Open-Vocabulary Object Detection
Exploring Regional Clues in CLIP for Zero-Shot Semantic Segmentation
Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches
Exploring the Potential of Large Foundation Models for Open-Vocabulary HOI Detection
Exploring the Transferability of Visual Prompting for Multimodal Large Language Models
ExtDM: Distribution Extrapolation Diffusion Model for Video Prediction
Extend Your Own Correspondences: Unsupervised Distant Point Cloud Registration by Progressive Distance Extension
ExtraNeRF: Visibility-Aware View Extrapolation of Neural Radiance Fields with Diffusion Models
Extreme Point Supervised Instance Segmentation
Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs
F3Loc: Fusion and Filtering for Floorplan Localization
FACT: Frame-Action Cross-Attention Temporal Modeling for Efficient Action Segmentation
FADES: Fair Disentanglement with Sensitive Relevance
FAR: Flexible Accurate and Robust 6DoF Relative Camera Pose Estimation
FC-GNN: Recovering Reliable and Accurate Correspondences from Interferences
FCS: Feature Calibration and Separation for Non-Exemplar Class Incremental Learning
FFF: Fixing Flawed Foundations in Contrastive Pre-Training Results in Very Strong Vision-Language Models
FINER: Flexible Spectral-bias Tuning in Implicit NEural Representation by Variable-periodic Activation Functions
FISBe: A Real-World Benchmark Dataset for Instance Segmentation of Long-Range Thin Filamentous Structures
FLHetBench: Benchmarking Device and State Heterogeneity in Federated Learning
FMA-Net: Flow-Guided Dynamic Filtering and Iterative Feature Refinement with Multi-Attention for Joint Video Super-Resolution and Deblurring
FREE: Faster and Better Data-Free Meta-Learning
FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation
FSC: Few-point Shape Completion
FSRT: Facial Scene Representation Transformer for Face Reenactment from Factorized Appearance Head-pose and Facial Expression Features
Face2Diffusion for Fast and Editable Face Personalization
FaceChain-ImagineID: Freely Crafting High-Fidelity Diverse Talking Faces from Disentangled Audio
FaceChain-SuDe: Building Derived Class to Inherit Category Attributes for One-shot Subject-Driven Generation
FaceCom: Towards High-fidelity 3D Facial Shape Completion via Optimization and Inpainting Guidance
FaceLift: Semi-supervised 3D Facial Landmark Localization
FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head Models
Faces that Speak: Jointly Synthesising Talking Face and Speech from Text
Facial Identity Anonymization via Intrinsic and Extrinsic Attention Distraction
Fair Federated Learning under Domain Skew with Local Consistency and Domain Diversity
Fair-VPT: Fair Visual Prompt Tuning for Image Classification
FairCLIP: Harnessing Fairness in Vision-Language Learning
FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication
FairRAG: Fair Human Generation via Fair Retrieval Augmentation
Fairy: Fast Parallelized Instruction-Guided Video-to-Video Synthesis
FakeInversion: Learning to Detect Images from Unseen Text-to-Image Models by Inverting Stable Diffusion
Fantastic Animals and Where to Find Them: Segment Any Marine Animal with Dual SAM
Fast Adaptation for Human Pose Estimation via Meta-Optimization
Fast ODE-based Sampling for Diffusion Models in Around 5 Steps
FastMAC: Stochastic Spectral Sampling of Correspondence Graph
Feature 3DGS: Supercharging 3D Gaussian Splatting to Enable Distilled Feature Fields
Feature Re-Embedding: Towards Foundation Model-Level Performance in Computational Pathology
FedAS: Bridging Inconsistency in Personalized Federated Learning
FedHCA2: Towards Hetero-Client Federated Multi-Task Learning
FedMef: Towards Memory-efficient Federated Dynamic Pruning
FedSOL: Stabilized Orthogonal Learning with Proximal Restrictions in Federated Learning
FedSelect: Personalized Federated Learning with Customized Selection of Parameters for Fine-Tuning
FedUV: Uniformity and Variance for Heterogeneous Federated Learning
Federated Generalized Category Discovery
Federated Online Adaptation for Deep Stereo
Feedback-Guided Autonomous Driving
Few-Shot Object Detection with Foundation Models
Few-shot Learner Parameterization by Diffusion Time-steps
Finding Lottery Tickets in Vision Models via Data-driven Spectral Foresight Pruning
Fine-Grained Bipartite Concept Factorization for Clustering
Fine-grained Prototypical Voting with Heterogeneous Mixup for Semi-supervised 2D-3D Cross-modal Retrieval
FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via Diffusion Models
FineParser: A Fine-grained Spatio-temporal Action Parser for Human-centric Action Quality Assessment
FineSports: A Multi-person Hierarchical Sports Video Dataset for Fine-grained Action Understanding
Finsler-Laplace-Beltrami Operators with Application to Shape Analysis
Fitting Flats to Flats
Fixed Point Diffusion Models
FlashAvatar: High-fidelity Head Avatar with Efficient Gaussian Embedding
FlashEval: Towards Fast and Accurate Evaluation of Text-to-image Diffusion Generative Models
Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning
Flattening the Parent Bias: Hierarchical Semantic Segmentation in the Poincaré Ball
Flexible Biometrics Recognition: Bridging the Multimodality Gap through Attention Alignment and Prompt Tuning
Flexible Depth Completion for Sparse and Varying Point Densities
Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks
Flow-Guided Online Stereo Rectification for Wide Baseline Stereo
FlowDiffuser: Advancing Optical Flow Estimation with Diffusion Models
FlowIE: Efficient Image Enhancement via Rectified Flow
FlowTrack: Revisiting Optical Flow for Long-Range Dense Tracking
FlowVQTalker: High-Quality Emotional Talking Face Generation through Normalizing Flow and Quantization
FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis
FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer
FocSAM: Delving Deeply into Focused Objects in Segmenting Anything
Focus on Hiders: Exploring Hidden Threats for Enhancing Adversarial Training
Focus on Your Instruction: Fine-grained and Multi-instruction Image Editing by Attention Modulation
FocusMAE: Gallbladder Cancer Detection from Ultrasound Videos with Focused Masked Autoencoders
Fooling Polarization-Based Vision using Locally Controllable Polarizing Projection
Forecasting of 3D Whole-body Human Poses with Grasping Objects
Forgery-aware Adaptive Transformer for Generalizable Synthetic Image Detection
FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects
Fourier Priors-Guided Diffusion for Zero-Shot Joint Low-Light Enhancement and Deblurring
Fourier-basis Functions to Bridge Augmentation Gap: Rethinking Frequency Augmentation in Image Classification
FreGS: 3D Gaussian Splatting with Progressive Frequency Regularization
Free3D: Consistent Novel View Synthesis without 3D Representation
FreeControl: Training-Free Spatial Control of Any Text-to-Image Diffusion Model with Any Condition
FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept Composition
FreeDrag: Feature Dragging for Reliable Point-based Image Editing
FreeKD: Knowledge Distillation via Semantic Frequency Prompt
FreeMan: Towards Benchmarking 3D Human Pose Estimation under Real-World Conditions
FreePoint: Unsupervised Point Cloud Instance Segmentation
FreeU: Free Lunch in Diffusion U-Net
Frequency Decoupling for Motion Magnification via Multi-Level Isomorphic Architecture
Frequency-Adaptive Dilated Convolution for Semantic Segmentation
Frequency-aware Event-based Video Deblurring for Real-World Motion Blur
Friendly Sharpness-Aware Minimization
From Activation to Initialization: Scaling Insights for Optimizing Neural Fields
From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations
From Coarse to Fine-Grained Open-Set Recognition
From Correspondences to Pose: Non-minimal Certifiably Optimal Relative Pose without Disambiguation
From Feature to Gaze: A Generalizable Replacement of Linear Layer for Gaze Estimation
From Isolated Islands to Pangea: Unifying Semantic Space for Human Action Understanding
From Pixels to Graphs: Open-Vocabulary Scene Graph Generation with Vision-Language Models
From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation
From Variance to Veracity: Unbundling and Mitigating Gradient Variance in Differentiable Bundle Adjustment Layers
From a Bird's Eye View to See: Joint Camera and Subject Registration without the Camera Calibration
From-Ground-To-Objects: Coarse-to-Fine Self-supervised Monocular Depth Estimation of Dynamic Objects with Ground Contact Prior
Frozen CLIP: A Strong Backbone for Weakly Supervised Semantic Segmentation
Frozen Feature Augmentation for Few-Shot Image Classification
Fully Convolutional Slice-to-Volume Reconstruction for Single-Stack MRI
Fully Exploiting Every Real Sample: SuperPixel Sample Gradient Model Stealing
Fully Geometric Panoramic Localization
Fun with Flags: Robust Principal Directions via Flag Manifolds
Functional Diffusion
Fusing Personal and Environmental Cues for Identification and Segmentation of First-Person Camera Wearers in Third-Person Views
FutureHuman3D: Forecasting Complex Long-Term 3D Human Behavior from Video Observations
G-FARS: Gradient-Field-based Auto-Regressive Sampling for 3D Part Grouping
G-HOP: Generative Hand-Object Prior for Interaction Reconstruction and Grasp Synthesis
G-NeRF: Geometry-enhanced Novel View Synthesis from Single-View Images
G3DR: Generative 3D Reconstruction in ImageNet
GAFusion: Adaptive Fusing LiDAR and Camera with Multiple Guidance for 3D Object Detection
GALA: Generating Animatable Layered Assets from a Single Scan
GARField: Group Anything with Radiance Fields
GART: Gaussian Articulated Template Models
GAvatar: Animatable 3D Gaussian Avatars with Implicit Mesh Learning
GDA: Generalized Diffusion for Robust Test-time Adaptation
GEARS: Local Geometry-aware Hand-object Interaction Synthesis
GES : Generalized Exponential Splatting for Efficient Radiance Field Rendering
GLACE: Global Local Accelerated Coordinate Encoding
GLID: Pre-training a Generalist Encoder-Decoder Vision Model
GLOW: Global Layout Aware Attacks on Object Detection
GLaMM: Pixel Grounding Large Multimodal Model
GLiDR: Topologically Regularized Graph Generative Network for Sparse LiDAR Point Clouds
GOAT-Bench: A Benchmark for Multi-Modal Lifelong Navigation
GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields
GP-NeRF: Generalized Perception NeRF for Context-Aware 3D Scene Understanding
GPLD3D: Latent Diffusion of 3D Shape Generative Models by Enforcing Geometric and Physical Priors
GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis
GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation
GPT4Point: A Unified Framework for Point-Language Understanding and Generation
GRAM: Global Reasoning for Multi-Page VQA
GROUNDHOG: Grounding Large Language Models to Holistic Segmentation
GS-IR: 3D Gaussian Splatting for Inverse Rendering
GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting
GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D Scene Understanding
GSVA: Generalized Segmentation via Multimodal Large Language Models
G^3-LQ: Marrying Hyperbolic Alignment with Explicit Semantic-Geometric Modeling for 3D Visual Grounding
Garment Recovery with Shape and Deformation Priors
Gated Fields: Learning Scene Reconstruction from Gated Videos
GauHuman: Articulated Gaussian Splatting from Monocular Human Videos
Gaussian Head Avatar: Ultra High-fidelity Head Avatar via Dynamic Gaussians
Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models
Gaussian Shadow Casting for Neural Characters
Gaussian Shell Maps for Efficient 3D Human Generation
Gaussian Splatting SLAM
Gaussian-Flow: 4D Reconstruction with Dynamic 3D Gaussian Particle
GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians
GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians
GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models
GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions
GaussianEditor: Swift and Controllable 3D Editing with Gaussian Splatting
GaussianShader: 3D Gaussian Splatting with Shading Functions for Reflective Surfaces
Gear-NeRF: Free-Viewpoint Rendering and Tracking with Motion-aware Spatio-Temporal Sampling
GenFlow: Generalizable Recurrent Flow for 6D Pose Refinement of Novel Objects
GenH2R: Learning Generalizable Human-to-Robot Handover via Scalable Simulation Demonstration and Imitation
GenHowTo: Learning to Generate Actions and State Transformations from Instructional Videos
GenN2N: Generative NeRF2NeRF Translation
GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction
GenTron: Diffusion Transformers for Image and Video Generation
GenZI: Zero-Shot 3D Human-Scene Interaction Generation
GeneAvatar: Generic Expression-Aware Volumetric Head Avatar Editing from a Single Image
General Object Foundation Model for Images and Videos at Scale
General Point Model Pretraining with Autoencoding and Autoregressive
Generalizable Face Landmarking Guided by Conditional Face Warping
Generalizable Novel-View Synthesis using a Stereo Camera
Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction
Generalized Event Cameras
Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching
Generalized Predictive Model for Autonomous Driving
Generalizing 6-DoF Grasp Detection via Domain Prior Knowledge
Generate Like Experts: Multi-Stage Font Generation by Incorporating Font Transfer Process into Diffusion Models
Generate Subgoal Images before Act: Unlocking the Chain-of-Thought Reasoning in Diffusion Model for Robot Manipulation with Multimodal Prompts
Generating Content for HDR Deghosting from Frequency View
Generating Enhanced Negatives for Training Language-Based Object Detectors
Generating Handwritten Mathematical Expressions From Symbol Graphs: An End-to-End Pipeline
Generating Human Motion in 3D Scenes from Text Descriptions
Generating Illustrated Instructions
Generating Non-Stationary Textures using Self-Rectification
Generative 3D Part Assembly via Part-Whole-Hierarchy Message Passing
Generative Image Dynamics
Generative Latent Coding for Ultra-Low Bitrate Image Compression
Generative Multi-modal Models are Good Class Incremental Learners
Generative Multimodal Models are In-Context Learners
Generative Powers of Ten
Generative Proxemics: A Prior for 3D Social Interaction from Images
Generative Quanta Color Imaging
Generative Region-Language Pretraining for Open-Ended Object Detection
Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models
Generative Unlearning for Any Identity
GenesisTex: Adapting Image Denoising Diffusion to Texture Space
Genuine Knowledge from Practice: Diffusion Test-Time Adaptation for Video Adverse Weather Removal
GeoAuxNet: Towards Universal 3D Representation Learning for Multi-sensor Point Clouds
GeoChat: Grounded Large Vision-Language Model for Remote Sensing
GeoReF: Geometric Alignment Across Shape Variation for Category-level Object Pose Refinement
Geometrically-driven Aggregation for Zero-shot 3D Point Cloud Understanding
Geometry Transfer for Stylizing Radiance Fields
Geometry-aware Reconstruction and Fusion-refined Rendering for Generalizable Neural Radiance Fields
GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence
GigaTraj: Predicting Long-term Trajectories of Hundreds of Pedestrians in Gigapixel Complex Scenes
GlitchBench: Can Large Multimodal Models Detect Video Game Glitches?
Global Latent Neural Rendering
Global and Hierarchical Geometry Consistency Priors for Few-shot NeRFs in Indoor Scenes
Global and Local Prompts Cooperation via Optimal Transport for Federated Learning
GoMAvatar: Efficient Animatable Human Modeling from Monocular Video Using Gaussians-on-Mesh
GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo
Going Beyond Multi-Task Dense Prediction with Synergy Embedding Models
GoodSAM: Bridging Domain and Capacity Gaps via Segment Anything Model for Distortion-aware Panoramic Semantic Segmentation
GraCo: Granularity-Controllable Interactive Segmentation
Gradient Alignment for Cross-Domain Face Anti-Spoofing
Gradient Reweighting: Towards Imbalanced Class-Incremental Learning
Gradient-based Parameter Selection for Efficient Fine-Tuning
GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs
GreedyViG: Dynamic Axial Graph Construction for Efficient Vision GNNs
Grid Diffusion Models for Text-to-Video Generation
Grounded Question-Answering in Long Egocentric Videos
Grounded Text-to-Image Synthesis with Attention Refocusing
Grounding Everything: Emerging Localization Properties in Vision-Language Transformers
Grounding and Enhancing Grid-based Models for Neural Fields
GroupContrast: Semantic-aware Self-supervised Representation Learning for 3D Understanding
Groupwise Query Specialization and Quality-Aware Multi-Assignment for Transformer-based Visual Relationship Detection
Guess The Unseen: Dynamic 3D Scene Reconstruction from Partial 2D Glimpses
Guided Slot Attention for Unsupervised Video Object Segmentation
H-ViT: A Hierarchical Vision Transformer for Deformable Image Registration
HAVE-FUN: Human Avatar Reconstruction from Few-Shot Unconstrained Images
HDQMF: Holographic Feature Decomposition Using Quantum Algorithms
HDRFlow: Real-Time HDR Video Reconstruction with Large Motions
HEAL-SWIN: A Vision Transformer On The Sphere
HHMR: Holistic Hand Mesh Recovery by Enhancing the Multimodal Controllability of Graph Diffusion Models
HIG: Hierarchical Interlacement Graph Approach to Scene Graph Generation in Video Understanding
HIMap: HybrId Representation Learning for End-to-end Vectorized HD Map Construction
HINTED: Hard Instance Enhanced Detector with Mixed-Density Feature Fusion for Sparsely-Supervised 3D Object Detection
HIPTrack: Visual Tracking with Historical Prompts
HIR-Diff: Unsupervised Hyperspectral Image Restoration Via Improved Diffusion Models
HIT: Estimating Internal Human Implicit Tissues from the Body Surface
HIVE: Harnessing Human Feedback for Instructional Visual Editing
HMD-Poser: On-Device Real-time Human Motion Tracking from Scalable Sparse Observations
HOI-M^3: Capture Multiple Humans and Objects Interaction within Contextual Environment
HOIAnimator: Generating Text-prompt Human-object Animations using Novel Perceptive Diffusion Models
HOIDiffusion: Generating Realistic 3D Hand-Object Interaction Data
HOISDF: Constraining 3D Hand-Object Pose Estimation with Global Signed Distance Fields
HOIST-Former: Hand-held Objects Identification Segmentation and Tracking in the Wild
HOLD: Category-agnostic 3D Reconstruction of Interacting Hands and Objects from Video
HPL-ESS: Hybrid Pseudo-Labeling for Unsupervised Event-based Semantic Segmentation
HPNet: Dynamic Trajectory Forecasting with Historical Prediction Attention
HRVDA: High-Resolution Visual Document Assistant
HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting
HUGS: Human Gaussian Splats
HUNTER: Unsupervised Human-centric 3D Detection via Transferring Knowledge from Synthetic Instances to Real Scenes
Habitat Synthetic Scenes Dataset (HSSD-200): An Analysis of 3D Scene Scale and Realism Tradeoffs for ObjectGoal Navigation
HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data
Hallucination Augmented Contrastive Learning for Multimodal Large Language Model
HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models
HanDiffuser: Text-to-Image Generation With Realistic Hand Appearances
HandBooster: Boosting 3D Hand-Mesh Reconstruction by Conditional Synthesis and Sampling of Hand-Object Interactions
HandDiff: 3D Hand Pose Estimation with Diffusion on Image-Point Cloud
HardMo: A Large-Scale Hardcase Dataset for Motion Capture
HarmonyView: Harmonizing Consistency and Diversity in One-Image-to-3D
Harnessing Large Language Models for Training-free Video Anomaly Detection
Harnessing Meta-Learning for Improving Full-Frame Video Stabilization
Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID
HashPoint: Accelerated Point Searching and Sampling for Neural Rendering
Hearing Anything Anywhere
HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian Splatting
HiKER-SGG: Hierarchical Knowledge Enhanced Robust Scene Graph Generation
HiLo: Detailed and Robust 3D Clothed Human Reconstruction with High-and Low-Frequency Information of Parametric Models
HiPose: Hierarchical Binary Surface Encoding and Correspondence Pruning for RGB-D 6DoF Object Pose Estimation
Hide in Thicket: Generating Imperceptible and Rational Adversarial Perturbations on 3D Point Clouds
Hierarchical Correlation Clustering and Tree Preserving Embedding
Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation
Hierarchical Histogram Threshold Segmentation – Auto-terminating High-detail Oversegmentation
Hierarchical Intra-modal Correlation Learning for Label-free 3D Semantic Segmentation
Hierarchical Patch Diffusion Models for High-Resolution Video Generation
Hierarchical Spatio-temporal Decoupling for Text-to-Video Generation
High-Quality Facial Geometry and Appearance Capture at Home
High-fidelity Person-centric Subject-to-Image Synthesis
Higher-order Relational Reasoning for Pedestrian Trajectory Prediction
Holistic Autonomous Driving Understanding by Bird’s-Eye-View Injected Multi-Modal Large Models
Holistic Features are almost Sufficient for Text-to-Video Retrieval
Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image
HoloVIC: Large-scale Dataset and Benchmark for Multi-Sensor Holographic Intersection and Vehicle-Infrastructure Cooperative
Holodeck: Language Guided Generation of 3D Embodied AI Environments
Holoported Characters: Real-time Free-viewpoint Rendering of Humans from Sparse RGB Cameras
HomoFormer: Homogenized Transformer for Image Shadow Removal
Honeybee: Locality-enhanced Projector for Multimodal LLM
Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation
HouseCat6D - A Large-Scale Multi-Modal Category Level 6D Object Perception Dataset with Household Objects in Realistic Scenarios
How Far Can We Compress Instant-NGP-Based NeRF?
How to Configure Good In-Context Sequence for Visual Question Answering
How to Handle Sketch-Abstraction in Sketch-Based Image Retrieval?
How to Make Cross Encoder a Good Teacher for Efficient Image-Text Retrieval?
How to Train Neural Field Representations: A Comprehensive Study and Benchmark
HumMUSS: Human Motion Understanding using State Space Models
Human Gaussian Splatting: Real-time Rendering of Animatable Avatars
Human Motion Prediction Under Unexpected Perturbation
HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting
HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with Diverse Poses
HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation
HumanRef: Single Image to 3D Human Generation via Reference-Guided Diffusion
Hunting Attributes: Context Prototype-Aware Learning for Weakly Supervised Semantic Segmentation
Hybrid Functional Maps for Crease-Aware Non-Isometric Shape Matching
Hybrid Proposal Refiner: Revisiting DETR Series from the Faster R-CNN Perspective
HybridNeRF: Efficient Neural Rendering via Adaptive Volumetric Surfaces
Hyper-MD: Mesh Denoising with Customized Parameters Aware of Noise Intensity and Geometric Characteristics
HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models
HyperSDFusion: Bridging Hierarchical Structures in Language and Geometry for Enhanced 3D Text2Shape Generation
Hyperbolic Anomaly Detection
Hyperbolic Learning with Synthetic Captions for Open-World Detection
Hyperspherical Classification with Dynamic Label-to-Prototype Assignment
I'M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions
IBD-SLAM: Learning Image-Based Depth Fusion for Generalizable SLAM
ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization
ICP-Flow: LiDAR Scene Flow Estimation with ICP
ID-Blau: Image Deblurring by Implicit Diffusion-based reBLurring AUgmentation
ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection
IDGuard: Robust General Identity-centric POI Proactive Defense Against Face Editing Abuse
IIRP-Net: Iterative Inference Residual Pyramid Network for Enhanced Image Registration
IMPRINT: Generative Object Compositing by Learning Identity-Preserving Representation
IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images
IQ-VFI: Implicit Quadratic Motion Estimation for Video Frame Interpolation
IReNe: Instant Recoloring of Neural Radiance Fields
IS-Fusion: Instance-Scene Collaborative Fusion for Multimodal 3D Object Detection
Identifying Important Group of Pixels using Interactions
Image Neural Field Diffusion Models
Image Processing GNN: Breaking Rigidity in Super-Resolution
Image Restoration by Denoising Diffusion Models with Iteratively Preconditioned Guidance
Image Sculpting: Precise Object Editing with 3D Geometry Control
Image-Text Co-Decomposition for Text-Supervised Semantic Segmentation
Image-to-Image Matching via Foundation Models: A New Perspective for Open-Vocabulary Semantic Segmentation
ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object
Imagine Before Go: Self-Supervised Generative Map for Object Goal Navigation
Implicit Discriminative Knowledge Learning for Visible-Infrared Person Re-Identification
Implicit Event-RGBD Neural SLAM
Implicit Motion Function
Improved Baselines with Visual Instruction Tuning
Improved Implicit Neural Representation with Fourier Reparameterized Training
Improved Self-Training for Test-Time Adaptation
Improved Visual Grounding through Self-Consistent Explanations
Improved Zero-Shot Classification by Adapting VLMs with Text Descriptions
Improving Bird's Eye View Semantic Segmentation by Task Decomposition
Improving Depth Completion via Depth Feature Upsampling
Improving Distant 3D Object Detection Using 2D Box Supervision
Improving Generalization via Meta-Learning on Hard Samples
Improving Generalized Zero-Shot Learning by Exploring the Diverse Semantics from External Class Names
Improving Graph Contrastive Learning via Adaptive Positive Sampling
Improving Image Restoration through Removing Degradations in Textual Representations
Improving Out-of-Distribution Generalization in Graphs via Hierarchical Semantic Environments
Improving Physics-Augmented Continuum Neural Radiance Field-Based Geometry-Agnostic System Identification with Lagrangian Particle Optimization
Improving Plasticity in Online Continual Learning via Collaborative Learning
Improving Semantic Correspondence with Viewpoint-Guided Spherical Maps
Improving Single Domain-Generalized Object Detection: A Focus on Diversification and Alignment
Improving Spectral Snapshot Reconstruction with Spectral-Spatial Rectification
Improving Subject-Driven Image Synthesis with Subject-Agnostic Guidance
Improving Training Efficiency of Diffusion Models via Multi-Stage Framework and Tailored Multi-Decoder Architecture
Improving Transferable Targeted Adversarial Attacks with Model Self-Enhancement
Improving Unsupervised Hierarchical Representation with Reinforcement Learning
Improving Visual Recognition with Hyperbolical Visual Hierarchy Mapping
Improving the Generalization of Segmentation Foundation Model under Distribution Shift via Weakly Supervised Adaptation
In Search of a Data Transformation That Accelerates Neural Field Training
In-Context Matting
In-N-Out: Faithful 3D GAN Inversion with Volumetric Decomposition for Face Editing
In-distribution Public Data Synthesis with Diffusion Models for Differentially Private Image Classification
In2SET: Intra-Inter Similarity Exploiting Transformer for Dual-Camera Compressive Hyperspectral Imaging
InNeRF360: Text-Guided 3D-Consistent Object Inpainting on 360-degree Neural Radiance Fields
InceptionNeXt: When Inception Meets ConvNeXt
Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition
Incremental Nuclei Segmentation from Histopathological Images via Future-class Awareness and Compatibility-inspired Distillation
Incremental Residual Concept Bottleneck Models
InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning
Infer from What You Have Seen Before: Temporally-dependent Classifier for Semi-supervised Video Segmentation
Infinigen Indoors: Photorealistic Indoor Scenes using Procedural Generation
Infrared Adversarial Car Stickers
Infrared Small Target Detection with Scale and Location Sensitivity
InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization
Initialization Matters for Adversarial Transfer Learning
Ink Dot-Oriented Differentiable Optimization for Neural Image Halftoning
Inlier Confidence Calibration for Point Cloud Registration
Insect-Foundation: A Foundation Model and Large-scale 1M Dataset for Visual Insect Understanding
Insights from the Use of Previously Unseen Neural Architecture Search Datasets
InstaGen: Enhancing Object Detection by Training on Synthetic Dataset
Instance Tracking in 3D Scenes from Egocentric Videos
Instance-Adaptive and Geometric-Aware Keypoint Learning for Category-Level 6D Object Pose Estimation
Instance-Aware Group Quantization for Vision Transformers
Instance-aware Contrastive Learning for Occluded Human Mesh Reconstruction
Instance-aware Exploration-Verification-Exploitation for Instance ImageGoal Navigation
Instance-based Max-margin for Practical Few-shot Recognition
Instance-level Expert Knowledge and Aggregate Discriminative Attention for Radiology Report Generation
InstanceDiffusion: Instance-level Control for Image Generation
InstantBooth: Personalized Text-to-Image Generation without Test-Time Finetuning
Instantaneous Perception of Moving Objects in 3D
Instruct 4D-to-4D: Editing 4D Scenes as Pseudo-3D Scenes Using 2D Diffusion
Instruct-Imagen: Image Generation with Multi-modal Instruction
Instruct-ReID: A Multi-purpose Person Re-identification Task with Instructions
InstructDiffusion: A Generalist Modeling Interface for Vision Tasks
InstructVideo: Instructing Video Diffusion Models with Human Feedback
Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning
Intelligent Grimm - Open-ended Visual Storytelling via Latent Diffusion Models
Intensity-Robust Autofocus for Spike Camera
Inter-X: Towards Versatile Human-Human Interaction Analysis
InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse Diffusion
InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models
Interactive Continual Learning: Fast and Slow Thinking
Interactive3D: Create What You Want by Interactive 3D Generation
InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks
Interpretable Measures of Conceptual Similarity by Complexity-Constrained Descriptive Auto-Encoding
Intraoperative 2D/3D Image Registration via Differentiable X-ray Rendering
Intriguing Properties of Diffusion Models: An Empirical Study of the Natural Attack Capability in Text-to-Image Generative Models
Intrinsic Image Diffusion for Indoor Single-view Material Estimation
IntrinsicAvatar: Physically Based Inverse Rendering of Dynamic Humans from Monocular Videos via Explicit Ray Tracing
Inverse Rendering of Glossy Objects via the Neural Plenoptic Function and Radiance Fields
Inversion-Free Image Editing with Language-Guided Diffusion Models
Investigating Compositional Challenges in Vision-Language Models for Visual Grounding
Investigating and Mitigating the Side Effects of Noisy Views for Self-Supervised Clustering Algorithms in Practical Multi-View Scenarios
Is Ego Status All You Need for Open-Loop End-to-End Autonomous Driving?
Is Vanilla MLP in Neural Radiance Field Enough for Few-shot View Synthesis?
It's All About Your Sketch: Democratising Sketch Control in Diffusion Models
Iterated Learning Improves Compositionality in Large Vision-Language Models
JDEC: JPEG Decoding via Enhanced Continuous Cosine Coefficients
JRDB-PanoTrack: An Open-world Panoptic Segmentation and Tracking Robotic Dataset in Crowded Human Environments
JRDB-Social: A Multifaceted Robotic Dataset for Understanding of Context and Dynamics of Human Interactions Within Social Groups
Jack of All Tasks Master of Many: Designing General-Purpose Coarse-to-Fine Vision-Language Model
JeDi: Joint-Image Diffusion Models for Finetuning-Free Personalized Text-to-Image Generation
JoAPR: Cleaning the Lens of Prompt Learning for Vision-Language Models
Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer
Joint-Task Regularization for Partially Labeled Multi-Task Learning
Joint2Human: High-Quality 3D Human Generation via Compact Spherical Embedding of 3D Joints
JointSQ: Joint Sparsification-Quantization for Distributed Learning
Jointly Training and Pruning CNNs via Learnable Agent Guidance and Alignment
Just Add ?! Pose Induced Video Transformers for Understanding Activities of Daily Living
KD-DETR: Knowledge Distillation for Detection Transformer with Consistent Distillation Points Sampling
KITRO: Refining Human Mesh by 2D Clues and Kinematic-tree Rotation
KP-RED: Exploiting Semantic Keypoints for Joint 3D Shape Retrieval and Deformation
KPConvX: Modernizing Kernel Point Convolution with Kernel Attention
KTPFormer: Kinematics and Trajectory Prior Knowledge-Enhanced Transformer for 3D Human Pose Estimation
KVQ: Kwai Video Quality Assessment for Short-form Videos
Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms
Kernel Adaptive Convolution for Scene Text Detection via Distance Map Prediction
KeyPoint Relative Position Encoding for Face Recognition
Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning
Knowledge-Enhanced Dual-stream Zero-shot Composed Image Retrieval
Koala: Key Frame-Conditioned Long Video-LLM
L-MAGIC: Language Model Assisted Generation of Images with Coherence
L0-Sampler: An L0 Model Guided Volume Sampling for NeRF
L2B: Learning to Bootstrap Robust Models for Combating Label Noise
L4D-Track: Language-to-4D Modeling Towards 6-DoF Tracking and Shape Reconstruction in 3D Point Cloud Stream
LAA-Net: Localized Artifact Attention Network for Quality-Agnostic and Generalizable Deepfake Detection
LAENeRF: Local Appearance Editing for Neural Radiance Fields
LAFS: Landmark-based Facial Self-supervised Learning for Face Recognition
LAKE-RED: Camouflaged Images Generation by Latent Background Knowledge Retrieval-Augmented Diffusion
LAMP: Learn A Motion Pattern for Few-Shot Video Generation
LAN: Learning to Adapt Noise for Image Denoising
LASA: Instance Reconstruction from Real Scans using A Large-scale Aligned Shape Annotation Dataset
LASIL: Learner-Aware Supervised Imitation Learning For Long-term Microscopic Traffic Simulation
LASO: Language-guided Affordance Segmentation on 3D Object
LDP: Language-driven Dual-Pixel Image Defocus Deblurring Network
LEAD: Exploring Logit Space Evolution for Model Selection
LEAD: Learning Decomposition for Source-free Universal Domain Adaptation
LEAP-VO: Long-term Effective Any Point Tracking for Visual Odometry
LED: A Large-scale Real-world Paired Dataset for Event Camera Denoising
LEDITS++: Limitless Image Editing using Text-to-Image Models
LEMON: Learning 3D Human-Object Interaction Relation from 2D Images
LEOD: Label-Efficient Object Detection for Event Cameras
LION: Empowering Multimodal Large Language Model with Dual-Level Visual Knowledge
LISA: Reasoning Segmentation via Large Language Model
LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding Reasoning and Planning
LLM4SGG: Large Language Models for Weakly Supervised Scene Graph Generation
LLMs are Good Action Recognizers
LLMs are Good Sign Language Translators
LLaFS: When Large Language Models Meet Few-Shot Segmentation
LLaMA-Excitor: General Instruction Tuning via Indirect Feature Interaction
LMDrive: Closed-Loop End-to-End Driving with Large Language Models
LORS: Low-rank Residual Structure for Parameter-Efficient Network Stacking
LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning
LP++: A Surprisingly Strong Linear Probe for Few-Shot CLIP
LPSNet: End-to-End Human Pose and Shape Estimation with Lensless Imaging
LQMFormer: Language-aware Query Mask Transformer for Referring Image Segmentation
LSK3DNet: Towards Effective and Efficient 3D Perception with Large Sparse Kernels
LTA-PCS: Learnable Task-Agnostic Point Cloud Sampling
LTGC: Long-tail Recognition via Leveraging LLMs-driven Generated Content
LTM: Lightweight Textured Mesh Extraction and Refinement of Large Unbounded Scenes for Efficient Storage and Real-time Rendering
LUWA Dataset: Learning Lithic Use-Wear Analysis on Microscopic Images
LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs
LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated Image Detection
Label Propagation for Zero-shot Classification with Vision-Language Models
Label-Efficient Group Robustness via Out-of-Distribution Concept Curation
Lane2Seq: Towards Unified Lane Detection via Sequence Generation
LaneCPP: Continuous 3D Lane Detection using Physical Priors
LangSplat: 3D Language Gaussian Splatting
Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding
Language Model Guided Interpretable Video Action Reasoning
Language Models as Black-Box Optimizers for Vision-Language Models
Language-Driven Anchors for Zero-Shot Adversarial Robustness
Language-aware Visual Semantic Distillation for Video Question Answering
Language-conditioned Detection Transformer
Language-driven All-in-one Adverse Weather Removal
Language-driven Grasp Detection
Language-driven Object Fusion into Neural Radiance Fields with Pose-Conditioned Dataset Updates
Language-guided Image Reflection Separation
Language-only Training of Zero-shot Composed Image Retrieval
Laplacian-guided Entropy Model in Neural Codec with Blur-dissipated Synthesis
Large Language Models are Good Prompt Learners for Low-Shot Image Classification
Latency Correction for Event-guided Deblurring and Frame Interpolation
Latent Modulated Function for Computational Optimal Continuous Image Representation
Layout-Agnostic Scene Text Image Synthesis with Diffusion Models
LayoutFormer: Hierarchical Text Detection Towards Scene Text Understanding
LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding
LeGO: Leveraging a Surface Deformation Network for Animatable Stylized Face Generation with One Example
Leak and Learn: An Attacker's Cookbook to Train Using Leaked Data from Federated Learning
Learn from View Correlation: An Anchor Enhancement Strategy for Multi-view Clustering
Learn to Rectify the Bias of CLIP for Unsupervised Semantic Segmentation
Learnable Earth Parser: Discovering 3D Prototypes in Aerial Scans
Learned Lossless Image Compression based on Bit Plane Slicing
Learned Representation-Guided Diffusion Models for Large-Image Generation
Learned Scanpaths Aid Blind Panoramic Video Quality Assessment
Learned Trajectory Embedding for Subspace Clustering
Learning Adaptive Spatial Coherent Correlations for Speech-Preserving Facial Expression Manipulation
Learning Background Prompts to Discover Implicit Knowledge for Open Vocabulary Object Detection
Learning CNN on ViT: A Hybrid Model to Explicitly Class-specific Boundaries for Domain Adaptation
Learning Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification
Learning Continuous 3D Words for Text-to-Image Generation
Learning Correlation Structures for Vision Transformers
Learning Coupled Dictionaries from Unpaired Data for Image Super-Resolution
Learning Degradation-Independent Representations for Camera ISP Pipelines
Learning Degradation-unaware Representation with Prior-based Latent Transformations for Blind Face Restoration
Learning Diffusion Texture Priors for Image Restoration
Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection
Learning Disentangled Identifiers for Action-Customized Text-to-Image Generation
Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis
Learning Equi-angular Representations for Online Continual Learning
Learning Group Activity Features Through Person Attribute Prediction
Learning Inclusion Matching for Animation Paint Bucket Colorization
Learning Instance-Aware Correspondences for Robust Multi-Instance Point Cloud Registration in Cluttered Scenes
Learning Intra-view and Cross-view Geometric Knowledge for Stereo Matching
Learning Large-Factor EM Image Super-Resolution with Generative Priors
Learning Multi-Dimensional Human Preference for Text-to-Image Generation
Learning Object State Changes in Videos: An Open-World Perspective
Learning Occupancy for Monocular 3D Object Detection
Learning SO(3)-Invariant Semantic Correspondence via Local Shape Transform
Learning Spatial Adaptation and Temporal Coherence in Diffusion Models for Video Super-Resolution
Learning Spatial Features from Audio-Visual Correspondence in Egocentric Videos
Learning Structure-from-Motion with Graph Attention Networks
Learning Transferable Negative Prompts for Out-of-Distribution Detection
Learning Triangular Distribution in Visual World
Learning Vision from Models Rivals Learning Vision from Data
Learning Visual Prompt for Gait Recognition
Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning
Learning for Transductive Threshold Calibration in Open-World Recognition
Learning from Observer Gaze: Zero-Shot Attention Prediction Oriented by Human-Object Interaction Recognition
Learning from One Continuous Video Stream
Learning from Synthetic Human Group Activities
Learning the 3D Fauna of the Web
Learning to Control Camera Exposure via Reinforcement Learning
Learning to Count without Annotations
Learning to Localize Objects Improves Spatial Reasoning in Visual-LLMs
Learning to Navigate Efficiently and Precisely in Real Environments
Learning to Predict Activity Progress by Self-Supervised Video Alignment
Learning to Produce Semi-dense Correspondences for Visual Localization
Learning to Rank Patches for Unbiased Image Redundancy Reduction
Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval
Learning to Remove Wrinkled Transparent Film with Polarized Prior
Learning to Segment Referred Objects from Narrated Egocentric Videos
Learning to Select Views for Efficient Multi-View Understanding
Learning to Transform Dynamically for Better Adversarial Transferability
Learning to Visually Localize Sound Sources from Mixtures without Prior Source Knowledge
Learning with Structural Labels for Learning with Noisy Labels
Learning with Unreliability: Fast Few-shot Voxel Radiance Fields with Relative Geometric Consistency
Learning without Exact Guidance: Updating Large-scale High-resolution Land Cover Maps from Low-resolution Historical Labels
LeftRefill: Filling Right Canvas based on Left Reference through Generalized Text-to-Image Diffusion Model
Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation
Leveraging Camera Triplets for Efficient and Accurate Structure-from-Motion
Leveraging Cross-Modal Neighbor Representation for Improved CLIP Classification
Leveraging Frame Affinity for sRGB-to-RAW Video De-rendering
Leveraging Predicate and Triplet Learning for Scene Graph Generation
Leveraging Vision-Language Models for Improving Domain Generalization in Image Classification
LiDAR-Net: A Real-scanned 3D Point Cloud Dataset for Indoor Scenes
LiDAR-based Person Re-identification
LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis
LiSA: LiDAR Localization with Semantic Awareness
LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes
Lift3D: Zero-Shot Lifting of Any 2D Vision Model to 3D
Light the Night: A Multi-Condition Diffusion Framework for Unpaired Low-Light Enhancement in Autonomous Driving
LightIt: Illumination Modeling and Control for Diffusion Models
LightOctree: Lightweight 3D Spatially-Coherent Indoor Lighting Estimation
Linguistic-Aware Patch Slimming Framework for Fine-grained Cross-Modal Alignment
Link-Context Learning for Multimodal LLMs
LiveHPS: LiDAR-based Scene-level Human Pose and Shape Estimation in Free Environment
Living Scenes: Multi-object Relocalization and Reconstruction in Changing 3D Environments
LoCoNet: Long-Short Context Network for Active Speaker Detection
LoS: Local Structure-Guided Stereo Matching
LoSh: Long-Short Text Joint Prediction Network for Referring Video Object Segmentation
LocLLM: Exploiting Generalizable Human Keypoint Localization via Large Language Model
Local-consistent Transformation Learning for Rotation-invariant Point Cloud Analysis
Localization Is All You Evaluate: Data Leakage in Online Mapping Datasets and How to Fix It
Locally Adaptive Neural 3D Morphable Models
Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation Guided by the Characteristic Dance Primitives
Logarithmic Lenses: Exploring Log RGB Data for Image Classification
Logit Standardization in Knowledge Distillation
Long-Tail Class Incremental Learning via Independent Sub-prototype Construction
Long-Tailed Anomaly Detection with Learnable Class Names
Look-Up Table Compression for Efficient Image Restoration
Lookahead Exploration with Neural Radiance Representation for Continuous Vision-Language Navigation
Looking 3D: Anomaly Detection with 2D-3D Alignment
Looking Similar Sounding Different: Leveraging Counterfactual Cross-Modal Pairs for Audiovisual Representation Learning
Loopy-SLAM: Dense Neural SLAM with Loop Closures
Loose Inertial Poser: Motion Capture with IMU-attached Loose-Wear Jacket
Low-Latency Neural Stereo Streaming
Low-Rank Approximation for Sparse Attention in Multi-Modal LLMs
Low-Rank Knowledge Decomposition for Medical Foundation Models
Low-Rank Rescaled Vision Transformer Fine-Tuning: A Residual Design Approach
Low-Res Leads the Way: Improving Generalization for Super-Resolution by Self-Supervised Learning
Low-Resource Vision Challenges for Foundation Models
Low-power Continuous Remote Behavioral Localization with Event Cameras
LowRankOcc: Tensor Decomposition and Low-Rank Recovery for Vision-based 3D Semantic Occupancy Prediction
LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching
M&M VTO: Multi-Garment Virtual Try-On and Editing
M3-UDA: A New Benchmark for Unsupervised Domain Adaptive Fetal Cardiac Structure Detection
MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding
MACE: Mass Concept Erasure in Diffusion Models
MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer
MAFA: Managing False Negatives for Vision-Language Pre-training
MAGICK: A Large-scale Captioned Dataset from Matting Generated Images using Chroma Keying
MANUS: Markerless Grasp Capture using Articulated 3D Gaussians
MAP: MAsk-Pruning for Source-Free Model Intellectual Property Protection
MAPLM: A Real-World Large-Scale Vision-Language Benchmark for Map and Traffic Scene Understanding
MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling
MART: Masked Affective RepresenTation Learning via Masked Temporal Distribution Distillation
MAS: Multi-view Ancestral Sampling for 3D Motion Generation Using 2D Diffusion
MCD: Diverse Large-Scale Multi-Campus Dataset for Robot Perception
MCNet: Rethinking the Core Ingredients for Accurate and Efficient Homography Estimation
MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes
MESA: Matching Everything by Segmenting Anything
MFP: Making Full Use of Probability Maps for Interactive Image Segmentation
MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction
MICap: A Unified Model for Identity-Aware Movie Descriptions
MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis
MLIP: Enhancing Medical Visual Representation with Divergence Encoder and Knowledge-guided Contrastive Learning
MLP Can Be A Good Transformer Learner
MM-Narrator: Narrating Long-form Videos with Multimodal In-Context Learning
MMA-Diffusion: MultiModal Attack on Diffusion Models
MMA: Multi-Modal Adapter for Vision-Language Models
MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models
MMM: Generative Masked Motion Model
MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI
MMSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos
MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors
MOHO: Learning Single-view Hand-held Object Reconstruction with Multi-view Occlusion-Aware Supervision
MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active Perception
MPOD123: One Image to 3D Content Generation Using Mask-enhanced Progressive Outline-to-Detail Optimization
MR-VNet: Media Restoration using Volterra Networks
MRC-Net: 6-DoF Pose Estimation with MultiScale Residual Correlation
MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with Multi-Resolution Feature Perturbation
MRFS: Mutually Reinforcing Image Fusion and Segmentation
MS-DETR: Efficient DETR Training with Mixed Supervision
MS-MANO: Enabling Hand Pose Tracking with Biomechanical Constraints
MSU-4S - The Michigan State University Four Seasons Dataset
MTLoRA: Low-Rank Adaptation Approach for Efficient Multi-Task Learning
MTMMC: A Large-Scale Real-World Multi-Modal Camera Tracking Benchmark
MULAN: A Multi Layer Annotated Dataset for Controllable Text-to-Image Generation
MULDE: Multiscale Log-Density Estimation via Denoising Score Matching for Video Anomaly Detection
MULTIFLOW: Shifting Towards Task-Agnostic Vision-Language Pruning
MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval
MVBench: A Comprehensive Multi-modal Video Understanding Benchmark
MVCPS-NeuS: Multi-view Constrained Photometric Stereo for Neural Surface Reconstruction
MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation
MVHumanNet: A Large-scale Dataset of Multi-view Daily Dressing Human Captures
MVIP-NeRF: Multi-view 3D Inpainting on NeRF Scenes via Diffusion Prior
MaGGIe: Masked Guided Gradual Human Instance Matting
Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification
MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model
Make Me a BNN: A Simple Strategy for Estimating Bayesian Uncertainty from Pre-trained Models
Make Pixels Dance: High-Dynamic Video Generation
Make-It-Vivid: Dressing Your Animatable Biped Cartoon Characters from Text
Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework
Makeup Prior Models for 3D Facial Makeup Estimation and Applications
Making Vision Transformers Truly Shift-Equivariant
Making Visual Sense of Oracle Bones for You and Me
ManiFPT: Defining and Analyzing Fingerprints of Generative Models
ManipLLM: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation
Map-Relative Pose Regression for Visual Re-Localization
MarkovGen: Structured Prediction for Efficient Text-to-Image Generation
Mask Grounding for Referring Image Segmentation
Mask4Align: Aligned Entity Prompting with Color Masks for Multi-Entity Localization Problems
MaskCLR: Attention-Guided Contrastive Learning for Robust Action Representation Learning
MaskClustering: View Consensus based Mask Graph Clustering for Open-Vocabulary 3D Instance Segmentation
MaskINT: Video Editing via Interpolative Non-autoregressive Masked Transformers
MaskPLAN: Masked Generative Layout Planning from Partial Input
Masked AutoDecoder is Effective Multi-Task Vision Generalist
Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology
Masked Spatial Propagation Network for Sparsity-Adaptive Depth Refinement
Masked and Shuffled Blind Spot Denoising for Real-World Images
MatFuse: Controllable Material Generation with Diffusion Models
MatSynth: A Modern PBR Materials Dataset
MatchU: Matching Unseen Objects for 6D Pose Estimation from RGB-D Images
Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences
Matching Anything by Segmenting Anything
Material Palette: Extraction of Materials from a Single Image
MaxQ: Multi-Axis Query for N:M Sparsity Network
MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models
MeaCap: Memory-Augmented Zero-shot Image Captioning
Mean-Shift Feature Transformer
MedBN: Robust Test-Time Adaptation against Malicious Test Samples
MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant
MemFlow: Optical Flow Estimation and Prediction with Memory
MemSAM: Taming Segment Anything Model for Echocardiography Video Segmentation
MemoNav: Working Memory Model for Visual Navigation
Memory-Scalable and Simplified Functional Map Learning
Memory-based Adapters for Online 3D Scene Perception
MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers
MeshPose: Unifying DensePose and 3D Body Mesh Reconstruction
Meta-Point Learning and Refining for Category-Agnostic Pose Estimation
MetaCloak: Preventing Unauthorized Subject-driven Text-to-image Diffusion-based Synthesis via Meta-learning
MiKASA: Multi-Key-Anchor & Scene-Aware Transformer for 3D Visual Grounding
MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation
MicroDiffusion: Implicit Representation-Guided Diffusion for 3D Reconstruction from Limited 2D Microscopy Projections
MimicDiffusion: Purifying Adversarial Perturbation via Mimicking Clean Diffusion Model
Mind Artist: Creating Artistic Snapshots with Human Thought
Mind Marginal Non-Crack Regions: Clustering-Inspired Representation Learning for Crack Segmentation
Mind The Edge: Refining Depth Edges in Sparsely-Supervised Monocular Depth Estimation
MindBridge: A Cross-Subject Brain Decoding Framework
Minimal Perspective Autocalibration
Mining Supervision for Dynamic Regions in Self-Supervised Monocular Depth Estimation
Mip-Splatting: Alias-free 3D Gaussian Splatting
MirageRoom: 3D Scene Segmentation with 2D Pre-trained Models by Mirage Projection
Mirasol3B: A Multimodal Autoregressive Model for Time-Aligned and Contextual Modalities
Misalignment-Robust Frequency Distribution Loss for Image Transformation
Mitigating Motion Blur in Neural Radiance Fields with Events and Frames
Mitigating Noisy Correspondence by Geometrical Structure Consistency Learning
Mitigating Object Dependencies: Improving Point Cloud Self-Supervised Learning through Object Exchange
Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding
Mixed-Precision Quantization for Federated Learning on Resource-Constrained Heterogeneous Devices
MoCha-Stereo: Motif Channel Attention Network for Stereo Matching
MoDE: CLIP Data Experts via Clustering
MoML: Online Meta Adaptation for 3D Human Motion Prediction
MoMask: Generative Masked Modeling of 3D Human Motions
MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric
MoReVQA: Exploring Modular Reasoning Models for Video Question Answering
MoSAR: Monocular Semi-Supervised Model for Avatar Reconstruction using Differentiable Shading
MoST: Motion Style Transformer Between Diverse Action Contents
MoST: Multi-Modality Scene Tokenization for Motion Prediction
MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training
Mocap Everyone Everywhere: Lightweight Motion Capture With Smartwatches and a Head-Mounted Camera
ModaVerse: Efficiently Transforming Modalities with LLMs
Modality-Agnostic Structural Image Representation Learning for Deformable Multi-Modality Medical Image Registration
Modality-Collaborative Test-Time Adaptation for Action Recognition
Modality-agnostic Domain Generalizable Medical Image Segmentation by Multi-Frequency in Multi-Scale Attention
Model Adaptation for Time Constrained Embodied Control
Model Inversion Robustness: Can Transfer Learning Help?
Modeling Collaborator: Enabling Subjective Vision Classification With Minimal Human Effort via LLM Tool-Use
Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction
Modeling Multimodal Social Interactions: New Challenges and Baselines with Densely Aligned Representations
Modular Blind Video Quality Assessment
Molecular Data Programming: Towards Molecule Pseudo-labeling with Systematic Weak Supervision
Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models
MonoCD: Monocular 3D Object Detection with Complementary Depths
MonoDiff: Monocular 3D Object Detection and Pose Estimation with Diffusion Models
MonoHair: High-Fidelity Hair Modeling from a Monocular Video
MonoNPHM: Dynamic Head Reconstruction from Monocular Videos
Monocular Identity-Conditioned Facial Reflectance Reconstruction
Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation
MorpheuS: Neural Dynamic 360° Surface Reconstruction from Monocular RGB-D Video
Morphological Prototyping for Unsupervised Slide Representation Learning in Computational Pathology
Mosaic-SDF for 3D Generative Models
Motion Blur Decomposition with Cross-shutter Guidance
Motion Diversification Networks
Motion-adaptive Separable Collaborative Filters for Blind Motion Deblurring
Motion2VecSets: 4D Latent Vector Set Diffusion for Non-rigid Shape Reconstruction and Tracking
MotionEditor: Editing Video Motion via Content-Aware Diffusion
Move Anything with Layered Scene Diffusion
Move as You Say Interact as You Can: Language-guided Human Motion Generation with Scene Affordance
MovieChat: From Dense Token to Sparse Memory for Long Video Understanding
MuGE: Multiple Granularity Edge Detection
MuRF: Multi-Baseline Radiance Fields
Mudslide: A Universal Nuclear Instance Segmentation Method
Multi-Attribute Interactions Matter for 3D Visual Grounding
Multi-Level Neural Scene Graphs for Dynamic Urban Environments
Multi-Modal Hallucination Control by Visual Information Grounding
Multi-Modal Proxy Learning Towards Personalized Visual Multiple Clustering
Multi-Object Tracking in the Dark
Multi-Scale 3D Gaussian Splatting for Anti-Aliased Rendering
Multi-Scale Video Anomaly Detection by Multi-Grained Spatio-Temporal Representation Learning
Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization
Multi-Space Alignments Towards Universal LiDAR Segmentation
Multi-Task Dense Prediction via Mixture of Low-Rank Experts
Multi-View Attentive Contextualization for Multi-View 3D Object Detection
Multi-agent Collaborative Perception via Motion-aware Robust Communication Network
Multi-agent Long-term 3D Human Pose Forecasting via Interaction-aware Trajectory Conditioning
Multi-criteria Token Fusion with One-step-ahead Attention for Efficient Vision Transformers
Multi-modal In-Context Learning Makes an Ego-evolving Scene Text Recognizer
Multi-modal Instruction Tuned LLMs with Fine-grained Visual Perception
Multi-modal Learning for Geospatial Vegetation Forecasting
Multi-scale Dynamic and Hierarchical Relationship Modeling for Facial Action Units Recognition
Multi-view Aggregation Network for Dichotomous Image Segmentation
MultiDiff: Consistent Novel View Synthesis from a Single Image
MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in 3D World
MultiPhys: Multi-Person Physics-aware 3D Motion Estimation
MultiPly: Reconstruction of Multiple People from Monocular Video in the Wild
Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset
Multimodal Industrial Anomaly Detection by Crossmodal Feature Mapping
Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities
Multimodal Prompt Perceiver: Empower Adaptiveness Generalizability and Fidelity for All-in-One Image Restoration
Multimodal Representation Learning by Alternating Unimodal Adaptation
Multimodal Sense-Informed Forecasting of 3D Human Motions
Multiplane Prior Guided Few-Shot Aerial Scene Rendering
Multiple View Geometry Transformers for 3D Human Pose Estimation
Multiscale Vision Transformers Meet Bipartite Matching for Efficient Single-stage Action Localization
Multiview Aerial Visual RECognition (MAVREC): Can Multi-view Improve Aerial Visual Perception?
Multiway Point Cloud Mosaicking with Diffusion and Global Optimization
MuseChat: A Conversational Music Recommendation System for Videos
NAPGuard: Towards Detecting Naturalistic Adversarial Patches
NARUTO: Neural Active Reconstruction from Uncertain Target Observations
NAYER: Noisy Layer Data Generation for Efficient and Effective Data-free Knowledge Distillation
NB-GTR: Narrow-Band Guided Turbulence Removal
NC-SDF: Enhancing Indoor Scene Reconstruction Using Neural SDFs with View-Dependent Normal Compensation
NC-TTT: A Noise Constrastive Approach for Test-Time Training
NEAT: Distilling 3D Wireframes from Neural Attraction Fields
NECA: Neural Customizable Human Avatar
NICE: Neurogenesis Inspired Contextual Encoding for Replay-free Class Incremental Learning
NIFTY: Neural Object Interaction Fields for Guided Human Motion Synthesis
NIVeL: Neural Implicit Vector Layers for Text-to-Vector Generation
NOPE: Novel Object Pose Estimation from a Single Image
NRDF: Neural Riemannian Distance Fields for Learning Articulated Pose Priors
NTO3D: Neural Target Object 3D Reconstruction with Segment Anything
NViST: In the Wild New View Synthesis from a Single Image with Transformers
Named Entity Driven Zero-Shot Image Manipulation
Narrative Action Evaluation with Prompt-Guided Multimodal Interaction
Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners
Navigate Beyond Shortcuts: Debiased Learning Through the Lens of Neural Collapse
Navigating Beyond Dropout: An Intriguing Solution towards Generalizable Image Super Resolution
NeISF: Neural Incident Stokes Field for Geometry and Material Estimation
NeLF-Pro: Neural Light Field Probes for Multi-Scale Novel View Synthesis
NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs
NeRF Director: Revisiting View Selection in Neural Volume Rendering
NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild
NeRF-HuGS: Improved Neural Radiance Fields in Non-static Scenes Using Heuristics-Guided Segmentation
NeRFCodec: Neural Feature Compression Meets Neural Radiance Fields for Memory-Efficient Scene Representation
NeRFDeformer: NeRF Transformation from a Single View via 3D Scene Flows
NeRFiller: Completing Scenes via Generative 3D Inpainting
NeRSP: Neural 3D Reconstruction for Reflective Objects with Sparse Polarized Images
Nearest is Not Dearest: Towards Practical Defense against Quantization-conditioned Backdoor Attacks
Neighbor Relations Matter in Video Scene Detection
NetTrack: Tracking Highly Dynamic Objects with a Net
NeuRAD: Neural Rendering for Autonomous Driving
Neural 3D Strokes: Creating Stylized 3D Scenes with Vectorized 3D Strokes
Neural Clustering based Visual Representation Learning
Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling
Neural Exposure Fusion for High-Dynamic Range Object Detection
Neural Fields as Distributions: Signal Processing Beyond Euclidean Space
Neural Implicit Morphing of Face Images
Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects
Neural Lineage
Neural Markov Random Field for Stereo Matching
Neural Modes: Self-supervised Learning of Nonlinear Modal Subspaces
Neural Parametric Gaussians for Monocular Non-Rigid Object Reconstruction
Neural Point Cloud Diffusion for Disentangled 3D Shape and Appearance Generation
Neural Redshift: Random Networks are not Random Functions
Neural Refinement for Absolute Pose Regression with Feature Synthesis
Neural Sign Actors: A Diffusion Model for 3D Sign Language Production from Text
Neural Spline Fields for Burst Image Fusion and Layer Separation
Neural Super-Resolution for Real-time Rendering with Radiance Demodulation
Neural Underwater Scene Representation
Neural Video Compression with Feature Modulation
Neural Visibility Field for Uncertainty-Driven Active Mapping
NightCC: Nighttime Color Constancy via Adaptive Channel Masking
No More Ambiguity in 360° Room Layout via Bi-Layout Estimation
No Time to Train: Empowering Non-Parametric Networks for Few-shot 3D Scene Segmentation
NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions in Diffusion Models
NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on Noise Cropping and Merging
Noisy One-point Homographies are Surprisingly Good
Noisy-Correspondence Learning for Text-to-Image Person Re-identification
Non-Rigid Structure-from-Motion: Temporally-Smooth Procrustean Alignment and Spatially-Variant Deformation Modeling
Non-autoregressive Sequence-to-Sequence Vision-Language Models
Normalizing Flows on the Product Space of SO(3) Manifolds for Probabilistic Human Pose Modeling
Not All Classes Stand on Same Embeddings: Calibrating a Semantic Distance with Metric Tensor
Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transfomers
Not All Voxels Are Equal: Hardness-Aware Semantic Scene Completion with Self-Distillation
Novel Class Discovery for Ultra-Fine-Grained Visual Categorization
Novel View Synthesis with View-Dependent Effects from a Single Image
OA-CNNs: Omni-Adaptive Sparse CNNs for 3D Semantic Segmentation
OAKINK2: A Dataset of Bimanual Hands-Object Manipulation in Complex Task Completion
OCAI: Improving Optical Flow Estimation by Occlusion and Consistency Aware Interpolation
ODCR: Orthogonal Decoupling Contrastive Regularization for Unpaired Image Dehazing
ODIN: A Single Model for 2D and 3D Segmentation
ODM: A Text-Image Further Alignment Pre-training Approach for Scene Text Detection and Spotting
OED: Towards One-stage End-to-End Dynamic Scene Graph Generation
OHTA: One-shot Hand Avatar via Data-driven Implicit Priors
OMG-Seg: Is One Model Good Enough For All Segmentation?
OMG: Towards Open-vocabulary Motion Generation via Mixture of Controllers
OOSTraj: Out-of-Sight Trajectory Prediction With Vision-Positioning Denoising
OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation
OST: Refining Text Knowledge with Optimal Spatio-Temporal Descriptor for General Video Recognition
OTE: Exploring Accurate Scene Text Recognition Using One Token
OVER-NAV: Elevating Iterative Vision-and-Language Navigation with Open-Vocabulary Detection and StructurEd Representation
OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation
OVMR: Open-Vocabulary Recognition with Multi-Modal References
Object Dynamics Modeling with Hierarchical Point Cloud-based Representations
Object Pose Estimation via the Aggregation of Diffusion Features
Object Recognition as Next Token Prediction
Objects as Volumes: A Stochastic Geometry View of Opaque Solids
Observation-Guided Diffusion Probabilistic Models
Omni-Q: Omni-Directional Scene Understanding for Unsupervised Visual Grounding
Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of Low-rank Experts
OmniGlue: Generalizable Feature Matching with Foundation Model Guidance
OmniLocalRF: Omnidirectional Local Radiance Fields from Dynamic Videos
OmniMedVQA: A New Large-Scale Comprehensive Evaluation Benchmark for Medical LVLM
OmniMotionGPT: Animal Motion Generation with Limited Data
OmniParser: A Unified Framework for Text Spotting Key Information Extraction and Table Recognition
OmniSDF: Scene Reconstruction using Omnidirectional Signed Distance Functions and Adaptive Binoctrees
OmniSeg3D: Omniversal 3D Segmentation via Hierarchical Contrastive Learning
OmniVec2 - A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning
OmniViD: A Generative Framework for Universal Video Understanding
On Exact Inversion of DPM-Solvers
On Scaling Up a Multilingual Vision and Language Model
On Train-Test Class Overlap and Detection for Image Retrieval
On the Content Bias in Fréchet Video Distance
On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm
On the Estimation of Image-matching Uncertainty in Visual Place Recognition
On the Faithfulness of Vision Transformer Explanations
On the Road to Portability: Compressing End-to-End Motion Planner for Autonomous Driving
On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation
On the Robustness of Large Multimodal Models Against Image Adversarial Attacks
On the Scalability of Diffusion-based Text-to-Image Generation
On the Test-Time Zero-Shot Generalization of Vision-Language Models: Do We Really Need Prompt Learning?
Once for Both: Single Stage of Importance and Sparsity Search for Vision Transformer Compression
One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion Schedule Flaws and Enhancing Low-Frequency Controls
One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models
One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion
One-Class Face Anti-spoofing via Spoof Cue Map-Guided Feature Learning
One-Prompt to Segment All Medical Images
One-Shot Open Affordance Learning with Foundation Models
One-Shot Structure-Aware Stylized Image Synthesis
One-dimensional Adapter to Rule Them All: Concepts Diffusion Models and Erasing Applications
One-step Diffusion with Distribution Matching Distillation
OneFormer3D: One Transformer for Unified Point Cloud Segmentation
OneLLM: One Framework to Align All Modalities with Language
OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning
Online Task-Free Continual Generative and Discriminative Learning via Dynamic Cluster Memory
Open Vocabulary Semantic Scene Sketch Understanding
Open-Set Domain Adaptation for Semantic Segmentation
Open-Vocabulary 3D Semantic Segmentation with Foundation Models
Open-Vocabulary Attention Maps with Token Optimization for Semantic Segmentation in Diffusion Models
Open-Vocabulary Object 6D Pose Estimation
Open-Vocabulary Segmentation with Semantic-Assisted Calibration
Open-Vocabulary Semantic Segmentation with Image Embedding Balancing
Open-Vocabulary Video Anomaly Detection
Open-World Human-Object Interaction Detection via Multi-modal Prompts
Open-World Semantic Segmentation Including Class Similarity
Open3DIS: Open-Vocabulary 3D Instance Segmentation with 2D Mask Guidance
Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds with Queryable Objects and Open-Set Relationships
OpenBias: Open-set Bias Detection in Text-to-Image Generative Models
OpenEQA: Embodied Question Answering in the Era of Foundation Models
OpenESS: Event-based Semantic Scene Understanding with Open Vocabularies
OpenStreetView-5M: The Many Roads to Global Visual Geolocation
OpticalDR: A Deep Optical Imaging Model for Privacy-Protective Depression Recognition
Optimal Transport Aggregation for Visual Place Recognition
Optimizing Diffusion Noise Can Serve As Universal Motion Priors
OrCo: Towards Better Generalization via Orthogonality and Contrast for Few-Shot Class-Incremental Learning
Orchestrate Latent Expertise: Advancing Online Continual Learning with Multi-Level Supervision and Reverse Self-Distillation
OrthCaps: An Orthogonal CapsNet with Sparse Attention Routing and Pruning
Orthogonal Adaptation for Modular Customization of Diffusion Models
Osprey: Pixel Understanding with Visual Instruction Tuning
Outdoor Scene Extrapolation with Hierarchical Generative Cellular Automata
Overcoming Generic Knowledge Loss with Selective Parameter Update
Overload: Latency Attacks on Object Detection for Edge Devices
PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios
PAD: Patch-Agnostic Defense against Adversarial Patch Attacks
PAIR Diffusion: A Comprehensive Multimodal Object-Level Image Editor
PAPR in Motion: Seamless Point-level 3D Scene Interpolation
PARA-Drive: Parallelized Architecture for Real-time Autonomous Driving
PBWR: Parametric-Building-Wireframe Reconstruction from Aerial LiDAR Point Clouds
PDF: A Probability-Driven Framework for Open World 3D Point Cloud Semantic Segmentation
PEEKABOO: Interactive Video Generation via Masked-Diffusion
PEGASUS: Personalized Generative 3D Avatars with Composable Attributes
PELA: Learning Parameter-Efficient Models with Low-Rank Approximation
PEM: Prototype-based Efficient MaskFormer for Image Segmentation
PFStorer: Personalized Face Restoration and Super-Resolution
PH-Net: Semi-Supervised Breast Lesion Segmentation via Patch-wise Hardness
PI3D: Efficient Text-to-3D Generation with Pseudo-Image Diffusion
PIA: Your Personalized Image Animator via Plug-and-Play Modules in Text-to-Image Models
PICTURE: PhotorealistIC virtual Try-on from UnconstRained dEsigns
PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF
PIGEON: Predicting Image Geolocations
PIN: Positional Insert Unlocks Object Localisation Abilities in VLMs
PKU-DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling
PLACE: Adaptive Layout-Semantic Fusion for Semantic Image Synthesis
PLGSLAM: Progressive Neural Scene Represenation with Local to Global Bundle Adjustment
PNeRV: Enhancing Spatial Consistency via Pyramidal Neural Representation for Videos
POCE: Primal Policy Optimization with Conservative Estimation for Multi-constraint Offline Reinforcement Learning
POPDG: Popular 3D Dance Generation with PopDanceSet
PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models
PREGO: Online Mistake Detection in PRocedural EGOcentric Videos
PSDPM: Prototype-based Secondary Discriminative Pixels Mining for Weakly Supervised Semantic Segmentation
PTM-VQA: Efficient Video Quality Assessment Leveraging Diverse PreTrained Models from the Wild
PTQ4SAM: Post-Training Quantization for Segment Anything
PTT: Point-Trajectory Transformer for Efficient Temporal 3D Object Detection
PaReNeRF: Toward Fast Large-scale Dynamic NeRF with Patch-based Reference
PaSCo: Urban 3D Panoptic Scene Completion with Uncertainty Awareness
Paint-it: Text-to-Texture Synthesis via Deep Convolutional Texture Map Optimization and Physically-Based Rendering
Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models
PairAug: What Can Augmented Image-Text Pairs Do for Radiology?
PairDETR : Joint Detection and Association of Human Bodies and Faces
Panacea: Panoramic and Controllable Video Generation for Autonomous Driving
Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers
PanoContext-Former: Panoramic Total Scene Understanding with a Transformer
PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation
PanoPose: Self-supervised Relative Pose Estimation for Panoramic Images
PanoRecon: Real-Time Panoptic 3D Reconstruction from Monocular Video
ParamISP: Learned Forward and Inverse ISPs using Camera Parameters
Parameter Efficient Fine-tuning via Cross Block Orchestration for Segment Anything Model
Parameter Efficient Self-Supervised Geospatial Domain Adaptation
ParameterNet: Parameters Are All You Need for Large-scale Visual Pretraining of Mobile Networks
Part-aware Unified Representation of Language and Skeleton for Zero-shot Action Recognition
PartDistill: 3D Shape Part Segmentation by Vision-Language Model Distillation
Partial-to-Partial Shape Matching with Geometric Consistency
Passive Snapshot Coded Aperture Dual-Pixel RGB-D Imaging
Patch2Self2: Self-supervised Denoising on Coresets via Matrix Sketching
PatchFusion: An End-to-End Tile-Based Framework for High-Resolution Monocular Metric Depth Estimation
PeLK: Parameter-efficient Large Kernel ConvNets with Peripheral Convolution
PeVL: Pose-Enhanced Vision-Language Model for Fine-Grained Human Action Recognition
PeerAiD: Improving Adversarial Distillation from a Specialized Peer Tutor
PerAda: Parameter-Efficient Federated Learning Personalization with Generalization Guarantees
Perception-Oriented Video Frame Interpolation via Asymmetric Blending
PerceptionGPT: Effectively Fusing Visual Perception into LLM
Perceptual Assessment and Optimization of HDR Image Rendering
Permutation Equivariance of Transformers and Its Applications
Person in Place: Generating Associative Skeleton-Guidance Maps for Human-Object Interaction Image Editing
Person-in-WiFi 3D: End-to-End Multi-Person 3D Pose Estimation with Wi-Fi
Personalized Residuals for Concept-Driven Text-to-Image Generation
Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models
Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular Stereo and RGB-D Cameras
PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding
PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI
PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics
PhysPT: Physics-aware Pretrained Transformer for Estimating Human Dynamics from Monocular Videos
Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving
Physical Backdoor: Towards Temperature-based Backdoor Attacks in the Physical World
Physical Property Understanding from Language-Embedded Feature Fields
Physics-Aware Hand-Object Interaction Denoising
Physics-guided Shape-from-Template: Monocular Video Perception through Neural Surrogate Models
Pick-or-Mix: Dynamic Channel Sampling for ConvNets
PikeLPN: Mitigating Overlooked Inefficiencies of Low-Precision Neural Networks
Pink: Unveiling the Power of Referential Comprehension for Multi-modal LLMs
Pixel-Aligned Language Model
Pixel-level Semantic Correspondence through Layout-aware Representation Learning and Multi-scale Matching Integration
PixelLM: Pixel Reasoning with Large Multimodal Model
PixelRNN: In-pixel Recurrent Neural Networks for End-to-end–optimized Perception with Neural Sensors
PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar
Plug and Play Active Learning for Object Detection
Plug-and-Play Diffusion Distillation
PoNQ: a Neural QEM-based Mesh Representation
Point Cloud Pre-training with Diffusion Models
Point Segment and Count: A Generalized Framework for Object Counting
Point Transformer V3: Simpler Faster Stronger
Point-VOS: Pointing Up Video Object Segmentation
Point2CAD: Reverse Engineering CAD Models from 3D Point Clouds
Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision
PointBeV: A Sparse Approach for BeV Predictions
PointInfinity: Resolution-Invariant Point Diffusion Models
PointOBB: Learning Oriented Object Detection via Single Point Supervision
PolarMatte: Fully Computational Ground-Truth-Quality Alpha Matte Extraction for Images and Video using Polarized Screen Matting
PolarRec: Improving Radio Interferometric Data Reconstruction Using Polar Coordinates
Polarization Wavefront Lidar: Learning Large Scene Reconstruction from Polarized Wavefronts
Polos: Multimodal Metric Learning from Human Feedback for Image Captioning
Poly Kernel Inception Network for Remote Sensing Detection
Portrait4D: Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data
PortraitBooth: A Versatile Portrait Model for Fast Identity-preserved Personalization
Pose Adapted Shape Learning for Large-Pose Face Reenactment
Pose-Guided Self-Training with Two-Stage Clustering for Unsupervised Landmark Discovery
Pose-Transformed Equivariant Network for 3D Point Trajectory Prediction
PoseIRM: Enhance 3D Human Pose Estimation on Unseen Camera Settings via Invariant Risk Minimization
Positive-Unlabeled Learning by Latent Group-Aware Meta Disambiguation
Posterior Distillation Sampling
PostureHMR: Posture Transformation for 3D Human Mesh Recovery
PrPSeg: Universal Proposition Learning for Panoramic Renal Pathology Segmentation
Practical Measurements of Translucent Materials with Inter-Pixel Translucency Prior
PracticalDG: Perturbation Distillation on Vision-Language Models for Hybrid Domain Generalization
Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial Robustness
Pre-trained Vision and Language Transformers Are Few-Shot Incremental Learners
Pre-training Vision Models with Mandelbulb Variations
PredToken: Predicting Unknown Tokens and Beyond with Coarse-to-Fine Iterative Decoding
Predicated Diffusion: Predicate Logic-Based Attention Guidance for Text-to-Image Diffusion Models
Preserving Fairness Generalization in Deepfake Detection
Previously on ... From Recaps to Story Summarization
Privacy-Preserving Face Recognition Using Trainable Feature Subtraction
Privacy-Preserving Optics for Enhancing Protection in Face De-Identification
ProMark: Proactive Diffusion Watermarking for Causal Attribution
ProMotion: Prototypes As Motion Learners
ProS: Prompting-to-simulate Generalized knowledge for Universal Cross-Domain Retrieval
ProTeCt: Prompt Tuning for Taxonomic Open Set Classification
Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing
Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks Methods and Applications
Probing Synergistic High-Order Interaction in Infrared and Visible Image Fusion
Probing the 3D Awareness of Visual Foundation Models
Producing and Leveraging Online Map Uncertainty in Trajectory Prediction
Programmable Motion Generation for Open-Set Motion Control Tasks
Progress-Aware Online Action Segmentation for Egocentric Procedural Task Videos
Progressive Divide-and-Conquer via Subsampling Decomposition for Accelerated MRI
Progressive Semantic-Guided Vision Transformer for Zero-Shot Learning
Projecting Trackable Thermal Patterns for Dynamic Computer Vision
Prompt Augmentation for Self-supervised Text-guided Image Manipulation
Prompt Highlighter: Interactive Control for Multi-Modal LLMs
Prompt Learning via Meta-Regularization
Prompt-Driven Dynamic Object-Centric Learning for Single Domain Generalization
Prompt-Driven Referring Image Segmentation with Instance Contrasting
Prompt-Enhanced Multiple Instance Learning for Weakly Supervised Video Anomaly Detection
Prompt-Free Diffusion: Taking “Text” out of Text-to-Image Diffusion Models
Prompt3D: Random Prompt Assisted Weakly-Supervised 3D Object Detection
PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection
PromptCoT: Align Prompt Distribution via Adapted Chain-of-Thought
PromptKD: Unsupervised Prompt Distillation for Vision-Language Models
Promptable Behaviors: Personalizing Multi-Objective Rewards from Human Preferences
Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models
Prompting Vision Foundation Models for Pathology Image Analysis
ProxyCap: Real-time Monocular Full-body Capture in World Space via Human-Centric Proxy-to-Motion Learning
Pseudo Label Refinery for Unsupervised Domain Adaptation on Cross-dataset 3D Object Detection
Psychometry: An Omnifit Model for Image Reconstruction from Human Brain Activity
Puff-Net: Efficient Style Transfer with Pure Content and Style Feature Fusion Network
Purified and Unified Steganographic Network
Putting the Object Back into Video Object Segmentation
Q-Instruct: Improving Low-level Visual Abilities for Multi-modality Foundation Models
QDFormer: Towards Robust Audiovisual Segmentation in Complex Environments with Quantization-based Semantic Decomposition
QN-Mixer: A Quasi-Newton MLP-Mixer Model for Sparse-View CT Reconstruction
QUADify: Extracting Meshes with Pixel-level Details and Materials from Images
Quantifying Task Priority for Multi-Task Optimization
Quantifying Uncertainty in Motion Prediction with Variational Bayesian Mixture
Querying as Prompt: Parameter-Efficient Learning for Multimodal Language Model
Question Aware Vision Transformer for Multimodal Reasoning
Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized Narratives from Open-Source Histopathology Videos
R-Cyclic Diffuser: Reductive and Cyclic Latent Diffusion for 3D Clothed Human Digitalization
RAM-Avatar: Real-time Photo-Realistic Avatar from Monocular Videos with Full-body Control
RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models
RCBEVDet: Radar-camera Fusion in Bird's Eye View for 3D Object Detection
RCL: Reliable Continual Learning for Unified Failure Detection
RCooper: A Real-world Large-scale Dataset for Roadside Cooperative Perception
REACTO: Reconstructing Articulated Objects from a Single Video
READ: Retrieval-Enhanced Asymmetric Diffusion for Motion Planning
RELI11D: A Comprehensive Multimodal Human Motion Dataset and Method
RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos
RILA: Reflective and Imaginative Language Agent for Zero-Shot Semantic Audio-Visual Navigation
RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback
RMT: Retentive Networks Meet Vision Transformers
RMem: Restricted Memory Banks Improve Video Object Segmentation
RNb-NeuS: Reflectance and Normal-based Multi-View 3D Reconstruction
RTMO: Towards High-Performance One-Stage Real-Time Multi-Person Pose Estimation
RTracker: Recoverable Tracking via PN Tree Structured Memory
RadSimReal: Bridging the Gap Between Synthetic and Real Data in Radar Object Detection With Simulation
RadarDistill: Boosting Radar-based Object Detection Performance via Knowledge Distillation from LiDAR Features
Random Entangled Tokens for Adversarially Robust Vision Transformer
RankED: Addressing Imbalance and Uncertainty in Edge Detection Using Ranking-based Losses
RankMatch: Exploring the Better Consistency Regularization for Semi-supervised Semantic Segmentation
Ranking Distillation for Open-Ended Video Question Answering with Insufficient Labels
Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following
Rapid 3D Model Generation with Intuitive 3D Input
Rapid Motor Adaptation for Robotic Manipulator Arms
Re-thinking Data Availability Attacks Against Deep Neural Networks
ReCoRe: Regularized Contrastive Representation Learning of World Model
ReGenNet: Towards Human Action-Reaction Synthesis
Readout Guidance: Learning Control from Diffusion Features
Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark
Real-IAD: A Real-World Multi-View Dataset for Benchmarking Versatile Industrial Anomaly Detection
Real-Time Exposure Correction via Collaborative Transformations and Adaptive Sampling
Real-Time Neural BRDF with Spherically Distributed Primitives
Real-Time Simulated Avatar from Head-Mounted Sensors
Real-World Efficient Blind Motion Deblurring via Blur Pixel Discretization
Real-World Mobile Image Denoising Dataset with Efficient Baselines
Real-time 3D-aware Portrait Video Relighting
Real-time Acquisition and Reconstruction of Dynamic Volumes with Neural Structured Illumination
RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization
RealNet: A Feature Selection Network with Realistic Synthetic Anomaly for Anomaly Detection
Realigning Confidence with Temporal Saliency Information for Point-Level Weakly-Supervised Temporal Action Localization
RecDiffusion: Rectangling for Image Stitching with Diffusion Models
ReconFusion: 3D Reconstruction with Diffusion Priors
Reconstructing Hands in 3D with Transformers
Reconstruction-free Cascaded Adaptive Compressive Sensing
Referring Expression Counting
Referring Image Editing: Object-level Image Editing via Referring Expressions
Reg-PTQ: Regression-specialized Post-training Quantization for Fully Quantized Object Detector
Region-Based Representations Revisited
RegionGPT: Towards Region Understanding Vision Language Model
RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D Scene Understanding
Regressor-Segmenter Mutual Prompt Learning for Crowd Counting
Regularized Parameter Uncertainty for Improving Generalization in Reinforcement Learning
Relation Rectification in Diffusion Model
Relational Matching for Weakly Semi-Supervised Oriented Object Detection
Relaxed Contrastive Learning for Federated Learning
Relightable Gaussian Codec Avatars
Relightable and Animatable Neural Avatar from Sparse-View Video
Relightful Harmonization: Lighting-aware Portrait Background Replacement
RepAn: Enhanced Annealing through Re-parameterization
RepKPU: Point Cloud Upsampling with Kernel Point Representation and Deformation
RepViT: Revisiting Mobile CNN From ViT Perspective
Representing Part-Whole Hierarchies in Foundation Models by Learning Localizability Composability and Decomposability from Anatomy via Self Supervision
Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation
Residual Denoising Diffusion Models
Residual Learning in Diffusion Models
Resolution Limit of Single-Photon LiDAR
Resource-Efficient Transformer Pruning for Finetuning of Large Models
Restoration by Generation with Constrained Priors
Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning
Rethinking Boundary Discontinuity Problem for Oriented Object Detection
Rethinking Diffusion Model for Multi-Contrast MRI Super-Resolution
Rethinking FID: Towards a Better Evaluation Metric for Image Generation
Rethinking Few-shot 3D Point Cloud Semantic Segmentation
Rethinking Generalizable Face Anti-spoofing via Hierarchical Prototype-guided Distribution Refinement in Hyperbolic Space
Rethinking Human Motion Prediction with Symplectic Integral
Rethinking Inductive Biases for Surface Normal Estimation
Rethinking Interactive Image Segmentation with Low Latency High Quality and Diverse Prompts
Rethinking Multi-domain Generalization with A General Learning Objective
Rethinking Multi-view Representation Learning via Distilled Disentangling
Rethinking Prior Information Generation with CLIP for Few-Shot Segmentation
Rethinking Transformers Pre-training for Multi-Spectral Satellite Imagery
Rethinking the Evaluation Protocol of Domain Generalization
Rethinking the Objectives of Vector-Quantized Tokenizers for Image Synthesis
Rethinking the Representation in Federated Unsupervised Learning with Non-IID Data
Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance
Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection
Retraining-Free Model Quantization via One-Shot Weight-Coupling Learning
Retrieval-Augmented Egocentric Video Captioning
Retrieval-Augmented Embodied Agents
Retrieval-Augmented Layout Transformer for Content-Aware Layout Generation
Retrieval-Augmented Open-Vocabulary Object Detection
Revamping Federated Learning Security from a Defender's Perspective: A Unified Defense with Homomorphic Encrypted Data Space
Revisiting Adversarial Training Under Long-Tailed Distributions
Revisiting Adversarial Training at Scale
Revisiting Counterfactual Problems in Referring Expression Comprehension
Revisiting Global Translation Estimation with Feature Tracks
Revisiting Non-Autoregressive Transformers for Efficient Image Synthesis
Revisiting Sampson Approximations for Geometric Estimation Problems
Revisiting Single Image Reflection Removal In the Wild
Revisiting Spatial-Frequency Information Integration from a Hierarchical Perspective for Panchromatic and Multi-Spectral Image Fusion
Revisiting the Domain Shift and Sample Uncertainty in Multi-source Active Domain Transfer
Rewrite the Stars
Rich Human Feedback for Text-to-Image Generation
RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail Richness in Text-to-3D
Riemannian Multinomial Logistics Regression for SPD Neural Networks
RoDLA: Benchmarking the Robustness of Document Layout Analysis Models
RoHM: Robust Human Motion Reconstruction via Diffusion
RoMa: Robust Dense Feature Matching
Robust Depth Enhancement via Polarization Prompt Fusion Tuning
Robust Distillation via Untargeted and Targeted Intermediate Adversarial Samples
Robust Emotion Recognition in Context Debiasing
Robust Image Denoising through Adversarial Frequency Mixup
Robust Noisy Correspondence Learning with Equivariant Similarity Consistency
Robust Overfitting Does Matter: Test-Time Adversarial Purification With FGSM
Robust Self-calibration of Focal Lengths from the Fundamental Matrix
Robust Synthetic-to-Real Transfer for Stereo Matching
RobustSAM: Segment Anything Robustly on Degraded Images
Rolling Shutter Correction with Intermediate Distortion Flow Estimation
Rotated Multi-Scale Interaction Network for Referring Remote Sensing Image Segmentation
Rotation-Agnostic Image Representation Learning for Digital Pathology
S-DyRF: Reference-Based Stylized Radiance Fields for Dynamic Scenes
S2MAE: A Spatial-Spectral Pretraining Foundation Model for Spectral Remote Sensing Data
SAFDNet: A Simple and Effective Network for Fully Sparse 3D Object Detection
SAI3D: Segment Any Instance in 3D Scenes
SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation
SANeRF-HQ: Segment Anything for NeRF in High Quality
SAOR: Single-View Articulated Object Reconstruction
SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes
SC-Tune: Unleashing Self-Consistent Referential Comprehension in Large Vision Language Models
SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder for Self-Supervised Landmark Estimation
SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing
SCINeRF: Neural Radiance Fields from a Snapshot Compressive Image
SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed and Textured Human Meshes
SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation
SD-DiT: Unleashing the Power of Self-supervised Discrimination in Diffusion Transformer
SD2Event:Self-supervised Learning of Dynamic Detectors and Contextual Descriptors for Event Cameras
SD4Match: Learning to Prompt Stable Diffusion Model for Semantic Matching
SDDGR: Stable Diffusion-based Deep Generative Replay for Class Incremental Object Detection
SDPose: Tokenized Pose Estimation via Circulation-Guide Self-Distillation
SDSTrack: Self-Distillation Symmetric Adapter Learning for Multi-Modal Visual Object Tracking
SEAS: ShapE-Aligned Supervision for Person Re-Identification
SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation
SEED-Bench: Benchmarking Multimodal Large Language Models
SFOD: Spiking Fusion Object Detector
SG-BEV: Satellite-Guided BEV Fusion for Cross-View Semantic Segmentation
SG-PGM: Partial Graph Matching Network with Semantic Geometric Fusion for 3D Scene Graph Alignment and Its Downstream Tasks
SHAP-EDITOR: Instruction-Guided Latent 3D Editing in Seconds
SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild
SHViT: Single-Head Vision Transformer with Memory Efficient Macro Design
SHiNe: Semantic Hierarchy Nexus for Open-vocabulary Object Detection
SI-MIL: Taming Deep MIL for Self-Interpretability in Gigapixel Histopathology
SIFU: Side-view Conditioned Implicit Function for Real-world Usable Clothed Human Reconstruction
SIGNeRF: Scene Integrated Generation for Neural Radiance Fields
SIRA: Scalable Inter-frame Relation and Association for Radar Perception
SLICE: Stabilized LIME for Consistent Explanations for Image Classification
SNED: Superposition Network Architecture Search for Efficient Video Diffusion Model
SNI-SLAM: Semantic Neural Implicit SLAM
SNIDA: Unlocking Few-Shot Object Detection with Non-linear Semantic Decoupling Augmentation
SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection
SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using Neural Radiance Fields
SODA: Bottleneck Diffusion Models for Representation Learning
SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge
SPAD: Spatially Aware Multi-View Diffusers
SPECAT: SPatial-spEctral Cumulative-Attention Transformer for High-Resolution Hyperspectral Image Reconstruction
SPIDeRS: Structured Polarization for Invisible Depth and Reflectance Sensing
SPIN: Simultaneous Perception Interaction and Navigation
SPOC: Imitating Shortest Paths in Simulation Enables Effective Navigation and Manipulation in the Real World
SPOT: Self-Training with Patch-Order Permutation for Object-Centric Learning with Autoregressive Transformers
SPU-PMD: Self-Supervised Point Cloud Upsampling via Progressive Mesh Deformation
SRTube: Video-Language Pre-Training with Action-Centric Video Tube Features and Semantic Role Labeling
SSR-Encoder: Encoding Selective Subject Representation for Subject-Driven Generation
SUGAR: Pre-training 3D Visual Representations for Robotics
SURE: SUrvey REcipes for building reliable and robust deep networks
SVDTree: Semantic Voxel Diffusion for Single Image Tree Reconstruction
SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from Regularized Modeling Perspective
SVGDreamer: Text Guided SVG Generation with Diffusion Model
SaCo Loss: Sample-wise Affinity Consistency for Vision-Language Pre-training
Salience DETR: Enhancing Detection Transformer with Hierarchical Salience Filtering Refinement
Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion
SatSynth: Augmenting Image-Mask Pairs through Diffusion Models for Aerial Semantic Segmentation
Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering
Scalable 3D Registration via Truncated Entry-wise Absolute Residuals
Scaled Decoupled Distillation
Scaling Diffusion Models to Real-World 3D LiDAR Scene Completion
Scaling Laws for Data Filtering— Data Curation cannot be Compute Agnostic
Scaling Laws of Synthetic Images for Model Training ... for Now
Scaling Up Dynamic Human-Scene Interaction Modeling
Scaling Up Video Summarization Pretraining with Large Language Models
Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild
ScanFormer: Referring Expression Comprehension by Iteratively Scanning
Scene Adaptive Sparse Transformer for Event-based Object Detection
Scene-adaptive and Region-aware Multi-modal Prompt for Open Vocabulary Object Detection
SceneFun3D: Fine-Grained Functionality and Affordance Understanding in 3D Scenes
SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion Priors
SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System
Score-Guided Diffusion for 3D Human Recovery
ScoreHypo: Probabilistic Human Mesh Estimation with Hypothesis Scoring
Sculpt3D: Multi-View Consistent Text-to-3D Generation with Sparse 3D Prior
Sculpting Holistic 3D Representation in Contrastive Language-Image-3D Pre-training
SeD: Semantic-Aware Discriminator for Image Super-Resolution
SeMoLi: What Moves Together Belongs Together
SeNM-VAE: Semi-Supervised Noise Modeling with Hierarchical Variational Autoencoder
SeaBird: Segmentation in Bird’s View with Dice Loss Improves Monocular 3D Detection of Large Objects
Seamless Human Motion Composition with Blended Positional Encodings
SecondPose: SE(3)-Consistent Dual-Stream Feature Fusion for Category-Level Pose Estimation
See Say and Segment: Teaching LMMs to Overcome False Premises
SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution
Seeing Motion at Nighttime with an Event Camera
Seeing Unseen: Discover Novel Biomedical Concepts via Geometry-Constrained Probabilistic Modeling
Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners
Seeing the Unseen: Visual Common Sense for Semantic Placement
Seeing the World through Your Eyes
Seg2Reg: Differentiable 2D Segmentation to 1D Regression Rendering for 360 Room Layout Reconstruction
Segment Any Event Streams via Weighted Adaptation of Pivotal Tokens
Segment Every Out-of-Distribution Object
Segment and Caption Anything
Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model
Selective Interpretable and Motion Consistent Privacy Attribute Obfuscation for Action Recognition
Selective Nonlinearities Removal from Digital Signals
Selective-Stereo: Adaptive Frequency Information Selection for Stereo Matching
Selectively Informative Description can Reduce Undesired Embedding Entanglements in Text-to-Image Personalization
Self-Adaptive Reality-Guided Diffusion for Artifact-Free Super-Resolution
Self-Calibrating Vicinal Risk Minimisation for Model Calibration
Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation
Self-Distilled Masked Auto-Encoders are Efficient Video Anomaly Detectors
Self-Supervised Class-Agnostic Motion Prediction with Spatial and Temporal Consistency Regularizations
Self-Supervised Dual Contouring
Self-Supervised Facial Representation Learning with Facial Region Awareness
Self-Supervised Multi-Object Tracking with Path Consistency
Self-Supervised Representation Learning from Arbitrary Scenarios
Self-Training Large Language Models for Improved Visual Program Synthesis With Visual Reinforcement
Self-correcting LLM-controlled Diffusion Models
Self-supervised Debiasing Using Low Rank Regularization
SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction
SelfPose3d: Self-Supervised Multi-Person Multi-View 3d Pose Estimation
SemCity: Semantic Scene Generation with Triplane Diffusion
Semantic Human Mesh Reconstruction with Textures
Semantic Line Combination Detector
Semantic Shield: Defending Vision-Language Models Against Backdooring and Poisoning via Fine-grained Knowledge Alignment
Semantic-Aware Multi-Label Adversarial Attacks
Semantic-aware SAM for Point-Prompted Instance Segmentation
Semantically-Shifted Incremental Adapter-Tuning is A Continual ViTransformer
Semantics Distortion and Style Matter: Towards Source-free UDA for Panoramic Segmentation
Semantics-aware Motion Retargeting with Vision-Language Models
Separate and Conquer: Decoupling Co-occurrence via Decomposition and Representation for Weakly Supervised Semantic Segmentation
Separating the "Chirp" from the "Chat": Self-supervised Visual Grounding of Sound and Language
Sequential Modeling Enables Scalable Learning for Large Vision Models
SfmCAD: Unsupervised CAD Reconstruction by Learning Sketch-based Feature Modeling Operations
Shadow Generation for Composite Image Using Diffusion Model
Shadow-Enlightened Image Outpainting
Shadows Don't Lie and Lines Can't Bend! Generative Models don't know Projective Geometry...for now
Shallow-Deep Collaborative Learning for Unsupervised Visible-Infrared Person Re-Identification
ShapeMatcher: Self-Supervised Joint Shape Canonicalization Segmentation Retrieval and Deformation
ShapeWalk: Compositional Shape Editing Through Language-Guided Chains
Sharingan: A Transformer Architecture for Multi-Person Gaze Following
Sheared Backpropagation for Fine-tuning Foundation Models
Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D Prior
SiTH: Single-view Textured Human Reconstruction with Image-Conditioned Diffusion
Siamese Learning with Joint Alignment and Regression for Weakly-Supervised Video Paragraph Grounding
Sieve: Multimodal Dataset Pruning using Image Captioning Models
SignGraph: A Sign Sequence is Worth Graphs of Nodes
SimAC: A Simple Anti-Customization Method for Protecting Face Privacy against Text-to-Image Synthesis of Diffusion Models
SimDA: Simple Diffusion Adapter for Efficient Video Generation
Simple Semantic-Aided Few-Shot Learning
SinSR: Diffusion-Based Image Super-Resolution in a Single Step
Single Domain Generalization for Crowd Counting
Single Mesh Diffusion Models with Field Latents for Texture Generation
Single View Refractive Index Tomography with Neural Fields
Single-Model and Any-Modality for Video Object Tracking
Single-View Scene Point Cloud Human Grasp Generation
Single-to-Dual-View Adaptation for Egocentric 3D Hand Pose Estimation
SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model
Situational Awareness Matters in 3D Vision Language Reasoning
Skeleton-in-Context: Unified Skeleton Sequence Modeling with In-Context Learning
SketchINR: A First Look into Sketches as Implicit Neural Representations
SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution
SkySense: A Multi-Modal Remote Sensing Foundation Model Towards Universal Interpretation for Earth Observation Imagery
SleepVST: Sleep Staging from Near-Infrared Video Signals using Pre-Trained Transformers
Slice3D: Multi-Slice Occlusion-Revealing Single View 3D Reconstruction
SlowFormer: Adversarial Attack on Compute and Energy Consumption of Efficient Vision Transformers
Small Scale Data-Free Knowledge Distillation
Small Steps and Level Sets: Fitting Neural Surface Models with Point Guidance
Smart Help: Strategic Opponent Modeling for Proactive and Adaptive Robot Assistance in Households
SmartEdit: Exploring Complex Instruction-based Image Editing with Multimodal Large Language Models
SmartMask: Context Aware High-Fidelity Mask Generation for Fine-grained Object Insertion and Layout Control
SmartRefine: A Scenario-Adaptive Refinement Framework for Efficient Motion Prediction
Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models
SnAG: Scalable and Accurate Video Grounding
Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis
Snapshot Lidar: Fourier Embedding of Amplitude and Phase for Single-Image Depth Reconstruction
SocialCircle: Learning the Angle-based Social Interaction Representation for Pedestrian Trajectory Prediction
SocialCounterfactuals: Probing and Mitigating Intersectional Social Biases in Vision-Language Models with Counterfactual Examples
Soften to Defend: Towards Adversarial Robustness via Self-Guided Label Refinement
Solving Masked Jigsaw Puzzles with Diffusion Vision Transformers
Solving the Catastrophic Forgetting Problem in Generalized Category Discovery
SonicVisionLM: Playing Sound with Vision Language Models
SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos
Source-Free Domain Adaptation with Frozen Multimodal Foundation Model
Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer
Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis
Spanning Training Progress: Temporal Dual-Depth Scoring (TDDS) for Enhanced Dataset Pruning
Sparse Global Matching for Video Frame Interpolation with Large Motion
Sparse Semi-DETR: Sparse Learnable Queries for Semi-Supervised Object Detection
Sparse Views Near Light: A Practical Paradigm for Uncalibrated Point-light Photometric Stereo
SparseOcc: Rethinking Sparse Latent Representation for Vision-Based Semantic Occupancy Prediction
Spatial-Aware Regression for Keypoint Localization
SpatialTracker: Tracking Any 2D Pixels in 3D Space
SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities
Spatio-Temporal Turbulence Mitigation: A Translational Perspective
SpecNeRF: Gaussian Directional Encoding for Specular Reflections
Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation
Spectral and Polarization Vision: Spectro-polarimetric Real-world Dataset
Spectrum AUC Difference (SAUCD): Human-aligned 3D Shape Evaluation
Specularity Factorization for Low-Light Enhancement
Spherical Mask: Coarse-to-Fine 3D Point Cloud Instance Segmentation with Spherical Representation
SpiderMatch: 3D Shape Matching with Global Optimality and Geometric Consistency
Spike-guided Motion Deblurring with Unknown Modal Spatiotemporal Alignment
SpikeNeRF: Learning Neural Radiance Fields from Continuous Spike Stream
SpikingResformer: Bridging ResNet and Vision Transformer in Spiking Neural Networks
Spin-UP: Spin Light for Natural Light Uncalibrated Photometric Stereo
SplaTAM: Splat Track & Map 3D Gaussians for Dense RGB-D SLAM
Splatter Image: Ultra-Fast Single-View 3D Reconstruction
SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting
Split to Merge: Unifying Separated Modalities for Unsupervised Domain Adaptation
SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos
SportsSloMo: A New Benchmark and Baselines for Human-centric Video Frame Interpolation
Stable Neighbor Denoising for Source-free Domain Adaptive Segmentation
StableVITON: Learning Semantic Correspondence with Latent Diffusion Model for Virtual Try-On
State Space Models for Event Cameras
Stationary Representations: Optimally Approximating Compatibility and Implications for Improved Model Replacements
Steerers: A Framework for Rotation Equivariant Keypoint Descriptors
Steganographic Passport: An Owner and User Verifiable Credential for Deep Model IP Protection Without Retraining
StegoGAN: Leveraging Steganography for Non-Bijective Image-to-Image Translation
Step Differences in Instructional Video
StraightPCF: Straight Point Cloud Filtering
Stratified Avatar Generation from Sparse Observations
Streaming Dense Video Captioning
StreamingFlow: Streaming Occupancy Forecasting with Asynchronous Multi-modal Data Streams via Neural Ordinary Differential Equation
StrokeFaceNeRF: Stroke-based Facial Appearance Editing in Neural Radiance Field
Strong Transferable Adversarial Attacks via Ensembled Asymptotically Normal Distribution Learning
Stronger Fewer & Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation
Structure Matters: Tackling the Semantic Discrepancy in Diffusion Models for Image Inpainting
Structure-Aware Sparse-View X-ray 3D Reconstruction
Structure-Guided Adversarial Training of Diffusion Models
Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training
Structured Model Probing: Empowering Efficient Transfer Learning by Structured Regularization
StyLitGAN: Image-Based Relighting via Latent Control
Style Aligned Image Generation via Shared Attention
Style Blind Domain Generalized Semantic Segmentation via Covariance Alignment and Semantic Consistence Contrastive Learning
Style Injection in Diffusion: A Training-free Approach for Adapting Large-scale Diffusion Models for Style Transfer
StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained StyleGAN
SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering
SubT-MRS Dataset: Pushing SLAM Towards All-weather Environments
Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation
Super-Resolution Reconstruction from Bayer-Pattern Spike Streams
SuperNormal: Neural Surface Reconstruction via Multi-View Normal Integration
SuperPrimitive: Scene Reconstruction at a Primitive Level
SuperSVG: Superpixel-based Scalable Vector Graphics Synthesis
Supervised Anomaly Detection for Complex Industrial Images
Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing
SurMo: Surface-based 4D Motion Modeling for Dynamic Human Rendering
SurroundSDF: Implicit 3D Scene Understanding Based on Signed Distance Field
SwiftBrush: One-Step Text-to-Image Diffusion Model with Variational Score Distillation
SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting
Symphonize 3D Semantic Scene Completion with Contextual Instance Queries
SynFog: A Photo-realistic Synthetic Fog Dataset based on End-to-end Imaging Simulation for Advancing Real-World Defogging in Autonomous Driving
SynSP: Synergy of Smoothness and Precision in Pose Sequences Refinement
SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining
SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis
Synergistic Global-space Camera and Human Reconstruction from Videos
Synthesize Diagnose and Optimize: Towards Fine-Grained Vision-Language Understanding
Synthesize Step-by-Step: Tools Templates and LLMs as Data Generators for Reasoning-Based Chart VQA
Systematic Comparison of Semi-supervised and Self-supervised Learning for Medical Image Classification
S²MVTC: a Simple yet Efficient Scalable Multi-View Tensor Clustering
T-VSL: Text-Guided Visual Sound Source Localization in Mixtures
T4P: Test-Time Training of Trajectory Prediction via Masked Autoencoder and Actor-specific Token Memory
TACO: Benchmarking Generalizable Bimanual Tool-ACtion-Object Understanding
TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding
TASeg: Temporal Aggregation Network for LiDAR Semantic Segmentation
TCP:Textual-based Class-aware Prompt tuning for Visual-Language Model
TE-TAD: Towards Full End-to-End Temporal Action Detection via Time-Aligned Coordinate Expression
TEA: Test-time Energy Adaptation
TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models
THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models
TI2V-Zero: Zero-Shot Image Conditioning for Text-to-Video Diffusion Models
TIGER: Time-Varying Denoising Model for 3D Point Cloud Generation with Diffusion Process
TIM: A Time Interval Machine for Audio-Visual Action Recognition
TRINS: Towards Multimodal Language Models that Can Read
TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models
TTA-EVF: Test-Time Adaptation for Event-based Video Frame Interpolation via Reliable Pixel and Sample Estimation
TULIP: Multi-camera 3D Precision Assessment of Parkinson’s Disease
TULIP: Transformer for Upsampling of LiDAR Point Clouds
TUMTraf V2X Cooperative Perception Dataset
Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models
Tactile-Augmented Radiance Fields
Tailored Visions: Enhancing Text-to-Image Generation with Personalized Prompt Rewriting
Taming Mode Collapse in Score Distillation for Text-to-3D Generation
Taming Self-Training for Open-Vocabulary Object Detection
Taming Stable Diffusion for Text to 360 Panorama Image Generation
Taming the Tail in Class-Conditional GANs: Knowledge Sharing via Unconditional Training at Lower Resolutions
Targeted Representation Alignment for Open-World Semi-Supervised Learning
Task-Adaptive Saliency Guidance for Exemplar-free Class Incremental Learning
Task-Aware Encoder Control for Deep Video Compression
Task-Conditioned Adaptation of Visual Features in Multi-Task Policy Learning
Task-Customized Mixture of Adapters for General Image Fusion
Task-Driven Exploration: Decoupling and Inter-Task Feedback for Joint Moment Retrieval and Highlight Detection
Task-Driven Wavelets using Constrained Empirical Risk Minimization
Task-aligned Part-aware Panoptic Segmentation through Joint Object-Part Representations
Task2Box: Box Embeddings for Modeling Asymmetric Task Relationships
TeMO: Towards Text-Driven 3D Stylization for Multi-Object Meshes
TeTriRF: Temporal Tri-Plane Radiance Fields for Efficient Free-Viewpoint Video
Teeth-SEG: An Efficient Instance Segmentation Framework for Orthodontic Treatment based on Multi-Scale Aggregation and Anthropic Prior Knowledge
Telling Left from Right: Identifying Geometry-Aware Semantic Correspondence
Template Free Reconstruction of Human-object Interaction with Procedural Interaction Generation
Temporally Consistent Unbalanced Optimal Transport for Unsupervised Action Segmentation
Test-Time Adaptation for Depth Completion
Test-Time Domain Generalization for Face Anti-Spoofing
Test-Time Linear Out-of-Distribution Detection
Test-Time Zero-Shot Temporal Action Localization
TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis
TexOct: Generating Textures of 3D Models with Octree-based Diffusion
TexTile: A Differentiable Metric for Texture Tileability
TexVocab: Texture Vocabulary-conditioned Human Avatars
Text Grouping Adapter: Adapting Pre-trained Text Detector for Layout Analysis
Text Is MASS: Modeling as Stochastic Embedding for Text-Video Retrieval
Text Prompt with Normality Guidance for Weakly Supervised Video Anomaly Detection
Text-Conditioned Generative Model of 3D Strand-based Human Hairstyles
Text-Driven Image Editing via Learnable Regions
Text-Enhanced Data-free Approach for Federated Class-Incremental Learning
Text-Guided 3D Face Synthesis - From Generation to Editing
Text-Guided Variational Image Generation for Industrial Anomaly Detection and Segmentation
Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion
Text-Image Alignment for Diffusion-Based Perception
Text-conditional Attribute Alignment across Latent Spaces for 3D Controllable Face Image Synthesis
Text-guided Explorable Image Super-resolution
Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors
Text-to-3D using Gaussian Splatting
Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers
Text2HOI: Text-guided 3D Motion Generation for Hand-Object Interaction
Text2Loc: 3D Point Cloud Localization from Natural Language
Text2QR: Harmonizing Aesthetic Customization and Scanning Robustness for Text-Guided QR Code Generation
TextCraftor: Your Text Encoder Can be Image Quality Controller
TextNeRF: A Novel Scene-Text Image Synthesis Method based on Neural Radiance Fields
Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On
TextureDreamer: Image-Guided Texture Synthesis Through Geometry-Aware Diffusion
The Audio-Visual Conversational Graph: From an Egocentric-Exocentric Perspective
The Devil is in the Details: StyleFeatureEditor for Detail-Rich StyleGAN Inversion and High Quality Image Editing
The Devil is in the Fine-Grained Details: Evaluating Open-Vocabulary Object Detectors for Fine-Grained Understanding
The Manga Whisperer: Automatically Generating Transcriptions for Comics
The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes
The More You See in 2D the More You Perceive in 3D
The Neglected Tails in Vision-Language Models
The STVchrono Dataset: Towards Continuous Change Recognition in Time
The Unreasonable Effectiveness of Pre-Trained Features for Camera Pose Refinement
Theoretically Achieving Continuous Representation of Oriented Bounding Boxes
Think Twice Before Selection: Federated Evidential Active Learning for Medical Image Analysis with Domain Shifts
Three Pillars Improving Vision Foundation Model Distillation for Lidar
TiNO-Edit: Timestep and Noise Optimization for Robust Diffusion-Based Image Editing
Time- Memory- and Parameter-Efficient Visual Adaptation
Time-Efficient Light-Field Acquisition Using Coded Aperture and Events
TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding
ToNNO: Tomographic Reconstruction of a Neural Network’s Output for Weakly Supervised Segmentation of 3D Medical Images
Token Transformation Matters: Towards Faithful Post-hoc Explanation for Vision Transformer
TokenCompose: Text-to-Image Diffusion with Token-level Supervision
TokenHMR: Advancing Human Mesh Recovery with a Tokenized Pose Representation
ToonerGAN: Reinforcing GANs for Obfuscating Automated Facial Indexing
Total Selfie: Generating Full-Body Selfies
Total-Decom: Decomposed 3D Scene Reconstruction with Minimal Interaction
Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts
Towards 3D Vision with Low-Cost Single-Photon Cameras
Towards Accurate Post-training Quantization for Diffusion Models
Towards Accurate and Robust Architectures via Neural Architecture Search
Towards Automated Movie Trailer Generation
Towards Automatic Power Battery Detection: New Challenge Benchmark Dataset and Baseline
Towards Backward-Compatible Continual Learning of Image Compression
Towards Better Vision-Inspired Vision-Language Models
Towards CLIP-driven Language-free 3D Visual Grounding via 2D-3D Relational Enhancement and Consistency
Towards Calibrated Multi-label Deep Neural Networks
Towards Co-Evaluation of Cameras HDR and Algorithms for Industrial-Grade 6DoF Pose Estimation
Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation
Towards Efficient Replay in Federated Incremental Learning
Towards Fairness-Aware Adversarial Learning
Towards General Robustness Verification of MaxPool-based Convolutional Neural Networks via Tightening Linear Approximation
Towards Generalizable Multi-Object Tracking
Towards Generalizable Tumor Synthesis
Towards Generalizing to Unseen Domains with Few Labels
Towards HDR and HFR Video from Rolling-Mixed-Bit Spikings
Towards High-fidelity Artistic Image Vectorization via Texture-Encapsulated Shape Parameterization
Towards Language-Driven Video Inpainting via Multimodal Large Language Models
Towards Large-scale 3D Representation Learning with Multi-dataset Point Prompt Training
Towards Learning a Generalist Model for Embodied Navigation
Towards Memorization-Free Diffusion Models
Towards Modern Image Manipulation Localization: A Large-Scale Dataset and Novel Methods
Towards More Accurate Diffusion Model Acceleration with A Timestep Tuner
Towards More Unified In-context Visual Understanding
Towards Progressive Multi-Frequency Representation for Image Warping
Towards Real-World HDR Video Reconstruction: A Large-Scale Benchmark Dataset and A Two-Stage Alignment Network
Towards Realistic Scene Generation with LiDAR Diffusion Models
Towards Robust 3D Object Detection with LiDAR and 4D Radar Fusion in Various Weather Conditions
Towards Robust 3D Pose Transfer with Adversarial Learning
Towards Robust Event-guided Low-Light Image Enhancement: A Large-Scale Real-World Event-Image Dataset and Novel Approach
Towards Robust Learning to Optimize with Theoretical Guarantees
Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network
Towards Surveillance Video-and-Language Understanding: New Dataset Baselines and Challenges
Towards Text-guided 3D Scene Composition
Towards Transferable Targeted 3D Adversarial Attack in the Physical World
Towards Understanding Cross and Self-Attention in Stable Diffusion for Text-Guided Image Editing
Towards Understanding and Improving Adversarial Robustness of Vision Transformers
Towards Variable and Coordinated Holistic Co-Speech Motion Generation
Towards a Perceptual Evaluation Framework for Lighting Estimation
Towards a Simultaneous and Granular Identity-Expression Control in Personalized Face Generation
Towards the Uncharted: Density-Descending Feature Perturbation for Semi-supervised Semantic Segmentation
Traceable Federated Continual Learning
Traffic Scene Parsing through the TSP6K Dataset
Training Diffusion Models Towards Diverse Image Generation with Reinforcement Learning
Training Generative Image Super-Resolution Models by Wavelet-Domain Losses Enables Better Control of Artifacts
Training Like a Medical Resident: Context-Prior Learning Toward Universal Medical Image Segmentation
Training Vision Transformers for Semi-Supervised Semantic Segmentation
Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation
Training-Free Pretrained Model Merging
TransLoc4D: Transformer-based 4D Radar Place Recognition
TransNeXt: Robust Foveal Visual Perception for Vision Transformers
Transcending Forgery Specificity with Latent Space Augmentation for Generalizable Deepfake Detection
Transcending the Limit of Local Window: Advanced Super-Resolution Transformer with Adaptive Token Dictionary
Transcriptomics-guided Slide Representation Learning in Computational Pathology
Transductive Zero-Shot and Few-Shot CLIP
Transfer CLIP for Generalizable Image Denoising
Transferable Structural Sparse Adversarial Attack Via Exact Group Sparsity Training
Transferable and Principled Efficiency for Open-Vocabulary Segmentation
Tri-Modal Motion Retrieval by Learning a Joint Embedding Space
Tri-Perspective View Decomposition for Geometry-Aware Depth Completion
Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers
Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning
Tumor Micro-environment Interactions Guided Graph Learning for Survival Analysis of Human Cancers from Whole-slide Pathological Images
Tune-An-Ellipse: CLIP Has Potential to Find What You Want
Tuning Stable Rank Shrinkage: Aiming at the Overlooked Structural Risk in Fine-tuning
Turb-Seg-Res: A Segment-then-Restore Pipeline for Dynamic Videos with Atmospheric Turbulence
TurboSL: Dense Accurate and Fast 3D by Neural Inverse Structured Light
TutteNet: Injective 3D Deformations by Composition of 2D Mesh Deformations
Tyche: Stochastic In-Context Learning for Medical Image Segmentation
U-VAP: User-specified Visual Appearance Personalization via Decoupled Self Augmentation
UDiFF: Generating Conditional Unsigned Distance Fields with Optimal Wavelet Diffusion
UFC-Net: Unrolling Fixed-point Continuous Network for Deep Compressive Sensing
UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs
UFORecon: Generalizable Sparse-View Surface Reconstruction from Arbitrary and Unfavorable Sets
UFineBench: Towards Text-based Person Retrieval with Ultra-fine Granularity
ULIP-2: Towards Scalable Multimodal Pre-training for 3D Understanding
URHand: Universal Relightable Hands
USE: Universal Segment Embeddings for Open-Vocabulary Image Segmentation
UV-IDM: Identity-Conditioned Latent Diffusion Model for Face UV-Texture Generation
UVEB: A Large-scale Benchmark and Baseline Towards Real-World Underwater Video Enhancement
UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures
UnO: Unsupervised Occupancy Fields for Perception and Forecasting
UnSAMFlow: Unsupervised Optical Flow Guided by Segment Anything Model
UnScene3D: Unsupervised 3D Instance Segmentation for Indoor Scenes
Unbiased Estimator for Distorted Conics in Camera Calibration
Unbiased Faster R-CNN for Single-source Domain Generalized Object Detection
Uncertainty Visualization via Low-Dimensional Posterior Projections
Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer
Uncertainty-Guided Never-Ending Learning to Drive
Uncertainty-aware Action Decoupling Transformer for Action Anticipation
Uncovering What Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly
Understanding Video Transformers via Universal Concept Discovery
Understanding and Improving Source-free Domain Adaptation from a Theoretical Perspective
Unexplored Faces of Robustness and Out-of-Distribution: Covariate Shifts in Environment and Sensor Domains
Ungeneralizable Examples
UniBind: LLM-Augmented Unified and Balanced Representation Space to Bind Them All
UniDepth: Universal Monocular Metric Depth Estimation
UniGS: Unified Representation for Image Generation and Segmentation
UniGarmentManip: A Unified Framework for Category-Level Garment Manipulation via Dense Visual Correspondence
UniHuman: A Unified Model For Editing Human Images in the Wild
UniMODE: Unified Monocular 3D Object Detection
UniMix: Towards Domain Adaptive and Generalizable LiDAR Semantic Segmentation in Adverse Weather
UniPAD: A Universal Pre-training Paradigm for Autonomous Driving
UniPT: Universal Parallel Tuning for Transfer Learning with Efficient Parameter and Memory
UniPTS: A Unified Framework for Proficient Post-Training Sparsity
UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio Video Point Cloud Time-Series and Image Recognition
UniVS: Unified and Universal Video Segmentation with Prompts as Queries
Unified Entropy Optimization for Open-Set Test-Time Adaptation
Unified Language-driven Zero-shot Domain Adaptation
Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision Language Audio and Action
Unifying Automatic and Interactive Matting with Pretrained ViTs
Unifying Correspondence Pose and NeRF for Generalized Pose-Free Novel View Synthesis
Unifying Top-down and Bottom-up Scanpath Prediction Using Transformers
UnionFormer: Unified-Learning Transformer with Multi-View Representation for Image Manipulation Detection and Localization
Universal Novelty Detection Through Adaptive Contrastive Learning
Universal Robustness via Median Randomized Smoothing for Real-World Super-Resolution
Universal Segmentation at Arbitrary Granularity with Language Instruction
Universal Semi-Supervised Domain Adaptation by Mitigating Common-Class Bias
Unknown Prompt the only Lacuna: Unveiling CLIP's Potential for Open Domain Generalization
Unleashing Channel Potential: Space-Frequency Selection Convolution for SAR Object Detection
Unleashing Network Potentials for Semantic Scene Completion
Unleashing Unlabeled Data: A Paradigm for Cross-View Geo-Localization
Unleashing the Potential of SAM for Medical Adaptation via Hierarchical Decoding
Unlocking Pre-trained Image Backbones for Semantic Image Synthesis
Unlocking the Potential of Pre-trained Vision Transformers for Few-Shot Semantic Segmentation through Relationship Descriptors
Unlocking the Potential of Prompt-Tuning in Bridging Generalized and Personalized Federated Learning
Unmixing Before Fusion: A Generalized Paradigm for Multi-Source-based Hyperspectral Image Synthesis
Unmixing Diffusion for Self-Supervised Hyperspectral Image Denoising
Unraveling Instance Associations: A Closer Look for Audio-Visual Segmentation
Unsegment Anything by Simulating Deformation
Unsigned Orthogonal Distance Fields: An Accurate Neural Implicit Representation for Diverse 3D Shapes
Unsupervised 3D Structure Inference from Category-Specific Image Collections
Unsupervised Blind Image Deblurring Based on Self-Enhancement
Unsupervised Deep Unrolling Networks for Phase Unwrapping
Unsupervised Feature Learning with Emergent Data-Driven Prototypicality
Unsupervised Gaze Representation Learning from Multi-view Face Images
Unsupervised Keypoints from Pretrained Diffusion Models
Unsupervised Learning of Category-Level 3D Pose from Object-Centric Videos
Unsupervised Occupancy Learning from Sparse Point Cloud
Unsupervised Salient Instance Detection
Unsupervised Semantic Segmentation Through Depth-Guided Feature Correlation and Sampling
Unsupervised Template-assisted Point Cloud Shape Correspondence Network
Unsupervised Universal Image Segmentation
Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training
Unveiling Parts Beyond Objects: Towards Finer-Granularity Referring Expression Segmentation
Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling
Unveiling the Unknown: Unleashing the Power of Unknown to Known in Open-Set Source-Free Domain Adaptation
Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution
Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model
Utility-Fairness Trade-Offs and How to Find Them
V?: Guided Visual Search as a Core Mechanism in Multimodal LLMs
VA3: Virtually Assured Amplification Attack on Probabilistic Copyright Protection for Text-to-Image Generative Models
VAREN: Very Accurate and Realistic Equine Network
VBench: Comprehensive Benchmark Suite for Video Generative Models
VCoder: Versatile Vision Encoders for Multimodal Large Language Models
VGGSfM: Visual Geometry Grounded Deep Structure From Motion
VILA: On Pre-training for Visual Language Models
VINECS: Video-based Neural Character Skinning
VISTA-LLAMA: Reducing Hallucination in Video Language Models via Equal Distance to Visual Tokens
VLP: Vision Language Planning for Autonomous Driving
VMC: Video Motion Customization using Temporal Attention Adaption for Text-to-Video Diffusion Models
VMINer: Versatile Multi-view Inverse Rendering with Near- and Far-field Light Sources
VOODOO 3D: Volumetric Portrait Disentanglement For One-Shot 3D Head Reenactment
VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation
VRP-SAM: SAM with Visual Reference Prompt
VRetouchEr: Learning Cross-frame Feature Interdependence with Imperfection Flow for Face Retouching in Videos
VS: Reconstructing Clothed 3D Human from Single Image via Vertex Shift
VSCode: General Visual Salient and Camouflaged Object Detection with 2D Prompt Learning
VSRD: Instance-Aware Volumetric Silhouette Rendering for Weakly Supervised 3D Object Detection
VTQA: Visual Text Question Answering via Entity Alignment and Cross-Media Reasoning
VTimeLLM: Empower LLM to Grasp Video Moments
Validating Privacy-Preserving Face Recognition under a Minimum Assumption
Vanishing-Point-Guided Video Semantic Segmentation of Driving Scenes
VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction
VecFusion: Vector Font Generation with Diffusion
Vector Graphics Generation via Mutually Impulsed Dual-domain Diffusion
Versatile Medical Image Segmentation Learned from Multi-Source Datasets via Model Self-Disambiguation
Versatile Navigation Under Partial Observability via Value-guided Diffusion Policy
ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification
ViP-LLaVA: Making Large Multimodal Models Understand Arbitrary Visual Prompts
ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions
ViT-Lens: Towards Omni-modal Representations
ViTamin: Designing Scalable Vision Models in the Vision-Language Era
ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models
VicTR: Video-conditioned Text Representations for Activity Recognition
VidLA: Video-Language Alignment at Scale
VidToMe: Video Token Merging for Zero-Shot Video Editing
Video Frame Interpolation via Direct Synthesis with the Event-based Reference
Video Harmonization with Triplet Spatio-Temporal Variation Patterns
Video Interpolation with Diffusion Models
Video Prediction by Modeling Videos as Continuous Multi-Dimensional Processes
Video ReCap: Recursive Captioning of Hour-Long Videos
Video Recognition in Portrait Mode
Video Super-Resolution Transformer with Masked Inter&Intra-Frame Attention
Video-Based Human Pose Regression via Decoupled Space-Time Aggregation
Video-P2P: Video Editing with Cross-attention Control
Video2Game: Real-time Interactive Realistic and Browser-Compatible Environment from a Single Video
VideoBooth: Diffusion-based Video Generation with Image Prompts
VideoCon: Robust Video-Language Alignment via Contrast Captions
VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models
VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation
VideoGrounding-DINO: Towards Open-Vocabulary Spatio-Temporal Video Grounding
VideoLLM-online: Online Video Large Language Model for Streaming Video
VideoMAC: Video Masked Autoencoders Meet ConvNets
VideoRF: Rendering Dynamic Radiance Fields as 2D Feature Video Streams
VideoSwap: Customized Video Subject Swapping with Interactive Semantic Point Correspondence
View From Above: Orthogonal-View aware Cross-view Localization
View-Category Interactive Sharing Transformer for Incomplete Multi-View Multi-Label Learning
View-decoupled Transformer for Person Re-identification under Aerial-ground Camera Network
ViewDiff: 3D-Consistent Image Generation with Text-to-Image Models
ViewFusion: Towards Multi-View Consistency via Interpolated Denoising
Viewpoint-Aware Visual Grounding in 3D Scenes
Virtual Immunohistochemistry Staining for Histological Images Assisted by Weakly-supervised Learning
Vision-and-Language Navigation via Causal Learning
Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models
Visual Concept Connectome (VCC): Open World Concept Discovery and their Interlayer Connections in Deep Models
Visual Delta Generator with Large Multi-modal Models for Semi-supervised Composed Image Retrieval
Visual Fact Checker: Enabling High-Fidelity Detailed Caption Generation
Visual In-Context Prompting
Visual Layout Composer: Image-Vector Dual Diffusion Model for Design Layout Generation
Visual Objectification in Films: Towards a New AI Task for Video Interpretation
Visual Point Cloud Forecasting enables Scalable Autonomous Driving
Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models
Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding
Visual Prompting for Generalized Few-shot Segmentation: A Multi-scale Approach
Visual-Augmented Dynamic Semantic Prototype for Generative Zero-Shot Learning
VkD: Improving Knowledge Distillation using Orthogonal Projections
Vlogger: Make Your Dream A Vlog
VoCo: A Simple-yet-Effective Volume Contrastive Learning Framework for 3D Medical Image Analysis
Volumetric Environment Representation for Vision-Language Navigation
WALT3D: Generating Realistic Training Data from Time-Lapse Imagery for Reconstructing Dynamic Objects Under Occlusion
WANDR: Intention-guided Human Motion Generation
WHAM: Reconstructing World-grounded Humans with Accurate 3D Motion
WOUAF: Weight Modulation for User Attribution and Fingerprinting in Text-to-Image Diffusion Models
WWW: A Unified Framework for Explaining What Where and Why of Neural Networks by Interpretation of Neuron Concepts
WateRF: Robust Watermarks in Radiance Fields for Protection of Copyrights
Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models
WaveFace: Authentic Face Restoration with Efficient Frequency Recovery
WaveMo: Learning Wavefront Modulations to See Through Scattering
Wavelet-based Fourier Information Interaction with Frequency Diffusion Adjustment for Underwater Image Restoration
Weak-to-Strong 3D Object Detection with X-Ray Distillation
Weakly Misalignment-free Adaptive Feature Alignment for UAVs-based Multimodal Object Detection
Weakly Supervised Monocular 3D Detection with a Single-View Image
Weakly Supervised Point Cloud Semantic Segmentation via Artificial Oracle
Weakly Supervised Video Individual Counting
Weakly-Supervised Audio-Visual Video Parsing with Prototype-based Pseudo-Labeling
Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech Gesture Generation
What Do You See in Vehicle? Comprehensive Vision Solution for In-Vehicle Gaze Estimation
What How and When Should Object Detectors Update in Continually Changing Test Domains?
What If the TV Was Off? Examining Counterfactual Reasoning Abilities of Multi-modal Language Models
What Sketch Explainability Really Means for Downstream Tasks?
What When and Where? Self-Supervised Spatio-Temporal Grounding in Untrimmed Multi-Action Videos from Narrated Instructions
What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs
When StyleGAN Meets Stable Diffusion: a W+ Adapter for Personalized Image Generation
When Visual Grounding Meets Gigapixel-level Large-scale Scenes: Benchmark and Approach
Why Not Use Your Textbook? Knowledge-Enhanced Procedure Planning of Instructional Videos
WildlifeMapper: Aerial Image Analysis for Multi-Species Detection and Identification
WinSyn: : A High Resolution Testbed for Synthetic Data
Wired Perspectives: Multi-View Wire Art Embraces Generative AI
Wonder3D: Single Image to 3D using Cross-Domain Diffusion
WonderJourney: Going from Anywhere to Everywhere
WorDepth: Variational Language Prior for Monocular Depth Estimation
Would Deep Generative Models Amplify Bias in Future Models?
X-3D: Explicit 3D Structure Modeling for Point Cloud Recognition
X-Adapter: Adding Universal Compatibility of Plugins for Upgraded Diffusion Model
X-MIC: Cross-Modal Instance Conditioning for Egocentric Action Generalization
XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies
XFeat: Accelerated Features for Lightweight Image Matching
XFibrosis: Explicit Vessel-Fiber Modeling for Fibrosis Staging from Liver Pathology Images
XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold
YOLO-World: Real-Time Open-Vocabulary Object Detection
YolOOD: Utilizing Object Detection Concepts for Multi-Label Out-of-Distribution Detection
You Only Need Less Attention at Each Stage in Vision Transformers
You'll Never Walk Alone: A Sketch and Text Duet for Fine-Grained Image Retrieval
Your Image is My Video: Reshaping the Receptive Field via Image-To-Video Differentiable AutoAugmentation and Fusion
Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models
Your Transferability Barrier is Fragile: Free-Lunch for Transferring the Non-Transferable Learning
Z*: Zero-shot Style Transfer via Attention Reweighting
ZERO-IG: Zero-Shot Illumination-Guided Joint Denoising and Adaptive Enhancement for Low-Light Images
ZONE: Zero-Shot Instruction-Guided Local Editing
ZePT: Zero-Shot Pan-Tumor Segmentation via Query-Disentangling and Self-Prompting
Zero-Painter: Training-Free Layout Control for Text-to-Image Synthesis
Zero-Reference Low-Light Enhancement via Physical Quadruple Priors
Zero-Shot Structure-Preserving Diffusion Model for High Dynamic Range Tone Mapping
Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention Graph in Pre-Trained Transformers
Zero-shot Referring Expression Comprehension via Structural Similarity Between Images and Captions
ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Image
ZeroRF: Fast Sparse View 360° Reconstruction with Zero Pretraining
ZeroShape: Regression-based Zero-shot Shape Reconstruction
eTraM: Event-based Traffic Monitoring Dataset
iKUN: Speak to Trackers without Retraining
iToF-flow-based High Frame Rate Depth Imaging
mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration
pix2gestalt: Amodal Segmentation by Synthesizing Wholes
pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction
vid-TLDR: Training Free Token Merging for Light-weight Video Transformer
