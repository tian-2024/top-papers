Provably Safe Online Multi-Agent Navigation in Unknown Environments
One Model to Drift Them All: Physics-Informed Conditional Diffusion Model for Driving at the Limits
EscIRL: Evolving Self-Contrastive IRL for Trajectory Prediction in Autonomous Driving
Learning Robotic Locomotion Affordances and Photorealistic Simulators from Human-Captured Data
Get a Grip: Multi-Finger Grasp Evaluation at Scale Enables Robust Sim-to-Real Transfer
Trajectory Improvement and Reward Learning from Comparative Language Feedback
Multi-agent Reinforcement Learning with Hybrid Action Space for Free Gait Motion Planning of Hexapod Robots
Genetic Algorithm for Curriculum Design in Multi-Agent Reinforcement Learning
Robot See Robot Do: Imitating Articulated Object Manipulation with Monocular 4D Reconstruction
Manipulate-Anything: Automating Real-World Robots using Vision-Language Models
Learning Transparent Reward Models via Unsupervised Feature Selection
Accelerating Visual Sparse-Reward Learning with Latent Nearest-Demonstration-Guided Explorations
FlowBotHD: History-Aware Diffuser Handling Ambiguities in Articulated Objects Manipulation
FREA: Feasibility-Guided Generation of Safety-Critical Scenarios with Reasonable Adversariality
UMI-on-Legs: Making Manipulation Policies Mobile with Manipulation-Centric Whole-body Controllers
PointPatchRL - Masked Reconstruction Improves Reinforcement Learning on Point Clouds
Twisting Lids Off with Two Hands
Continuously Improving Mobile Manipulation with Autonomous Real-World RL
RP1M: A Large-Scale Motion Dataset for Piano Playing with Bi-Manual Dexterous Robot Hands
Bimanual Dexterity for Complex Tasks
IMAGINATION POLICY: Using Generative Point Cloud Models for Learning Manipulation Policies
Learning Differentiable Tensegrity Dynamics using Graph Neural Networks
DexGraspNet 2.0: Learning Generative Dexterous Grasping in Large-scale Synthetic Cluttered Scenes
Promptable Closed-loop Traffic Simulation
EquiGraspFlow: SE(3)-Equivariant 6-DoF Grasp Pose Generative Flows
GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning LLMs
In-Flight Attitude Control of a Quadruped using Deep Reinforcement Learning
Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance
Online Transfer and Adaptation of Tactile Skill: A Teleoperation Framework
Distribution Discrepancy and Feature Heterogeneity for Active 3D Object Detection
D$^3$RoMa: Disparity Diffusion-based Depth Sensing for Material-Agnostic Robotic Manipulation
Automated Creation of Digital Cousins for Robust Policy Learning
ACE: A Cross-platform and visual-Exoskeletons System for Low-Cost Dexterous Teleoperation
UBSoft: A Simulation Platform for Robotic Skill Learning in Unbounded Soft Environments
GenDP: 3D Semantic Fields for Category-Level Generalizable Diffusion Policy
MimicTouch: Leveraging Multi-modal Human Tactile Demonstrations for Contact-rich Manipulation
Monocular Event-Based Vision for Obstacle Avoidance with a Quadrotor
Autonomous Improvement of Instruction Following Skills via Foundation Models
Learning Performance-oriented Control Barrier Functions Under Complex Safety Constraints and Limited Actuation
RAM: Retrieval-Based Affordance Transfer for Generalizable Zero-Shot Robotic Manipulation
Safe Bayesian Optimization for the Control of High-Dimensional Embodied Systems
Splat-MOVER: Multi-Stage, Open-Vocabulary Robotic Manipulation via Editable Gaussian Splatting
AnyRotate: Gravity-Invariant In-Hand Object Rotation with Sim-to-Real Touch
DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models
Handling Long-Term Safety and Uncertainty in Safe Reinforcement Learning
Contrastive Imitation Learning for Language-guided Multi-Task Robotic Manipulation
Generalized Animal Imitator: Agile Locomotion with Versatile Motion Prior
Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation
Fleet Supervisor Allocation: A Submodular Maximization Approach
ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation
Leveraging Mutual Information for Asymmetric Learning under Partial Observability
What Makes Pre-Trained Visual Representations Successful for Robust Manipulation?
KOROL: Learning Visualizable Object Feature with Koopman Operator Rollout for Manipulation
Physically Embodied Gaussian Splatting: A Visually Learnt and Physically Grounded 3D Representation for Robotics
Neural Attention Field: Emerging Point Relevance in 3D Scenes for One-Shot Dexterous Grasping
Velociraptor: Leveraging Visual Foundation Models for Label-Free, Risk-Aware Off-Road Navigation
Simple Masked Training Strategies Yield Control Policies That Are Robust to Sensor Failure
Scaling Cross-Embodied Learning: One Policy for Manipulation, Navigation, Locomotion and Aviation
Dynamics-Guided Diffusion Model for Sensor-less Robot Manipulator Design
Learning to Look: Seeking Information for Decision Making via Policy Factorization
ResPilot: Teleoperated Finger Gaiting via Gaussian Process Residual Learning
DiffusionSeeder: Seeding Motion Optimization with Diffusion for Rapid Motion Planning
Neural Inverse Source Problem
Bridging the Sim-to-Real Gap from the Information Bottleneck Perspective
VoxAct-B: Voxel-Based Acting and Stabilizing Policy for Bimanual Manipulation
SonicSense: Object Perception from In-Hand Acoustic Vibration
Enhancing Visual Domain Robustness in Behaviour Cloning via Saliency-Guided Augmentation
WoCoCo: Learning Whole-Body Humanoid Control with Sequential Contacts
Multi-Task Interactive Robot Fleet Learning with Visual World Models
SoloParkour: Constrained Reinforcement Learning for Visual Locomotion from Privileged Experience
Context-Aware Replanning with Pre-Explored Semantic Map for Object Navigation
Learning Long-Horizon Action Dependencies in Sampling-Based Bilevel Planning
Visual Manipulation with Legs
BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark
ViPER: Visibility-based Pursuit-Evasion via Reinforcement Learning
Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models
What Matters in Range View 3D Object Detection
TaMMa: Target-driven Multi-subscene Mobile Manipulation
Event3DGS: Event-Based 3D Gaussian Splatting for High-Speed Robot Egomotion
Environment Curriculum Generation via Large Language Models
FlowRetrieval: Flow-Guided Data Retrieval for Few-Shot Imitation Learning
Mobile ALOHA: Learning Bimanual Mobile Manipulation using Low-Cost Whole-Body Teleoperation
Not All Errors Are Made Equal: A Regret Metric for Detecting System-level Trajectory Prediction Failures
Teaching Robots with Show and Tell: Using Foundation Models to Synthesize Robot Policies from Language and Visual Demonstration
Action Space Design in Reinforcement Learning for Robot Motor Skills
RoboPoint: A Vision-Language Model for Spatial Affordance Prediction in Robotics
Detect Everything with Few Examples
VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding
Dreamitate: Real-World Visuomotor Policy Learning via Video Generation
ANAVI: Audio Noise Awareness using Visual of Indoor environments for NAVIgation
Multi-Strategy Deployment-Time Learning and Adaptation for Navigation under Uncertainty
MaIL: Improving Imitation Learning with Selective State Space Models
Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs
KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance
Object-Centric Dexterous Manipulation from Human Motion Data
Reasoning Grasping via Multimodal Large Language Model
CoViS-Net: A Cooperative Visual Spatial Foundation Model for Multi-Robot Applications
Transferable Tactile Transformers for Representation Learning Across Diverse Sensors and Tasks
Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving
PoliFormer: Scaling On-Policy RL with Transformers Results in Masterful Navigators
Gameplay Filters: Robust Zero-Shot Safety through Adversarial Imagination
TidyBot++: An Open-Source Holonomic Mobile Manipulator for Robot Learning
Evaluating Real-World Robot Manipulation Policies in Simulation
Uncertainty-Aware Decision Transformer for Stochastic Driving Environments
MBC: Multi-Brain Collaborative Control for Quadruped Robots
A Planar-Symmetric SO(3) Representation for Learning Grasp Detection
Tokenize the World into Object-level Knowledge to Address Long-tail Events in Autonomous Driving
T$^2$SQNet: A Recognition Model for Manipulating Partially Observed Transparent Tableware Objects
CtRL-Sim: Reactive and Controllable Driving Agents with Offline Reinforcement Learning
LiDARGrid: Self-supervised 3D Opacity Grid from LiDAR for Scene Forecasting
ThinkGrasp: A Vision-Language System for Strategic Part Grasping in Clutter
Modeling Drivers’ Situational Awareness from Eye Gaze for Driving Assistance
SHADOW: Leveraging Segmentation Masks for Cross-Embodiment Policy Transfer
Scaling Safe Multi-Agent Control for Signal Temporal Logic Specifications
Play to the Score: Stage-Guided Dynamic Multi-Sensory Fusion for Robotic Manipulation
Learning a Distributed Hierarchical Locomotion Controller for Embodied Cooperation
RoboKoop: Efficient Control Conditioned Representations from Visual Input in Robotics using Koopman Operator
TOP-Nav: Legged Navigation Integrating Terrain, Obstacle and Proprioception Estimation
Adapting Humanoid Locomotion over Challenging Terrain via Two-Phase Training
Adaptive Language-Guided Abstraction from Contrastive Explanations
Body Transformer: Leveraging Robot Embodiment for Policy Learning
JointMotion: Joint Self-Supervision for Joint Motion Prediction
ScissorBot: Learning Generalizable Scissor Skill for Paper Cutting via Simulation, Imitation, and Sim2Real
One Policy to Run Them All: an End-to-end Learning Approach to Multi-Embodiment Locomotion
LLARVA: Vision-Action Instruction Tuning Enhances Robot Learning
Towards Open-World Grasping with Large Vision-Language Models
Progressive Multi-Modal Fusion for Robust 3D Object Detection
Leveraging Locality to Boost Sample Efficiency in Robotic Manipulation
Task Success Prediction for Open-Vocabulary Manipulation Based on Multi-Level Aligned Representations
Learning Granular Media Avalanche Behavior for Indirectly Manipulating Obstacles on a Granular Slope
SLR: Learning Quadruped Locomotion without Privileged Information
DextrAH-G: Pixels-to-Action Dexterous Arm-Hand Grasping with Geometric Fabrics
Robotic Control via Embodied Chain-of-Thought Reasoning
Autonomous Interactive Correction MLLM for Robust Robotic Manipulation
Lessons from Learning to Spin “Pens”
JA-TN: Pick-and-Place Towel Shaping from Crumpled States based on TransporterNet with Joint-Probability Action Inference
An Open-Source Soft Robotic Platform for Autonomous Aerial Manipulation in the Wild
TieBot: Learning to Knot a Tie from Visual Demonstration through a Real-to-Sim-to-Real Approach
Structured Bayesian Meta-Learning for Data-Efficient Visual-Tactile Model Estimation
FetchBench: A Simulation Benchmark for Robot Fetching
RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for Robotic Manipulation
OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation
Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions
D$^3$Fields: Dynamic 3D Descriptor Fields for Zero-Shot Generalizable Rearrangement
Differentiable Discrete Elastic Rods for Real-Time Modeling of Deformable Linear Objects
Sim-to-Real Transfer via 3D Feature Fields for Vision-and-Language Navigation
DexCatch: Learning to Catch Arbitrary Objects with Dexterous Hands
Implicit Grasp Diffusion: Bridging the Gap between Dense Prediction and Sampling-based Grasping
Legolas: Deep Leg-Inertial Odometry
Learning to Open and Traverse Doors with a Legged Manipulator
Let Occ Flow: Self-Supervised 3D Occupancy Flow Prediction
Continuous Control with Coarse-to-fine Reinforcement Learning
Cloth-Splatting: 3D Cloth State Estimation from RGB Supervision
HumanPlus: Humanoid Shadowing and Imitation from Humans
Multi-Transmotion: Pre-trained Model for Human Motion Prediction
Learning Quadruped Locomotion Using Differentiable Simulation
So You Think You Can Scale Up Autonomous Robot Data Collection?
SkillMimicGen: Automated Demonstration Generation for Efficient Skill Learning and Deployment
Open-TeleVision: Teleoperation with Immersive Active Visual Feedback
Scaling Manipulation Learning with Visual Kinematic Chain Prediction
OpenVLA: An Open-Source Vision-Language-Action Model
Bridging the gap between Learning-to-plan, Motion Primitives and Safe Reinforcement Learning
Conformal Prediction for Semantically-Aware Autonomous Perception in Urban Environments
Dreaming to Assist: Learning to Align with Human Objectives for Shared Control in High-Speed Racing
Rate-Informed Discovery via Bayesian Adaptive Multifidelity Sampling
3D-ViTac: Learning Fine-Grained Manipulation with Visuo-Tactile Sensing
Bootstrapping Reinforcement Learning with Imitation for Vision-Based Agile Flight
Perceive With Confidence: Statistical Safety Assurances for Navigation with Learning-Based Perception
Learning Visual Parkour from Generated Images
Flow as the Cross-domain Manipulation Interface
Visual Whole-Body Control for Legged Loco-Manipulation
OrbitGrasp: SE(3)-Equivariant Grasp Learning
Generative Image as Action Models
Pre-emptive Action Revision by Environmental Feedback for Embodied Instruction Following Agents
RoVi-Aug: Robot and Viewpoint Augmentation for Cross-Embodiment Robot Learning
OPEN TEACH: A Versatile Teleoperation System for Robotic Manipulation
SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for Long-Horizon Manipulation
Meta-Control: Automatic Model-based Control Synthesis for Heterogeneous Robot Skills
MOSAIC: Modular Foundation Models for Assistive and Interactive Cooking
Contrast Sets for Evaluating Language-Guided Robot Policies
TLDR: Unsupervised Goal-Conditioned RL via Temporal Distance-Aware Representations
Reinforcement Learning with Foundation Priors: Let Embodied Agent Efficiently Learn on Its Own
RiEMann: Near Real-Time SE(3)-Equivariant Robot Manipulation without Point Cloud Segmentation
Solving Offline Reinforcement Learning with Decision Tree Regression
Tag Map: A Text-Based Map for Spatial Reasoning and Navigation with Large Language Models
Large Scale Mapping of Indoor Magnetic Field by Local and Sparse Gaussian Processes
Shelf-Supervised Cross-Modal Pre-Training for 3D Object Detection
Learning to Walk from Three Minutes of Real-World Data with Semi-structured Dynamics Models
Learning Robot Soccer from Egocentric Vision with Deep Reinforcement Learning
InstructNav: Zero-shot System for Generic Instruction Navigation in Unexplored Environment
VIRL: Self-Supervised Visual Graph Inverse Reinforcement Learning
ReMix: Optimizing Data Mixtures for Large Scale Imitation Learning
Surgical Robot Transformer (SRT): Imitation Learning for Surgical Tasks
Learning Compositional Behaviors from Demonstration and Language
Humanoid Parkour Learning
3D Diffuser Actor: Policy Diffusion with 3D Scene Representations
Avoid Everything: Model-Free Collision Avoidance with Expert-Guided Fine-Tuning
ALOHA Unleashed: A Simple Recipe for Robot Dexterity
Task-Oriented Hierarchical Object Decomposition for Visuomotor Control
I Can Tell What I am Doing: Toward Real-World Natural Language Grounding of Robot Experiences
Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling
Region-aware Grasp Framework with Normalized Grasp Space for Efficient 6-DoF Grasping
Learning to Manipulate Anywhere: A Visual Generalizable Framework For Reinforcement Learning
Verification of Neural Control Barrier Functions with Symbolic Derivative Bounds Propagation
ClutterGen: A Cluttered Scene Generator for Robot Learning
Q-SLAM: Quadric Representations for Monocular SLAM
Goal-Reaching Policy Learning from Non-Expert Observations via Effective Subgoal Guidance
InterACT: Inter-dependency Aware Action Chunking with Hierarchical Attention Transformers for Bimanual Manipulation
TRANSIC: Sim-to-Real Policy Transfer by Learning from Online Correction
Differentiable Robot Rendering
A3VLM: Actionable Articulation-Aware Vision Language Model
HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation
APRICOT: Active Preference Learning and Constraint-Aware Task Planning with LLMs
DiffuseLoco: Real-Time Legged Locomotion Control with Diffusion from Offline Datasets
General Flow as Foundation Affordance for Scalable Robot Learning
OmniH2O: Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning
Learning Visuotactile Estimation and Control for Non-prehensile Manipulation under Occlusions
SoftManiSim: A Fast Simulation Framework for Multi-Segment Continuum Manipulators Tailored for Robot Learning
Generative Factor Chaining: Coordinated Manipulation with Diffusion-based Factor Graph
GraspSplats: Efficient Manipulation with 3D Feature Splatting
Modeling the Real World with High-Density Visual Particle Dynamics
Policy Adaptation via Language Optimization: Decomposing Tasks for Few-Shot Imitation
Control with Patterns: A D-learning Method
Trust the PRoC3S: Solving Long-Horizon Robotics Problems with LLMs and Constraint Satisfaction
Toward General Object-level Mapping from Sparse Views with 3D Diffusion Priors
SELFI: Autonomous Self-Improvement with RL for Vision-Based Navigation around People
NOD-TAMP: Generalizable Long-Horizon Planning with Neural Object Descriptors
DeliGrasp: Inferring Object Properties with LLMs for Adaptive Grasp Policies
Non-rigid Relative Placement through 3D Dense Diffusion
Text2Interaction: Establishing Safe and Preferable Human-Robot Interaction
Generalizing End-To-End Autonomous Driving In Real-World Environments Using Zero-Shot LLMs
Exploring Under Constraints with Model-Based Actor-Critic and Safety Filters
PianoMime: Learning a Generalist, Dexterous Piano Player from Internet Demonstrations
View-Invariant Policy Learning via Zero-Shot Novel View Synthesis
RT-Sketch: Goal-Conditioned Imitation Learning from Hand-Drawn Sketches
EXTRACT: Efficient Policy Learning by Extracting Transferable Robot Skills from Offline Data
A Dual Approach to Imitation Learning from Observations with Offline Datasets
Real-to-Sim Grasp: Rethinking the Gap between Simulation and Real World in Grasp Detection
Learning H-Infinity Locomotion Control
Gaussian Splatting to Real World Flight Navigation Transfer with Liquid Networks
EquiBot: SIM(3)-Equivariant Diffusion Policy for Generalizable and Data Efficient Learning
Lifelong Autonomous Improvement of Navigation Foundation Models in the Wild
Learning Decentralized Multi-Biped Control for Payload Transport
Jacta: A Versatile Planner for Learning Dexterous and Whole-body Manipulation
Learning Robotic Manipulation Policies from Point Clouds with Conditional Flow Matching
Equivariant Diffusion Policy
Bi-Level Motion Imitation for Humanoid Robots
ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data
HiRT: Enhancing Robotic Control with Hierarchical Robot Transformers
RobotKeyframing: Learning Locomotion with High-Level Objectives via Mixture of Dense and Sparse Rewards
Sparsh: Self-supervised touch representations for vision-based tactile sensing
Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation
Discovering Robotic Interaction Modes with Discrete Representation Learning
OCCAM: Online Continuous Controller Adaptation with Meta-Learned Models
MILES: Making Imitation Learning Easy with Self-Supervision
Robust Manipulation Primitive Learning via Domain Contraction
Gaitor: Learning a Unified Representation Across Gaits for Real-World Quadruped Locomotion
Language-guided Manipulator Motion Planning with Bounded Task Space
Theia: Distilling Diverse Vision Foundation Models for Robot Learning
Vocal Sandbox: Continual Learning and Adaptation for Situated Human-Robot Collaboration
Unpacking Failure Modes of Generative Policies: Runtime Monitoring of Consistency and Progress
LeLaN: Learning A Language-Conditioned Navigation Policy from In-the-Wild Video
Sparse Diffusion Policy: A Sparse, Reusable, and Flexible Policy for Robot Learning
Gentle Manipulation of Tree Branches: A Contact-Aware Policy Learning Approach
