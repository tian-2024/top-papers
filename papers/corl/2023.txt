Simultaneous Learning of Contact and Continuous Dynamics
Act3D: 3D Feature Field Transformers for Multi-Task Robotic Manipulation
ViNT: A Foundation Model for Visual Navigation
Preference learning for guiding the tree search in continuous POMDPs
Q-Transformer: Scalable Offline Reinforcement Learning via Autoregressive Q-Functions
Goal Representations for Instruction Following: A Semi-Supervised Language Interface to Control
RVT: Robotic View Transformer for 3D Object Manipulation
$\alpha$-MDF: An Attention-based Multimodal Differentiable Filter for Robot State Estimation
Improving Behavioural Cloning with Positive Unlabeled Learning
Deception Game: Closing the Safety-Learning Loop in Interactive Robot Autonomy
Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon Manipulation
Policy Stitching: Learning Transferable Robot Policies
Marginalized Importance Sampling for Off-Environment Policy Evaluation
Robot Learning with Sensorimotor Pre-training
Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition
DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object Detection and Tracking
STOW: Discrete-Frame Segmentation and Tracking of Unseen Objects for Warehouse Picking Robots
Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners
Generating Transferable Adversarial Simulation Scenarios for Self-Driving via Neural Rendering
Online Model Adaptation with Feedforward Compensation
Ready, Set, Plan! Planning to Goal Sets Using Generalized Bayesian Inference
RoboCook: Long-Horizon Elasto-Plastic Object Manipulation with Diverse Tools
MOTO: Offline Pre-training to Online Fine-tuning for Model-based Robot Learning
Learning to Drive Anywhere
Measuring Interpretability of Neural Policies of Robots with Disentangled Representation
M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place
How to Learn and Generalize From Three Minutes of Data: Physics-Constrained and Uncertainty-Aware Neural Stochastic Differential Equations
Learning Human Contribution Preferences in Collaborative Human-Robot Tasks
SLAP: Spatial-Language Attention Policies
SayTap: Language to Quadrupedal Locomotion
Stabilize to Act: Learning to Coordinate for Bimanual Manipulation
XSkill: Cross Embodiment Skill Discovery
Push Past Green: Learning to Look Behind Plant Foliage by Moving It
Task Generalization with Stability Guarantees via Elastic Dynamical System Motion Policies
REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction
Dexterous Functional Grasping
AdaptSim: Task-Driven Simulation Adaptation for Sim-to-Real Transfer
Learning Generalizable Manipulation Policies with Object-Centric 3D Representations
VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models
Open-World Object Manipulation using Pre-Trained Vision-Language Models
Language-Conditioned Path Planning
LabelFormer: Object Trajectory Reﬁnement for Offboard Perception from LiDAR Point Clouds
A Universal Semantic-Geometric Representation for Robotic Manipulation
UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding
Equivariant Reinforcement Learning under Partial Observability
Self-Improving Robots: End-to-End Autonomous Visuomotor Reinforcement Learning
Cold Diffusion on the Replay Buffer: Learning to Plan from Known Good States
Precise Robotic Needle-Threading with Tactile Perception and Reinforcement Learning
Compositional Diffusion-Based Continuous Constraint Solvers
Topology-Matching Normalizing Flows for Out-of-Distribution Detection in Robot Learning
Surrogate Assisted Generation of Human-Robot Interaction Scenarios
Few-Shot In-Context Imitation Learning via Implicit Graph Alignment
Structural Concept Learning via Graph Attention for Multi-Level Rearrangement Planning
Diff-LfD: Contact-aware Model-based Learning from Visual Demonstration for Robotic Manipulation via Differentiable Physics-based Simulation and Rendering
PreCo: Enhancing Generalization in Co-Design of Modular Soft Robots via Brain-Body Pre-Training
ADU-Depth: Attention-based Distillation with Uncertainty Modeling for Depth Estimation
Dexterity from Touch: Self-Supervised Pre-Training of Tactile Representations with Robotic Play
Intent-Aware Planning in Heterogeneous Traffic via Distributed Multi-Agent Reinforcement Learning
Energy-based Potential Games for Joint Motion Forecasting and Control
FastRLAP: A System for Learning High-Speed Driving via Deep RL and Autonomous Practicing
TactileVAD: Geometric Aliasing-Aware Dynamics for High-Resolution Tactile Control
Gesture-Informed Robot Assistance via Foundation Models
Human-in-the-Loop Task and Motion Planning for Imitation Learning
Heteroscedastic Gaussian Processes and Random Features: Scalable Motion Primitives with Guarantees
Revisiting Depth-guided Methods for Monocular 3D Object Detection by Hierarchical Balanced Depth
RoboPianist: Dexterous Piano Playing with Deep Reinforcement Learning
Polybot: Training One Policy Across Robots While Embracing Variability
Online Learning for Obstacle Avoidance
Generative Skill Chaining: Long-Horizon Skill Planning with Diffusion Models
Fighting Uncertainty with Gradients: Offline Reinforcement Learning via Diffusion Score Matching
PairwiseNet: Pairwise Collision Distance Learning for High-dof Robot Systems
Affordance-Driven Next-Best-View Planning for Robotic Grasping
AR2-D2: Training a Robot Without a Robot
Finetuning Offline World Models in the Real World
Neural Field Dynamics Model for Granular Object Piles Manipulation
Multi-Predictor Fusion: Combining Learning-based and Rule-based Trajectory Predictors
CAJun: Continuous Adaptive Jumping using a Learned Centroidal Controller
Generalization of Heterogeneous Multi-Robot Policies via Awareness and Communication of Capabilities
CALAMARI: Contact-Aware and Language conditioned spatial Action MApping for contact-RIch manipulation
Language Conditioned Traffic Generation
A Data-efficient Neural ODE Framework for Optimal Control of Soft Manipulators
Navigation with Large Language Models: Semantic Guesswork as a Heuristic for Planning
MUTEX: Learning Unified Policies from Multimodal Task Specifications
Learning Lyapunov-Stable Polynomial Dynamical Systems Through Imitation
PLEX: Making the Most of the Available Data for Robotic Manipulation Pretraining
Towards Scalable Coverage-Based Testing of Autonomous Vehicles
Curiosity-Driven Learning of Joint Locomotion and Manipulation Tasks
Imitating Task and Motion Planning with Visuomotor Transformers
General In-hand Object Rotation with Vision and Touch
Learning to See Physical Properties with Active Sensing Motor Policies
One-shot Imitation Learning via Interaction Warping
Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation
Large Language Models as General Pattern Machines
Language to Rewards for Robotic Skill Synthesis
Enabling Efficient, Reliable Real-World Reinforcement Learning with Approximate Physics-Based Models
TraCo: Learning Virtual Traffic Coordinator for Cooperation with Multi-Agent Reinforcement Learning
Tuning Legged Locomotion Controllers via Safe Bayesian Optimization
ScalableMap: Scalable Map Learning for Online Long-Range Vectorized HD Map Construction
Towards General Single-Utensil Food Acquisition with Human-Informed Actions
Predicting Object Interactions with Behavior Primitives: An Application in Stowing Tasks
STERLING: Self-Supervised Terrain Representation Learning from Unconstrained Robot Experience
Neural Graph Control Barrier Functions Guided Distributed Collision-avoidance Multi-agent Control
CAT: Closed-loop Adversarial Training for Safe End-to-End Driving
IIFL: Implicit Interactive Fleet Learning from Heterogeneous Human Supervisors
ChainedDiffuser: Unifying Trajectory Diffusion and Keypose Prediction for Robotic Manipulation
A Bayesian Approach to Robust Inverse Reinforcement Learning
Transforming a Quadruped into a Guide Robot for the Visually Impaired: Formalizing Wayfinding, Interaction Modeling, and Safety Mechanism
Synthesizing Navigation Abstractions for Planning with Portable Manipulation Skills
Learning Robot Manipulation from Cross-Morphology Demonstration
HANDLOOM: Learned Tracing of One-Dimensional Objects for Inspection and Manipulation
SCALE: Causal Learning and Discovery of Robot Manipulation Skills using Simulation
Multi-Resolution Sensing for Real-Time Control with Vision-Language Models
Waypoint-Based Imitation Learning for Robotic Manipulation
Seeing-Eye Quadruped Navigation with Force Responsive Locomotion Control
DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control
RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control
4D-Former: Multimodal 4D Panoptic Segmentation
Embodied Lifelong Learning for Task and Motion Planning
HYDRA: Hybrid Robot Actions for Imitation Learning
DYNAMO-GRASP: DYNAMics-aware Optimization for GRASP Point Detection in Suction Grippers
Learning Efficient Abstract Planning Models that Choose What to Predict
Shelving, Stacking, Hanging: Relational Pose Diffusion for Multi-modal Rearrangement
Bootstrap Your Own Skills: Learning to Solve New Tasks with Large Language Model Guidance
PlayFusion: Skill Acquisition via Diffusion from Language-Annotated Play
HomeRobot: Open-Vocabulary Mobile Manipulation
GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields
Hijacking Robot Teams Through Adversarial Communication
Context-Aware Entity Grounding with Open-Vocabulary 3D Scene Graphs
REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation
Cross-Dataset Sensor Alignment: Making Visual 3D Object Detector Generalizable
Dynamic Handover: Throw and Catch with Bimanual Hands
Quantifying Assistive Robustness Via the Natural-Adversarial Frontier
MimicGen: A Data Generation System for Scalable Robot Learning using Human Demonstrations
A Data-Efficient Visual-Audio Representation with Intuitive Fine-tuning for Voice-Controlled Robots
Stealthy Terrain-Aware Multi-Agent Active Search
PolarNet: 3D Point Clouds for Language-Guided Robotic Manipulation
NOIR: Neural Signal Operated Intelligent Robots for Everyday Activities
BridgeData V2: A Dataset for Robot Learning at Scale
A Bayesian approach to breaking things: efficiently predicting and repairing failure modes via sampling
Stochastic Occupancy Grid Map Prediction in Dynamic Scenes
HACMan: Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation
Continual Vision-based Reinforcement Learning with Group Symmetries
Dynamic Multi-Team Racing: Competitive Driving on 1/10-th Scale Vehicles via Learning in Simulation
Tell Me Where to Go: A Composable Framework for Context-Aware Embodied Robot Navigation
Efficient Sim-to-real Transfer of Contact-Rich Manipulation Skills with Online Admittance Residual Learning
OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D Data
Hierarchical Planning for Rope Manipulation using Knot Theory and a Learned Inverse Model
SA6D: Self-Adaptive Few-Shot 6D Pose Estimator for Novel and Occluded Objects
DROID: Learning from Offline Heterogeneous Demonstrations via Reward-Policy Distillation
Im2Contact: Vision-Based Contact Localization Without Touch or Force Sensing
MimicPlay: Long-Horizon Imitation Learning by Watching Human Play
Sample-Efficient Preference-based Reinforcement Learning with Dynamics Aware Rewards
Learning Reusable Manipulation Strategies
Language-guided Robot Grasping: CLIP-based Referring Grasp Synthesis in Clutter
Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping
Learning to Discern: Imitating Heterogeneous Human Demonstrations with Preference and Representation Learning
Context-Aware Deep Reinforcement Learning for Autonomous Robotic Navigation in Unknown Area
Robust Reinforcement Learning in Continuous Control Tasks with Uncertainty Set Regularization
Fleet Active Learning: A Submodular Maximization Approach
Batch Differentiable Pose Refinement for In-The-Wild Camera/LiDAR Extrinsic Calibration
Action-Quantized Offline Reinforcement Learning for Robotic Skill Learning
Language-Guided Traffic Simulation via Scene-Level Diffusion
FindThis: Language-Driven Object Disambiguation in Indoor Environments
Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop Simulation
Composable Part-Based Manipulation
Learning Sequential Acquisition Policies for Robot-Assisted Feeding
Parting with Misconceptions about Learning-based Vehicle Motion Planning
Contrastive Value Learning: Implicit Models for Simple Offline RL
Geometry Matching for Multi-Embodiment Grasping
Rearrangement Planning for General Part Assembly
FlowBot++: Learning Generalized Articulated Objects Manipulation via Articulation Projection
Equivariant Motion Manifold Primitives
On the Utility of Koopman Operator Theory in Learning Dexterous Manipulation Skills
Task-Oriented Koopman-Based Control with Contrastive Encoder
An Unbiased Look at Datasets for Visuo-Motor Pre-Training
A Policy Optimization Method Towards Optimal-time Stability
Reinforcement Learning Enables Real-Time Planning and Control of Agile Maneuvers for Soft Robot Arms
HOI4ABOT: Human-Object Interaction Anticipation for Human Intention Reading Collaborative roBOTs
Grounding Complex Natural Language Commands for Temporal Tasks in Unseen Environments
Predicting Routine Object Usage for Proactive Robot Assistance
ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting
That Sounds Right: Auditory Self-Supervision for Dynamic Robot Manipulation
BM2CP: Efficient Collaborative Perception with LiDAR-Camera Modalities
Robot Parkour Learning
KITE: Keypoint-Conditioned Policies for Semantic Manipulation
Semantic Mechanical Search with Large Vision and Language Models
One-Shot Imitation Learning: A Pose Estimation Perspective
DEFT: Dexterous Fine-Tuning for Hand Policies
SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning
CLUE: Calibrated Latent Guidance for Offline Reinforcement Learning
Expansive Latent Planning for Sparse Reward Offline Reinforcement Learning
Learning to Design and Use Tools for Robotic Manipulation
Fine-Tuning Generative Models as an Inference Method for Robotic Tasks
SCONE: A Food Scooping Robot Learning Framework with Active Perception
Leveraging 3D Reconstruction for Mechanical Search on Cluttered Shelves
Learning Realistic Trafﬁc Agents in Closed-loop
Autonomous Robotic Reinforcement Learning with Asynchronous Human Feedback
Scalable Deep Kernel Gaussian Process for Vehicle Dynamics in Autonomous Racing
What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal Discovery
